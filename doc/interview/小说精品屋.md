# 小说精品屋



## 快速开始

### 项目简介

novel 是一套基于时下**最新** Java 技术栈 Spring Boot 3 + Vue 3 开发的前后端分离的**学习型**小说项目，配备详细的项目开发文档手把手教你**从零开始**开发上线一个生产级别的 Java 系统，由小说门户系统、作家后台管理系统、平台后台管理系统等多个子系统构成。包括小说推荐、作品检索、小说排行榜、小说阅读、小说评论、会员中心、作家专区、充值订阅、新闻发布等功能。

### 项目地址

-   单体架构后端项目：[GitHub](https://github.com/huang-yilong/novel)
-   前端项目：[GitHub](https://github.com/huang-yilong/novel-front-web)

### 开发环境

-   MySQL 8.0
-   Redis 7.0
-   Elasticsearch 8.2.0（可选）
-   RabbitMQ 3.10.2（可选）
-   XXL-JOB 2.3.1（可选）
-   JDK 17
-   Maven 3.8
-   IntelliJ IDEA 2021.3（可选）
-   Node 16.14

**注：Elasticsearch、RabbitMQ 和 XXL-JOB 默认关闭，可通过 application.yml 配置文件中相应的`enable`配置属性开启。**

PS：觉得手动安装开发环境比较麻烦的同学可以[使用 Docker Compose 一键安装开发环境](https://docs.xxyopen.com/course/novel/9.html#%E4%BD%BF%E7%94%A8-docker-compose-%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83)

### 安装步骤

此安装步骤的前提是需要保证上一节的[开发环境](https://docs.xxyopen.com/course/novel/#%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83)可用。

-   下载后端源码

```
git clone https://github.com/huang-yilong/novel.git
```

-   数据库文件导入
    
    1.  新建数据库（建议 novel）
        
    2.  解压后端源码`doc/sql/novel.sql.zip`压缩包，得到数据库结构文件`novel_struc.sql`和数据库小说数据文件`novel_data.sql`
        
    3.  导入`novel_struct.sql`数据库结构文件
        
    4.  导入`novel_data.sql`数据库小说数据文件
    
-   novel 后端服务安装
    
    1.  修改`src/resources/application.yml`配置文件中的数据源配置
    
    ```
    spring:
        datasource:
            url: jdbc:mysql://localhost:3306/novel_test?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=Asia/Shanghai
            username: root
            password: test123456
    ```
    
    2.  修改`src/resources/application.yml` 配置文件中的`redis`连接配置
    
    ```
    spring:
        data:
            # Redis 配置
            redis:
            host: 127.0.0.1
            port: 6379
            password: 123456
    ```
    
    3. 根据前后端的实际部署情况，修改`application.yml`中的跨域配置（默认情况可忽略此步骤）
    
    4. 项目根目录下运行如下命令来启动后端服务（有安装 IDE 的可以导入源码到 IDE 中运行）
    
    ```
    mvn spring-boot:run
    ```
    
    5. 接口文档访问地址：`http://server:port/swagger-ui/index.html`
    
-   下载前端前台门户系统源码
    

```
git clone https://github.com/huang-yilong/novel-front-web.git
```

-   novel-front-web 前端前台门户系统安装
    
    1. 根据前后端的实际部署情况，修改`.env.development`中的`VUE_APP_BASE_API_URL`属性（默认情况可忽略此步骤）
    
    2. `yarn`安装
    
       ```
       npm install -g yarn
       ```
    
    3. 项目根目录下运行如下命令来安装项目依赖
    
       ```
       yarn install
       ```
    
    4. 项目根目录下运行如下命令启动
    
       ```
       yarn serve
       ```
    
    5. 浏览器通过`http://localhost:1024`来访问



## 技术架构

### 运行环境

-   JDK 17
-   MySQL 8.0
-   Redis 7.0
-   Elasticsearch 8.2（默认关闭）
-   RabbitMQ 3.10.2 （默认关闭）
-   XXL-JOB 2.3.1（默认关闭）
-   Undertow 2.2
-   Nginx 1.21

### 后端技术选型

| 技术                | 版本         | 说明                         | 官网                                                     | 学习                                                         |
| ------------------- | ------------ | ---------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| Spring Boot         | 3.0.0        | 容器 + MVC 框架              | [进入](https://spring.io/projects/spring-boot)           | [进入](https://docs.spring.io/spring-boot/docs/3.0.0/reference/html) |
| MyBatis             | 3.5.9        | ORM 框架                     | [进入](http://www.mybatis.org/)                          | [进入](https://mybatis.org/mybatis-3/zh/index.html)          |
| MyBatis-Plus        | 3.5.3        | MyBatis 增强工具             | [进入](https://baomidou.com/)                            | [进入](https://baomidou.com/pages/24112f/)                   |
| JJWT                | 0.11.5       | JWT 登录支持                 | [进入](https://github.com/jwtk/jjwt)                     | \-                                                           |
| Lombok              | 1.18.24      | 简化对象封装工具             | [进入](https://github.com/projectlombok/lombok)          | [进入](https://projectlombok.org/features/all)               |
| Caffeine            | 3.1.0        | 本地缓存支持                 | [进入](https://github.com/ben-manes/caffeine)            | [进入](https://github.com/ben-manes/caffeine/wiki/Home-zh-CN) |
| Redis               | 7.0          | 分布式缓存支持               | [进入](https://redis.io/)                                | [进入](https://redis.io/docs)                                |
| Redisson            | 3.17.4       | 分布式锁实现                 | [进入](https://github.com/redisson/redisson)             | [进入](https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95) |
| MySQL               | 8.0          | 数据库服务                   | [进入](https://www.mysql.com/)                           | [进入](https://docs.oracle.com/en-us/iaas/mysql-database/doc/getting-started.html) |
| ShardingSphere-JDBC | 5.1.1        | 数据库分库分表支持           | [进入](https://shardingsphere.apache.org/)               | [进入](https://shardingsphere.apache.org/document/5.1.1/cn/overview) |
| Elasticsearch       | 8.2.0        | 搜索引擎服务                 | [进入](https://www.elastic.co/)                          | [进入](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html) |
| RabbitMQ            | 3.10.2       | 开源消息中间件               | [进入](https://www.rabbitmq.com/)                        | [进入](https://www.rabbitmq.com/tutorials/tutorial-one-java.html) |
| XXL-JOB             | 2.3.1        | 分布式任务调度平台           | [进入](https://www.xuxueli.com/xxl-job)                  | [进入](https://www.xuxueli.com/xxl-job)                      |
| Sentinel            | 1.8.4        | 流量控制组件                 | [进入](https://github.com/alibaba/Sentinel)              | [进入](https://github.com/alibaba/Sentinel/wiki/%E4%B8%BB%E9%A1%B5) |
| Springdoc-openapi   | 2.0.0        | Swagger 3 接口文档自动生成   | [进入](https://github.com/springdoc/springdoc-openapi)   | [进入](https://springdoc.org/)                               |
| Spring Boot Admin   | 3.0.4        | 应用管理和监控               | [进入](https://github.com/codecentric/spring-boot-admin) | [进入](https://codecentric.github.io/spring-boot-admin/3.0.0-M1) |
| Undertow            | 2.2.17.Final | Java 开发的高性能 Web 服务器 | [进入](https://undertow.io/)                             | [进入](https://undertow.io/documentation.html)               |
| Docker              | \-           | 应用容器引擎                 | [进入](https://www.docker.com/)                          | \-                                                           |
| Jenkins             | \-           | 自动化部署工具               | [进入](https://github.com/jenkinsci/jenkins)             | \-                                                           |
| Sonarqube           | \-           | 代码质量控制                 | [进入](https://www.sonarqube.org/)                       | \-                                                           |

**注：更多热门新技术待集成。**

### 前端技术选型

| 技术         | 版本   | 说明                                   | 官网                                                 | 学习                                                         |
| ------------ | ------ | -------------------------------------- | ---------------------------------------------------- | ------------------------------------------------------------ |
| Vue.js       | 3.2.13 | 渐进式 JavaScript 框架                 | [进入](https://vuejs.org/)        | [进入](https://staging-cn.vuejs.org/guide/introduction.html) |
| Vue Router   | 4.0.15 | Vue.js 的官方路由                      | [进入](https://router.vuejs.org/) | [进入](https://router.vuejs.org/zh/guide/) |
| axios        | 0.27.2 | 基于 promise 的网络请求库              | [进入](https://axios-http.com/)   | [进入](https://axios-http.com/zh/docs/intro) |
| element-plus | 2.2.0  | 基于 Vue 3，面向设计师和开发者的组件库 | [进入](https://element-plus.org/) | [进入](https://element-plus.org/zh-CN/guide/design.html) |

### 编码规范

-   规范方式：严格遵守阿里编码规约。
-   命名统一：简介最大程度上达到了见名知意。
-   分包明确：层级分明可快速定位到代码位置。
-   注释完整：描述性高大量减少了开发人员的代码阅读工作量。
-   工具规范：使用统一jar包避免出现内容冲突。
-   代码整洁：可读性、维护性高。
-   依赖版本：所有依赖均使用当前最新可用版本以便新技术学习。

### 包结构

```
io
 +- github
     +- xxyopen   
        +- novel
            +- NovelApplication.java -- 项目启动类
            |
            +- core -- 项目核心模块，包括各种工具、配置和常量等
            |   +- common -- 业务无关的通用模块
            |   |   +- exception -- 通用异常处理
            |   |   +- constant -- 通用常量   
            |   |   +- req -- 通用请求数据格式封装，例如分页请求数据  
            |   |   +- resp -- 接口响应工具及响应数据格式封装 
            |   |   +- util -- 通用工具   
            |   | 
            |   +- auth -- 用户认证授权相关
            |   +- config -- 业务相关配置
            |   +- constant -- 业务相关常量         
            |   +- filter -- 过滤器 
            |   +- interceptor -- 拦截器
            |   +- json -- JSON 相关的包，包括序列化器和反序列化器
            |   +- task -- 定时任务
            |   +- util -- 业务相关工具 
            |   +- wrapper -- 装饰器
            |
            +- dto -- 数据传输对象，包括对各种 Http 请求和响应数据的封装
            |   +- req -- Http 请求数据封装
            |   +- resp -- Http 响应数据封装
            |
            +- dao -- 数据访问层，与底层 MySQL 进行数据交互
            +- manager -- 通用业务处理层，对第三方平台封装、对 Service 层通用能力的下沉以及对多个 DAO 的组合复用 
            +- service -- 相对具体的业务逻辑服务层  
            +- controller -- 主要是处理各种 Http 请求，各类基本参数校验，或者不复用的业务简单处理，返回 JSON 数据等
            |   +- front -- 小说门户相关接口
            |   +- author -- 作家管理后台相关接口
            |   +- admin -- 平台管理后台相关接口
            |   +- app -- app 接口
            |   +- applet -- 小程序接口
            |   +- open -- 开放接口，供第三方调用 
```

### 版本说明

-   主版本号： 产品方向改变， 或者大规模 API 不兼容， 或者架构不兼容升级。
-   次版本号： 保持相对兼容性，增加主要功能特性，影响范围极小的 API 不兼容修改。
-   修订号： 保持完全兼容性， 修复 BUG、 新增次要功能特性等。



## 技术要点

### MySQL 新特性

1.  `新增 JSON 数据类型`
    
    在 5.7.8 版本之后，MySQL 新增了一个原生的 JSON 数据类型，JSON 值将不再以字符串的形式存储，而是采用一种允许快速读取文本元素（document elements）的内部二进制（internal binary）格式；在 JSON 列插入或者更新的时候将会自动验证 JSON 文本，未通过验证的文本将产生一个错误信息。
    
    之前如果要存储 JSON 类型的数据的话我们只能自己做 JSON.stringify() 和 JSON.parse() 的操作，而且没办法针对 JSON 内的数据进行查询操作，所有的操作必须读取出来 parse 之后进行，非常的麻烦。原生的 JSON 数据类型支持之后，我们就可以直接对 JSON 进行数据查询和修改等操作了，较之前会方便非常多。
    
    MySQL 8 大幅改进了对 JSON 的支持，在主从复制中，新增参数 binlog\_row\_value\_options，控制 JSON 数据的传输方式，允许对于 JSON 类型部分修改，在binlog中只记录修改的部分，减少JSON大数据在只有少量修改的情况下，对资源的占用。
    
2.  `默认字符集由 latin1 变为 utf8mb4`
    
    在 MySQL 8.0 版本之前，默认字符集为 latin1，utf8 指向的是 utf8mb3，8.0版本默认字符集为 utf8mb4，utf8 默认指向的也是 utf8mb4。
    
3.  `MyISAM 系统表全部换成 InnoDB 表`
    
    MySQL 8.0 版本之后系统表全部换成了事务型的 Innodb 表，默认的 MySQL 实例将不包含任何 MyISAM 表，除非手动创建 MyISAM 表。
    
4.  `自增变量持久化`
    
    在 MySQL 8.0 之前的版本，自增主键 AUTO\_INCREMENT 的值如果大于 max(primary key)+1，在 MySQL 重启后，会重置 AUTO\_INCREMENT=max(primary key)+1，这种现象在某些情况下会导致业务主键冲突或者其他难以发现的问题。
    
5.  `DDL 原子化`
    
    MySQL 8.0 版本之后 InnoDB 表的 DDL 支持事务完整性，要么成功要么回滚，例如，数据库里只有一个t1表，执行`drop table t1,t2`语句试图删除t1,t2两张表，在 5.7 中，执行报错，但是 t1 表被删除，在 8.0 中执行报错，但是 t1 表没有被删除，证明了 8.0 DDL操作的原子性，要么全部成功，要么失败回滚。
    
6.  `参数修改持久化`
    
    MySQL 8.0 版本支持在线修改全局参数并持久化，通过加上 PERSIST 关键字，可以将修改的参数持久化到新的配置文件（mysqld-auto.cnf）中，重启 MySQL 时，可以从该配置文件获取到最新的配置参数。
    
7.  `group by 不再隐式排序`
    
    MySQL 8.0 对于group by 字段不再隐式排序，如需要排序，必须显式加上 order by 子句。
    
8.  `支持不可见索引`
    
    MySQL 8.0 支持不可见索引， 使用INVISIBLE关键字在创建表或者进行表变更中设置索引是否可见，索引不可见只是在查询时优化器不使用该索引，即使使用 force index，优化器也不会使用该索引，同时优化器也不会报索引不存在的错误，因为索引仍然真实存在，在必要时，也可以快速的恢复成可见。
    
9.  `新增 innodb_dedicated_server 参数`
    
    MySQL 8.0 新增 innodb\_dedicated\_server 参数，能够让InnoDB根据服务器上检测到的内存大小自动配置 innodb\_buffer\_pool\_size，innodb\_log\_file\_size，innodb\_flush\_method 三个参数。
    
10.  `增加角色管理`
     
    MySQL 8.0 增加角色管理，通常，MySQL 数据库拥有多个相同权限集合的用户。以前，向多个用户授予和撤销权限的唯一方法是单独更改每个用户的权限，假如用户数量比较多的时候，这是非常耗时的，为了用户权限管理更容易，MySQL 提供了一个名为 role 的新对象，它是一个命名的特权集合。
    
11.  `克隆功能`
     
    MySQL 8.0 clone 插件提供从一个实例克隆数据的功能，克隆功能提供了更有效的方式来快速创建MySQL实例，用于自动搭建从节点，也可用于备份 innodb 表，增强了 MySQL InnoDB Cluster。
    
    在 MySQL 克隆功能出现之前，如果想将一个单机MySQL实例升级为高可用实例，或者一个 MySQL 节点由于硬件故障等原因需要重建时首先需要通过 xtrabackup 或mydumper 等物理或逻辑备份工具从正常的 MySQL 节点上进行一个全量备份，然后基于这个全量备份配置正确的 Binlog 相关参数，最后通过 change master to 和 start slave 等命令使新建的 MySQL 节点与所需的 MySQL 节点建立复制关系等待一系列复杂的操作。
    
12.  `binlog 日志压缩`
     
    MySQL 从 8.0.20 增加了 binlog 日志事务压缩功能，开启压缩功能后，将事务信息使用 zstd 算法进行压缩，然后再写入 binlog 日志文件，降低了原文件占用的磁盘空间和网络带宽传输。
    
13.  `连接管理`
     
    在 MySQL 8.0 版本中，对连接管理这一块，先后做了两个比较大的改变：一个是允许额外连接，另一个是专用的管理端口。在 MySQL 8.0 版本中，在当前连接数达到最大连接数时，服务端允许1个额外连接，可以让具有 CONNECTION\_ADMIN 权限的用户连接进来，并且允许具有 SERVICE\_CONNECTION\_ADMIN 权限的用户，通过特定的 IP 和 PORT 连接上来，且没有连接数限制。
    
14.  `取消 Query Cache`
     
    MySQL 8.0 开始，取消了查询缓存，经过时间的考验，MySQL 的工程团队发现启用缓存的好处并不多。
    
    首先，查询缓存的效果取决于缓存的命中率，只有命中缓存的查询效果才能有改善，因此无法预测其性能；其次，查询缓存的另一个大问题是它受到单个互斥锁的保护，在具有多个内核的服务器上，大量查询会导致大量的互斥锁争用；最后，相对来说，缓存越靠近客户端，获得的好处越大。
    
15.  `允许禁用 redo log`
     
    MySQL 8.0.21 开始可以禁用 redo log 来提升数据库的写性能，但降低了安全性，适用于某些对安全要求较低的场景。
    

###  JDK 新特性

1.  `引入模块`
    
    Java 9 开始引入了模块（Module），目的是为了管理依赖。使用模块可以按需打包 JRE 和进一步限制类的访问权限。
    
2.  `接口支持私有方法`
    
    JAVA 9 开始，接口里可以添加私有方法，JAVA 8 对接口增加了默认方法的支持，在 JAVA 9 中对该功能又来了一次升级，现在可以在接口里定义私有方法，然后在默认方法里调用接口的私有方法。这样一来，既可以重用私有方法里的代码，又可以不公开代码。
    
3.  `匿名内部类支持钻石（diamond）运算符`
    
    JAVA 5 就引入了泛型（generic），到了 JAVA 7 开始支持钻石（diamond）运算符：<>，可以自动推断泛型的类型；但是这个自动推断类型的钻石运算符不支持匿名内部类，在 JAVA 9 中也对匿名内部类做了支持。
    
4.  `增强的 try-with-resources`
    
    JAVA 7 中增加了try-with-resources的支持，可以自动关闭资源，但需要声明多个资源变量时，需要在 try 中写多个变量的创建过程，JAVA 9 中对这个功能进行了增强，可以引用 try 代码块之外的变量来自动关闭。
    
5.  `弃用 new Integer()`
    
    JAVA 9 开始弃用了 new Integer() 的方式来创建 Integer 对象，推荐通过静态工厂 Integer.valueOf() 的方式来替代，其它包装类类似。
    
6.  `局部变量的自动类型推断（var）`
    
    JAVA 10 带来了一个很有意思的语法 var，它可以自动推断局部变量的类型，以后再也不用写类型了，也不用靠 lombok 的 var 注解增强了，不过这个只是语法糖，编译后变量还是有类型的。
    
    ```
    for (var c : CacheConsts.CacheEnum.values()) {
            if (c.isLocal()) {
                Caffeine<Object, Object> caffeine = Caffeine.newBuilder().recordStats()
                    .maximumSize(c.getMaxSize());
                if (c.getTtl() > 0) {
                    caffeine.expireAfterWrite(Duration.ofSeconds(c.getTtl()));
                }
                caches.add(new CaffeineCache(c.getName(), caffeine.build()));
            }
        }
    ```
    
7.  `java 命令增强`
    
    以前编译一个 java 文件时，需要先 javac 编译为 class，然后再用 java 执行，JAVA 11 之后可以直接使用 java 命令。
    
8.  `Java Flight Recorder 开源`
    
    「Java Flight Recorder」 是个非常好用的调试诊断工具，不过之前是在 Oracle JDK 中， JAVA 11 后就开源了，OpenJDK 现在也可以用这个功能。
    
9.  `文本块（Text Block）的支持`
    
    JAVA 13 中帮你解决了`大段带换行符的字符串报文`的问题，增加了文本块（"""）的支持，可以不通过换行符换行拼字符串，而且不需要转义特殊字符，就像用模板一样。
    
10.  `新增 record 类型`
     
    JAVA 14 新增 record 类型，干掉复杂的 POJO 类，一般我们创建一个 POJO 类，需要定义属性列表，构造函数，getter/setter方法，比较麻烦，JAVA 14 为我们带来了一个便捷的创建类的方式 - record。
    
    不过这个只是一个语法糖，编译后还是一个 Class，和普通的 Class 区别不大。
    
    POJO含义是指：那些没有继承任何类、也没有实现任何接口，更没有被其它框架侵入的java对象。
    
    ```
    @ConfigurationProperties(prefix = "novel.cors")
    public record CorsProperties(List<String> allowOrigins) {
    
    }
    ```
    
11.  `更直观的 NullPointerException 提示`
     
    JAVA 14 优化了 NullPointerException 的提示，让你更容易定位到哪个对象为空。
    
12.  `switch 语法增强`
     
    switch 从 JDK 14 开始可以通过`yield`关键字来生成结果，并且支持箭头语法取代`case`后面的冒号，使用箭头语法后每个 case 语句后面也无需再加上 break；JDK 17 支持了 case null 的用法。
    
13.  `新增 jpackage 打包工具`
     
    JAVA 14 新增 jpackage 打包工具，可以直接打包二进制程序，再也不用装 JRE 了。
    
    之前如果想构建一个可执行的程序，还需要借助三方工具，将 JRE 一起打包，或者让客户电脑也装一个 JRE 才可以运行我们的 JAVA 程序。
    
    现在 JAVA 直接内置了 jpackage 打包工具，帮助你一键打包二进制程序包。
    
14.  `新增封闭（Sealed ）类`
     
    JAVA 的继承以前只能选择允许继承和不允许继承（final 修饰），JAVA 15 新增了一个封闭（Sealed ）类的特性，可以指定某些类才可以继承。
    
15.  `新增垃圾回收器`
     
    JAVA 15 中，两款垃圾回收器ZGC 和 Shenandoah 正式登陆（默认 G1 ），性能更强，延迟更低。
    
16.  `instanceof 智能转型`
     
    之前处理动态类型碰上要强转时，需要先 instanceof 判断一下，然后再强转为该类型处理，JDK 16 最终完成了 JEP 394 的定稿，针对 instanceof 智能转换变量类型，不需要再来一次额外的强转，语法：`x instanceof String s`。
    

**注：Spring Framework 6 和 Spring Boot 3 的应用程序运行时至少需要JDK 17。**

### SpringBoot 新特性

1.  `优雅关机`
    
    Spring Boot 2.3.0 配置关机缓冲时间后，在关闭时，Web服务器将不再允许新请求，并且将等待缓冲时间以使活动请求完成。
    
    目前内置的四个嵌入式 Web 服务器（Jetty，Reactor Netty，Tomcat和Undertow）以及响应式和基于 Servlet 的 Web 应用程序都支持优雅关机。
    
2.  `Docker 支持`
    
    Spring Boot 2.3.0 添加了部分功能用来帮助将 Spring Boot 应用直接打包到 Docker 镜像。
    
    -   支持 Cloud Native Buildpacks 构建镜像；
        
    -   maven 插件 增加 spring-boot:build-image 、gradle 增加 bootBuildImage task 帮助快速构建镜像；
        
    -   支持 jar 分层，更好的优化打包镜像过程。
    
3.  `全新的配置文件处理`
    
    使用`---`在一个 yml 文件中分割多个配置，如果启用多个配置中有一样的配置项会相互覆盖，在 Spring Boot 2.4.0 版本中声明在最后面的会覆盖前面的配置。在 Spring Boot 2.4.0 之前的版本中取决于`spring.profiles.active`中声明的顺序。
    
    Spring Boot 2.4.0 版本之前使用文件名`application-{profile}`的方式指定配置标识，使用`spring.profiles.active`开启配置；Spring Boot 2.4.0 版本的用法是使用`spring.config.activate.on-profile`来指定配置标识，`spring.profiles.active`不能和它配置在同一个配置块中。
    
    ```
    spring:
      profiles:
        active: dev
    ---
    spring:
      config:
        activate:
          on-profile: dev
    secret：dev-password
    ```
    
    Spring Boot 2.4.0 版本以前使用`spring.profiles`和`spring.profiles.include`配置组合，Spring Boot 2.4.0 版本之后，使用`spring.profiles.group`来配置组合。
    
    ```
    spring:
      profiles:
        active:
          - dev
        group:
          dev:
            - devdb
            - devmq
          test:
            - testdb
            - testmq
    ---
    spring:
      config:
        activate:
          on-profile: dev
    secret: dev-password
    ---
    spring:
      config:
        activate:
          on-profile: devdb
    db: devdb
    ---
    spring:
      config:
        activate:
          on-profile: devmq
    mq: devmq
    ```
    
4.  `默认禁止循环依赖`
    
    我们都知道，如果两个 Bean 互相注入对方就会存在循环引用问题，Spring Boot 2.6.0 这个版本已经默认禁止 Bean 之间的循环引用，如果存在循环引用就会启动失败报错。
    
5.  `支持自定义脱敏规则`
    
    Spring Boot 2.6.0 版本可以清理 /env 和 /configprops 端点中存在的敏感值。另外，还可以通过添加类型为 SanitizingFunction 的 @Bean 类来配置自定义清理规则。
    
6.  `重要端点变更`
    
    Spring Boot 2.6.0版本的环境变量 /env 端点已经默认不开放了，另外 Spring Boot 下的 /info 端点现在可以公开 Java 运行时信息了。
    
7.  `Redis 连接池`
    
    当 commons-pool2 在类路径下时，Redis（包括：Jedis 和 Lettuce）在 Spring Boot 2.6.0 之后的版本会自动开启连接池，也可以设置禁用连接池。
    
8.  `最低 Java 要求`
    
    从Spring Boot 3.0 开始，Java 17 是最低版本，Java 8 不再被兼容。到正式版发行的时候 Java 19 也应该发行了。
    
9.  `Jakarta EE 9`
    
    Spring Boot 依赖于 Jakarta EE（原名 Java EE） 规范，3.0 已经升级到 Jakarta EE 9 版本。因此 Spring Boot 3.0 会使用 Servlet 5.0 规范和 JPA 3.0 规范。相关的三方依赖如果不支持这些规范，将减少或者移除这些依赖。所以相关的三方依赖请尽快根据 Jakarta EE 9 进行版本迭代。基于这个原因，目前不支持Jakarta EE 9 的类库将被移除，包含了一些知名三方类库，例如 EhCache3、Jersey、JOOQ、Thymeleaf 等等，直到这些类库适配 Jakarta EE 9。
    
10.  `声明式 HTTP 客户端`
     
    Spring 6（Spring Boot 3） 开始支持新的声明式 HTTP 客户端。
    
11.  `新的 @AutoConfiguration 类`
     
    Spring Boot 2.7/3 开始，@AutoConfiguration 类由 `META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports`文件而不再是 `META-INF/spring.factories` 文件配置。
    
12.  `@ConfigurationProperties 构造函数绑定`
     
    Spring 6（Spring Boot 3） 开始，@ConfigurationProperties 类支持新的构造函数绑定，而无需显式 @ConstructorBinding。
    

### 全新的 Elasticsearch Java API Client

Elasticsearch Java API Client 是自 7.16 版本开始稳定发布的官方 Java API 客户端。该客户端为所有 Elasticsearch API 提供强类型请求和响应。主要特性如下：

-   所有 Elasticsearch API 的强类型请求和响应。
-   所有 API 的阻塞和异步版本。
-   在创建复杂的嵌套结构时，使用流利的构建器和功能模式允许编写简洁易读的代码。
-   通过使用对象映射器（例如 Jackson）或任何 JSON-B 实现来无缝集成应用程序类。
-   将协议处理委托给 http 客户端，例如 [Java Low Level REST Client](https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/8.2/java-rest-low.html)，该客户端负责处理所有传输级别的问题：HTTP 连接池、重试、节点发现等。

Elasticsearch Java API Client 是一个全新的客户端库，与旧的 High Level Rest Client (HLRC) 没有任何关系。它提供了一个独立于 Elasticsearch 服务器代码的库，并为所有 Elasticsearch 功能提供了一个非常一致且更易于使用的 API。



#### 安装要求

-   Java 8 或更高版本。
-   一个 JSON 对象映射库，允许我们应用程序类与 Elasticsearch API 无缝集成。Java API Client 支持 Jackson 或 Eclipse Yasson 等 JSON-B 库 。

#### 安装

添加以下的 maven 依赖来安装 Java API Client：

```
<dependencies>

    <dependency>
      <groupId>co.elastic.clients</groupId>
      <artifactId>elasticsearch-java</artifactId>
      <version>8.2.0</version>
    </dependency>

    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>2.12.3</version>
    </dependency>

</dependencies>
```

#### 连接

Java API Client 围绕三个主要组件构建：

-   API 客户端类。它们为 Elasticsearch API 提供强类型数据结构和方法。由于 Elasticsearch API 很大，它以功能组（也称为“命名空间”）的形式构成，每个组都有自己的客户端类。Elasticsearch 核心功能在 ElasticsearchClient 类中实现。
-   JSON 对象映射器。将应用程序类映射到 JSON 并将它们与 API 客户端无缝集成。
-   传输层实现。这是所有 HTTP 请求处理发生的地方。

以下代码片段创建并将这三个组件连接在一起：

```
// 1. Create the low-level client
RestClient restClient = RestClient.builder(
new HttpHost("localhost", 9200)).build();

// 2. Create the transport with a Jackson mapper
ElasticsearchTransport transport = new RestClientTransport(
restClient, new JacksonJsonpMapper());

// 3. And create the API client
ElasticsearchClient client = new ElasticsearchClient(transport);
```

#### Spring Boot 中使用

1.  在配置文件 application.yml 中配置如下的 Elasticsearch 连接信息：

```
spring:
  elasticsearch:
    uris:
      - https://my-deployment-ce7ca3.es.us-central1.gcp.cloud.es.io:9243
    username: elastic
    password: qTjgYVKSuExX
```

2.  因为我们使用的是 Spring Boot 项目，当我们引入了 Java API Client 的 maven 相关依赖时，Spring Boot 的自动配置类 `ElasticsearchRestClientAutoConfiguration` 生效，会自动为我们配置`RestClient`、`ElasticsearchTransport`和`ElasticsearchClient`。
    
3.  `ElasticsearchRestClientAutoConfiguration`自动配置类在配置`JacksonJsonpMapper`对象的时候会通过`objectMapper.configure(SerializationFeature.INDENT_OUTPUT, false).setSerializationInclusion(Include.NON_NULL)`代码修改默认的`ObjectMapper`配置覆盖掉了我们自定义的`ObjectMapper`配置，所以我们要手动配置一个`JacksonJsonpMapper`而不是直接使用自动配置的`JacksonJsonpMapper`对象：
    

```
/**
 * elasticsearch 相关配置
 *
 * @author xiongxiaoyang
 * @date 2022/5/23
 */
@Configuration
public class EsConfig {

    /**
     * 解决 ElasticsearchClientConfigurations 修改默认 ObjectMapper 配置的问题
     */
    @Bean
    JacksonJsonpMapper jacksonJsonpMapper() {
        return new JacksonJsonpMapper();
    }

}
```

#### 使用示例

1.  批量插入数据

```
public void saveToEs() {
        QueryWrapper<BookInfo> queryWrapper = new QueryWrapper<>();
        List<BookInfo> bookInfos;
        long maxId = 0;
        for(;;) {
            queryWrapper.clear();
            queryWrapper
                    .orderByAsc(DatabaseConsts.CommonColumnEnum.ID.getName())
                    .gt(DatabaseConsts.CommonColumnEnum.ID.getName(), maxId)
                    .last(DatabaseConsts.SqlEnum.LIMIT_30.getSql());
            bookInfos = bookInfoMapper.selectList(queryWrapper);
            if (bookInfos.isEmpty()) {
                break;
            }
            BulkRequest.Builder br = new BulkRequest.Builder();

            for (BookInfo book : bookInfos) {
                EsBookDto esBook = buildEsBook(book);
                br.operations(op -> op
                        .index(idx -> idx
                                .index(EsConsts.IndexEnum.BOOK.getName())
                                .id(book.getId().toString())
                                .document(esBook)
                        )
                ).timeout(Time.of(t -> t.time("10s")));
                maxId = book.getId();
            }

            BulkResponse result = elasticsearchClient.bulk(br.build());

            // Log errors, if any
            if (result.errors()) {
                log.error("Bulk had errors");
                for (BulkResponseItem item : result.items()) {
                    if (item.error() != null) {
                        log.error(item.error().reason());
                    }
                }
            }

        }

    }
```

2.  全文检索

```
@SneakyThrows
@Override
public RestResp<PageRespDto<BookInfoRespDto>> searchBooks(BookSearchReqDto condition) {

    SearchResponse<EsBookDto> response = esClient.search(s -> {

                SearchRequest.Builder searchBuilder = s.index(EsConsts.IndexEnum.BOOK.getName());
                buildSearchCondition(condition, searchBuilder);
                // 排序
                if (!StringUtils.isBlank(condition.getSort())) {
                    searchBuilder.sort(o ->
                            o.field(f -> f.field(condition.getSort()).order(SortOrder.Desc))
                    );
                }
                // 分页
                searchBuilder.from((condition.getPageNum() - 1) * condition.getPageSize())
                        .size(condition.getPageSize());

                return searchBuilder;
            },
            EsBookDto.class
    );

    TotalHits total = response.hits().total();

    List<BookInfoRespDto> list = new ArrayList<>();
    List<Hit<EsBookDto>> hits = response.hits().hits();
    for (Hit<EsBookDto> hit : hits) {
        EsBookDto book = hit.source();
        list.add(BookInfoRespDto.builder()
                .id(book.getId())
                .bookName(book.getBookName())
                .categoryId(book.getCategoryId())
                .categoryName(book.getCategoryName())
                .authorId(book.getAuthorId())
                .authorName(book.getAuthorName())
                .wordCount(book.getWordCount())
                .lastChapterName(book.getLastChapterName())
                .build());
    }
    return RestResp.ok(PageRespDto.of(condition.getPageNum(), condition.getPageSize(), total.value(), list));

}

/**
 * 构建查询条件
 */
private void buildSearchCondition(BookSearchReqDto condition, SearchRequest.Builder searchBuilder) {

    BoolQuery boolQuery = BoolQuery.of(b -> {

        if (!StringUtils.isBlank(condition.getKeyword())) {
            // 关键词匹配
            b.must((q -> q.multiMatch(t -> t
                    .fields("bookName^2","authorName^1.8","bookDesc^0.1")
                    .query(condition.getKeyword())
            )
            ));
        }

        // 精确查询
        if (Objects.nonNull(condition.getWorkDirection())) {
            b.must(TermQuery.of(m -> m
                    .field("workDirection")
                    .value(condition.getWorkDirection())
            )._toQuery());
        }

        if (Objects.nonNull(condition.getCategoryId())) {
            b.must(TermQuery.of(m -> m
                    .field("categoryId")
                    .value(condition.getCategoryId())
            )._toQuery());
        }

        // 范围查询
        if (Objects.nonNull(condition.getWordCountMin())) {
            b.must(RangeQuery.of(m -> m
                    .field("wordCount")
                    .gte(JsonData.of(condition.getWordCountMin()))
            )._toQuery());
        }

        if (Objects.nonNull(condition.getWordCountMax())) {
            b.must(RangeQuery.of(m -> m
                    .field("wordCount")
                    .lt(JsonData.of(condition.getWordCountMax()))
            )._toQuery());
        }

        if (Objects.nonNull(condition.getUpdateTimeMin())) {
            b.must(RangeQuery.of(m -> m
                    .field("lastChapterUpdateTime")
                    .gte(JsonData.of(condition.getUpdateTimeMin().getTime()))
            )._toQuery());
        }

        return b;

    });

    searchBuilder.query(q -> q.bool(boolQuery));

}
```



## 数据库设计

### 数据库设计规约

1.  表达是与否概念的字段，必须使用 is\_xxx 的方式命名，数据类型是 unsigned tinyint（ 1 表示是， 0 表示否）。

说明： 任何字段如果为非负数，必须是 unsigned，坚持 is\_xxx 的命名方式是为了明确其取值含义与取值范围。

正例： 表达逻辑删除的字段名 is\_deleted， 1 表示删除， 0 表示未删除。

2.  表名、字段名必须使用小写字母或数字， 禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，字段名称需要慎重考虑。

说明： MySQL 在 Windows 下不区分大小写，但在 Linux 下默认是区分大小写。因此，数据库名、表名、字段名，都不允许出现任何大写字母，避免节外生枝。

3.  表名不使用复数名词。

说明： 表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。

4.  禁用保留字，如 desc、 range、 match、 delayed 等， 请参考 MySQL 官方保留字。
    
5.  主键索引名为 pk\_字段名；唯一索引名为 uk\_字段名； 普通索引名则为 idx\_字段名。
    

说明： pk\_ 即 primary key； uk\_ 即 unique key； idx\_ 即 index 的简称。

6.  小数类型为 decimal，禁止使用 float 和 double。

说明： 在存储的时候， float 和 double 都存在精度损失的问题，很可能在比较值的时候，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数并分开存储。

7.  如果存储的字符串长度几乎相等，使用 char 定长字符串类型。
    
8.  varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。
    
9.  表必备三字段： id, create\_time, update\_time。
    

说明： 其中 id 必为主键，类型为 bigint unsigned、单表时自增、步长为 1。 create\_time, update\_time的类型均为 datetime 类型，前者现在时表示主动式创建，后者过去分词表示被动式更新。

注意：更新数据表记录时，必须同时更新记录对应的 update\_time 字段值为当前时间。

10.  表的命名最好是遵循“业务名称\_表的作用” 。

正例：book\_info / book\_chapter / user\_bookshelf / user\_comment / author\_info

11.  库名与应用名称尽量一致。
    
12.  如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。
    
13.  字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：
     
    -   不是频繁修改的字段。
    -   不是唯一索引的字段。
    -   不是 varchar 超长字段，更不能是 text 字段。

正例： 各业务线经常冗余存储小说名称，避免查询时需要连表（单体应用）或跨服务（微服务应用）获取。

14.  单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。

说明： 如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。

15.  合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。

正例： 无符号值可以避免误存负数， 且扩大了表示范围。

16.  业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。

说明： 不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明显的； 另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。

17.  超过三个表禁止 join。需要 join 的字段，数据类型保持绝对一致； 多表关联查询时，保证被关联的字段需要有索引。

说明： 即使双表 join 也要注意表索引、 SQL 性能。

18.  在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度。

说明： 索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90%以上，可以使用 count(distinct left(列名, 索引长度))/count(\*)的区分度来确定。

19.  创建索引时避免有如下极端误解：
     
    -   索引宁滥勿缺。 认为一个查询就需要建一个索引。
    -   吝啬索引的创建。 认为索引会消耗空间、 严重拖慢记录的更新以及行的新增速度。
    -   抵制惟一索引。 认为惟一索引一律需要在应用层通过“先查后插” 方式解决。

### 数据库建模工具

本项目使用PDManer对数据库进行设计、版本管理等。

#### 介绍

PDManer 元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具，基于 ES6 + React + Electron + Java 构建，相对于 PowerDesigner，他具备界面简洁美观，操作简单，上手容易等特点。支持 Windows, Mac, Linux 等操作系统，也能够支持国产操作系统，能够支持的数据库如下：

-   MySQL, PostgreSQL, Oracle, SQLServer等常见数据库
-   支持达梦，GuassDB 等国产数据库
-   支持 Hive，MaxCompute 等大数据方向的数据库
-   用户还可以自行添加更多的数据库扩展

#### 主要功能

**数据表管理：** 数据表，字段，注释，索引等基本功能。 
**视图管理：** 实现选择多张表多个字段后，组合一个新的视图对象，视图可生成 DDL 以及相关程序代码，例如 Java 的 DTO 等。
**ER关系图：** 数据表可绘制ER关系图至画布，也支持概念模型等高阶抽像设计。 
**数据字典：** 代码映射表管理，例如 1 表示男，2 表示女，并且实现数据字典与数据表字段的关联。 
**数据类型：** 系统实现了基础数据类型，基础数据类型在不同数据库下表现为不同数据库类型的方言，这是实现多数据\*\*库支持的基础，为更贴近业务，引入了PowerDesigner的数据域这一概念，用于统一同一类具有同样业务属性字段的批量设置类型，长度等。基础数据类型以及数据域，用户均可自行添加，自行定义。 
**多数据库：** 内置主流常见数据库，如 MySQL，PostgreSQL，SQLServer，Oracle等，并且支持用户自行添加新的数据库。 
**代码生成：** 内置 Java，Mybatis，MyBatisPlus 等常规情况下 Controller，Service，Mapper 的生成，也添加了 C# 语言支持，可自行扩展对其他语言的支持，如Python 等。 
**版本管理：** 实现数据表的版本管理，可生成增量DDL脚本。 
**生态对接：** 能够导入PowerDesigner的pdm文件，老版本的PDMan文件，也能导出为word文档，导出相关设置等。

#### 软件下载

[https://gitee.com/robergroup/pdmaner/releases](https://gitee.com/robergroup/pdmaner/releases)

### 系统功能概要

-   前台门户系统
    
    -   **首页：** 轮播图、本周推荐、热门推荐、精品推荐、点击榜单、新书榜单、更新榜单、最新新闻、友情链接、反馈留言
    -   **新闻模块：** 新闻分类、新闻列表、新闻阅读
    -   **小说检索：** 根据书名、作者名等关键词和作品频道、分类、是否完结、字数、更新方式等筛选条件检索小说
    -   **小说详情页：** 小说信息展示、作家信息展示、最新章节概要、最新评论、评论发表、加入书架、同类推荐
    -   **小说评论页：** 小说评论区，评论展示、发表评论
    -   **小说目录页：** 小说目录展示
    -   **小说内容页：** 小说章节订阅、小说内容阅读、小说段落评论
    -   **排行榜：** 点击榜、更新榜、新书榜、评论榜
    -   **充值：** 支付宝/微信购买虚拟币
    -   **会员中心：** 登录注册、账号信息、账号设置、书架、阅读历史、书评、充值/消费记录、用户反馈
-   作家后台管理系统
    
    -   **作家申请：** 获取邀请码、作家信息提交
    -   **小说管理：** 小说发布、章节管理、薪酬查询、作品信息
    -   **稿费收入：** 订阅明细、稿费汇总
-   平台后台管理系统
    
    -   **系统管理：** 用户管理、角色管理、权限管理、菜单管理
    -   **首页管理：** 小说推荐管理、新闻发布管理、友情链接管理
    -   **会员管理：** 网站会员管理、反馈管理、评论管理
    -   **作家管理：** 作家邀请码管理、作家信息管理
    -   **小说管理：** 小说管理、小说章节管理
    -   **订单管理：** 充值订单、订阅订单
    -   **统计报表：** 会员、作家、小说、交易等数据的统计报表

### 数据库关系图

#### 首页模块

![首页模块ER图](pic/home-ER.png)

#### 新闻模块

![新闻模块ER图](pic/news-ER.png)

#### 小说模块

![小说模块ER图](pic/book-ER.png)

#### 用户模块

![用户模块ER图](pic/user-ER.png)

#### 作家模块

![作家模块ER图](pic/author-ER.png)

#### 支付模块

![作家模块ER图](pic/pay-ER.png)

#### 系统模块

![系统模块ER图](pic/sys-ER.png)

### 数据库表结构

#### 首页模块

**home\_book \[**首页小说推荐**\]**

| **#** | **字段**     | **名称**   | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**                                       |
| ----- | ------------ | ---------- | ---------------- | -------- | -------- | ---------- | -------------------------------------------------- |
| 1     | id           |            | BIGINT UNSIGNED  | √        | √        |            |                                                    |
| 2     | type         | 推荐类型   | TINYINT UNSIGNED |          | √        |            | 0-轮播图 1-顶部栏 2-本周强推 3-热门推荐 4-精品推荐 |
| 3     | sort         | 推荐排序   | TINYINT UNSIGNED |          | √        |            |                                                    |
| 4     | book\_id     | 推荐小说ID | BIGINT UNSIGNED  |          | √        |            |                                                    |
| 5     | create\_time | 创建时间   | DATETIME         |          |          |            |                                                    |
| 6     | update\_time | 更新时间   | DATETIME         |          |          |            |                                                    |

**home\_friend\_link \[**友情链接**\]**

| **#** | **字段**     | **名称** | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**    |
| ----- | ------------ | -------- | ---------------- | -------- | -------- | ---------- | --------------- |
| 1     | id           |          | BIGINT UNSIGNED  | √        | √        |            |                 |
| 2     | link\_name   | 链接名   | VARCHAR(50)      |          | √        |            |                 |
| 3     | link\_url    | 链接url  | VARCHAR(100)     |          | √        |            |                 |
| 4     | sort         | 排序号   | TINYINT UNSIGNED |          | √        | 11         |                 |
| 5     | is\_open     | 是否开启 | TINYINT UNSIGNED |          | √        | 1          | 0-不开启 1-开启 |
| 6     | create\_time | 创建时间 | DATETIME         |          |          |            |                 |
| 7     | update\_time | 更新时间 | DATETIME         |          |          |            |                 |

#### 新闻模块

**news\_category \[**新闻类别**\]**

| **#** | **字段**     | **名称** | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | -------- | ---------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           |          | BIGINT UNSIGNED  | √        | √        |            |              |
| 2     | name         | 类别名   | VARCHAR(20)      |          | √        |            |              |
| 3     | sort         | 排序     | TINYINT UNSIGNED |          | √        | 10         |              |
| 4     | create\_time | 创建时间 | DATETIME         |          |          |            |              |
| 5     | update\_time | 更新时间 | DATETIME         |          |          |            |              |

**news\_info \[**新闻信息**\]**

| **#** | **字段**       | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | -------------- | -------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id             | 主键     | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | category\_id   | 类别ID   | BIGINT UNSIGNED |          | √        |            |              |
| 3     | category\_name | 类别名   | VARCHAR(50)     |          | √        |            |              |
| 4     | source\_name   | 新闻来源 | VARCHAR(50)     |          | √        |            |              |
| 5     | title          | 新闻标题 | VARCHAR(100)    |          | √        |            |              |
| 6     | create\_time   | 创建时间 | DATETIME        |          |          |            |              |
| 7     | update\_time   | 更新时间 | DATETIME        |          |          |            |              |

**news\_content \[**新闻内容**\]**

| **#** | **字段**     | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | -------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           | 主键     | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | news\_id     | 新闻ID   | BIGINT UNSIGNED |          | √        |            |              |
| 3     | content      | 新闻内容 | MEDIUMTEXT      |          | √        |            |              |
| 4     | create\_time | 创建时间 | DATETIME        |          |          |            |              |
| 5     | update\_time | 更新时间 | DATETIME        |          |          |            |              |

#### 小说模块

**book\_category \[**小说类别**\]**

| **#** | **字段**        | **名称** | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | --------------- | -------- | ---------------- | -------- | -------- | ---------- | ------------- |
| 1     | id              |          | BIGINT UNSIGNED  | √        | √        |            |               |
| 2     | work\_direction | 作品方向 | TINYINT UNSIGNED |          | √        |            | 0-男频 1-女频 |
| 3     | name            | 类别名   | VARCHAR(20)      |          | √        |            |               |
| 4     | sort            | 排序     | TINYINT UNSIGNED |          | √        | 10         |               |
| 5     | create\_time    | 创建时间 | DATETIME         |          |          |            |               |
| 6     | update\_time    | 更新时间 | DATETIME         |          |          |            |               |

**book\_info \[**小说信息**\]**

| **#** | **字段**                    | **名称**         | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**                  |
| ----- | --------------------------- | ---------------- | ---------------- | -------- | -------- | ---------- | ----------------------------- |
| 1     | id                          | 主键             | BIGINT UNSIGNED  | √        | √        |            |                               |
| 2     | work\_direction             | 作品方向         | TINYINT UNSIGNED |          | √        |            | 0-男频 1-女频                 |
| 3     | category\_id                | 类别ID           | BIGINT UNSIGNED  |          | √        |            |                               |
| 4     | category\_name              | 类别名           | VARCHAR(50)      |          | √        |            |                               |
| 5     | pic\_url                    | 小说封面地址     | VARCHAR(200)     |          | √        |            |                               |
| 6     | book\_name                  | 小说名           | VARCHAR(50)      |          | √        |            |                               |
| 7     | author\_id                  | 作家id           | BIGINT UNSIGNED  |          | √        |            |                               |
| 8     | author\_name                | 作家名           | VARCHAR(50)      |          | √        |            |                               |
| 9     | book\_desc                  | 书籍描述         | VARCHAR(2000)    |          | √        |            |                               |
| 10    | score                       | 评分             | TINYINT UNSIGNED |          | √        |            | 总分:10 ，真实评分 = score/10 |
| 11    | book\_status                | 书籍状态         | TINYINT UNSIGNED |          | √        | 0          | 0-连载中 1-已完结             |
| 12    | visit\_count                | 点击量           | BIGINT UNSIGNED  |          | √        | 103        |                               |
| 13    | word\_count                 | 总字数           | INT UNSIGNED     |          | √        | 0          |                               |
| 14    | comment\_count              | 评论数           | INT UNSIGNED     |          | √        | 0          |                               |
| 15    | last\_chapter\_id           | 最新章节ID       | BIGINT UNSIGNED  |          |          |            |                               |
| 16    | last\_chapter\_name         | 最新章节名       | VARCHAR(50)      |          |          |            |                               |
| 17    | last\_chapter\_update\_time | 最新章节更新时间 | DATETIME         |          |          |            |                               |
| 18    | is\_vip                     | 是否收费         | TINYINT UNSIGNED |          | √        | 0          | 1-收费 0-免费                 |
| 19    | create\_time                | 创建时间         | DATETIME         |          |          |            |                               |
| 20    | update\_time                | 更新时间         | DATETIME         |          | √        |            |                               |

**book\_chapter \[**小说章节**\]**

| **#** | **字段**      | **名称** | **数据类型**      | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | ------------- | -------- | ----------------- | -------- | -------- | ---------- | ------------- |
| 1     | id            |          | BIGINT UNSIGNED   | √        | √        |            |               |
| 2     | book\_id      | 小说ID   | BIGINT UNSIGNED   |          | √        |            |               |
| 3     | chapter\_num  | 章节号   | SMALLINT UNSIGNED |          | √        |            |               |
| 4     | chapter\_name | 章节名   | VARCHAR(100)      |          | √        |            |               |
| 5     | word\_count   | 章节字数 | INT UNSIGNED      |          | √        |            |               |
| 6     | is\_vip       | 是否收费 | TINYINT UNSIGNED  |          | √        | 0          | 1-收费 0-免费 |
| 7     | create\_time  |          | DATETIME          |          |          |            |               |
| 8     | update\_time  |          | DATETIME          |          |          |            |               |

**book\_content \[**小说内容**\]**

| **#** | **字段**     | **名称**     | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | ------------ | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           | 主键         | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | chapter\_id  | 章节ID       | BIGINT UNSIGNED |          | √        |            |              |
| 3     | content      | 小说章节内容 | MEDIUMTEXT      |          | √        |            |              |
| 4     | create\_time |              | DATETIME        |          |          |            |              |
| 5     | update\_time |              | DATETIME        |          |          |            |              |

**book\_comment \[**小说评论**\]**

| **#** | **字段**         | **名称**   | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**                     |
| ----- | ---------------- | ---------- | ---------------- | -------- | -------- | ---------- | -------------------------------- |
| 1     | id               | 主键       | BIGINT UNSIGNED  | √        | √        |            |                                  |
| 2     | book\_id         | 评论小说ID | BIGINT UNSIGNED  |          | √        |            |                                  |
| 3     | user\_id         | 评论用户ID | BIGINT UNSIGNED  |          | √        |            |                                  |
| 4     | comment\_content | 评价内容   | VARCHAR(512)     |          | √        |            |                                  |
| 5     | reply\_count     | 回复数量   | INT UNSIGNED     |          | √        | 0          |                                  |
| 6     | audit\_status    | 审核状态   | TINYINT UNSIGNED |          | √        | 0          | 0-待审核 1-审核通过 2-审核不通过 |
| 7     | create\_time     | 创建时间   | DATETIME         |          |          |            |                                  |
| 8     | update\_time     | 更新时间   | DATETIME         |          |          |            |                                  |

**book\_comment\_reply \[**小说评论回复**\]**

| **#** | **字段**       | **名称**   | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**                     |
| ----- | -------------- | ---------- | ---------------- | -------- | -------- | ---------- | -------------------------------- |
| 1     | id             | 主键       | BIGINT UNSIGNED  | √        | √        |            |                                  |
| 2     | comment\_id    | 评论ID     | BIGINT UNSIGNED  |          | √        |            |                                  |
| 3     | user\_id       | 回复用户ID | BIGINT UNSIGNED  |          | √        |            |                                  |
| 4     | reply\_content | 回复内容   | VARCHAR(512)     |          | √        |            |                                  |
| 5     | audit\_status  | 审核状态   | TINYINT UNSIGNED |          | √        | 0          | 0-待审核 1-审核通过 2-审核不通过 |
| 6     | create\_time   | 创建时间   | DATETIME         |          |          |            |                                  |
| 7     | update\_time   | 更新时间   | DATETIME         |          |          |            |                                  |

#### 用户模块

**user\_info \[**用户信息**\]**

| **#** | **字段**         | **名称**      | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ---------------- | ------------- | ---------------- | -------- | -------- | ---------- | ------------ |
| 1     | id               |               | BIGINT UNSIGNED  | √        | √        |            |              |
| 2     | username         | 登录名        | VARCHAR(50)      |          | √        |            |              |
| 3     | password         | 登录密码-加密 | VARCHAR(100)     |          | √        |            |              |
| 4     | salt             | 加密盐值      | VARCHAR(8)       |          | √        |            |              |
| 5     | nick\_name       | 昵称          | VARCHAR(50)      |          |          |            |              |
| 6     | user\_photo      | 用户头像      | VARCHAR(100)     |          |          |            |              |
| 7     | user\_sex        | 用户性别      | TINYINT UNSIGNED |          |          |            | 0-男 1-女    |
| 8     | account\_balance | 账户余额      | BIGINT UNSIGNED  |          | √        | 0          |              |
| 9     | status           | 用户状态      | TINYINT UNSIGNED |          | √        | 0          | 0-正常       |
| 10    | create\_time     | 创建时间      | DATETIME         |          | √        |            |              |
| 11    | update\_time     | 更新时间      | DATETIME         |          | √        |            |              |

**user\_feedback \[**用户反馈**\]**

| **#** | **字段**     | **名称**   | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | ---------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           |            | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | user\_id     | 反馈用户id | BIGINT UNSIGNED |          | √        |            |              |
| 3     | content      | 反馈内容   | VARCHAR(512)    |          | √        |            |              |
| 4     | create\_time | 创建时间   | DATETIME        |          |          |            |              |
| 5     | update\_time | 更新时间   | DATETIME        |          |          |            |              |

**user\_bookshelf \[**用户书架**\]**

| **#** | **字段**         | **名称**                 | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ---------------- | ------------------------ | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id               | 主键                     | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | user\_id         | 用户ID                   | BIGINT UNSIGNED |          | √        |            |              |
| 3     | book\_id         | 小说ID                   | BIGINT UNSIGNED |          | √        |            |              |
| 4     | pre\_content\_id | 上一次阅读的章节内容表ID | BIGINT UNSIGNED |          |          |            |              |
| 5     | create\_time     | 创建时间                 | DATETIME        |          |          |            |              |
| 6     | update\_time     | 更新时间                 | DATETIME        |          |          |            |              |

**user\_read\_history \[**用户阅读历史**\]**

| **#** | **字段**         | **名称**                 | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ---------------- | ------------------------ | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id               | 主键                     | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | user\_id         | 用户ID                   | BIGINT UNSIGNED |          | √        |            |              |
| 3     | book\_id         | 小说ID                   | BIGINT UNSIGNED |          | √        |            |              |
| 4     | pre\_content\_id | 上一次阅读的章节内容表ID | BIGINT UNSIGNED |          | √        |            |              |
| 5     | create\_time     | 创建时间                 | DATETIME        |          |          |            |              |
| 6     | update\_time     | 更新时间                 | DATETIME        |          |          |            |              |

**user\_consume\_log \[**用户消费记录**\]**

| **#** | **字段**      | **名称**       | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | ------------- | -------------- | ---------------- | -------- | -------- | ---------- | ------------- |
| 1     | id            | 主键           | BIGINT UNSIGNED  | √        | √        |            |               |
| 2     | user\_id      | 消费用户ID     | BIGINT UNSIGNED  |          | √        |            |               |
| 3     | amount        | 消费使用的金额 | INT UNSIGNED     |          | √        |            | 单位：屋币    |
| 4     | product\_type | 消费商品类型   | TINYINT UNSIGNED |          | √        | 0          | 0-小说VIP章节 |
| 5     | product\_id   | 消费的的商品ID | BIGINT UNSIGNED  |          |          |            | 例如：章节ID  |
| 6     | produc\_name  | 消费的的商品名 | VARCHAR(50)      |          |          |            | 例如：章节名  |
| 7     | produc\_value | 消费的的商品值 | INT UNSIGNED     |          |          |            | 例如：1       |
| 8     | create\_time  | 创建时间       | DATETIME         |          |          |            |               |
| 9     | update\_time  | 更新时间       | DATETIME         |          |          |            |               |

**user\_pay\_log \[**用户充值记录**\]**

| **#** | **字段**       | **名称**     | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**     |
| ----- | -------------- | ------------ | ---------------- | -------- | -------- | ---------- | ---------------- |
| 1     | id             |              | BIGINT UNSIGNED  | √        | √        |            |                  |
| 2     | user\_id       | 充值用户ID   | BIGINT UNSIGNED  |          | √        |            |                  |
| 3     | pay\_channel   | 充值方式     | TINYINT UNSIGNED |          | √        | 1          | 0-支付宝 1-微信  |
| 4     | out\_trade\_no | 商户订单号   | VARCHAR(64)      |          | √        |            |                  |
| 5     | amount         | 充值金额     | INT UNSIGNED     |          | √        |            | 单位：分         |
| 6     | product\_type  | 充值商品类型 | TINYINT UNSIGNED |          | √        | 0          | 0-屋币 1-包年VIP |
| 7     | product\_id    | 充值商品ID   | BIGINT UNSIGNED  |          |          |            |                  |
| 8     | product\_name  | 充值商品名   | VARCHAR(255)     |          | √        |            | 示例值：屋币     |
| 9     | product\_value | 充值商品值   | INT UNSIGNED     |          |          |            | 示例值：255      |
| 10    | pay\_time      | 充值时间     | DATETIME         |          | √        |            |                  |
| 11    | create\_time   | 创建时间     | DATETIME         |          |          |            |                  |
| 12    | update\_time   | 更新时间     | DATETIME         |          |          |            |                  |

#### 作家模块

**author\_code \[**作家邀请码**\]**

| **#** | **字段**       | **名称**   | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**      |
| ----- | -------------- | ---------- | ---------------- | -------- | -------- | ---------- | ----------------- |
| 1     | id             | 主键       | BIGINT UNSIGNED  | √        | √        |            |                   |
| 2     | invite\_code   | 邀请码     | VARCHAR(100)     |          | √        |            |                   |
| 3     | validity\_time | 有效时间   | DATETIME         |          | √        |            |                   |
| 4     | is\_used       | 是否使用过 | TINYINT UNSIGNED |          | √        | 0          | 0-未使用 1-使用过 |
| 5     | create\_time   | 创建时间   | DATETIME         |          |          |            |                   |
| 6     | update\_time   | 更新时间   | DATETIME         |          |          |            |                   |

**author\_info \[**作者信息**\]**

| **#** | **字段**        | **名称**     | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | --------------- | ------------ | ---------------- | -------- | -------- | ---------- | ------------- |
| 1     | id              | 主键         | BIGINT UNSIGNED  | √        | √        |            |               |
| 2     | user\_id        | 用户ID       | BIGINT UNSIGNED  |          | √        |            |               |
| 3     | invite\_code    | 邀请码       | VARCHAR(20)      |          | √        |            |               |
| 4     | pen\_name       | 笔名         | VARCHAR(20)      |          | √        |            |               |
| 5     | tel\_phone      | 手机号码     | VARCHAR(20)      |          |          |            |               |
| 6     | chat\_account   | QQ或微信账号 | VARCHAR(50)      |          |          |            |               |
| 7     | email           | 电子邮箱     | VARCHAR(50)      |          |          |            |               |
| 8     | work\_direction | 作品方向     | TINYINT UNSIGNED |          |          |            | 0-男频 1-女频 |
| 9     | status          | 0：正常      | TINYINT UNSIGNED |          | √        | 0          | 1-封禁        |
| 10    | create\_time    | 创建时间     | DATETIME         |          |          |            |               |
| 11    | update\_time    | 更新时间     | DATETIME         |          |          |            |               |

**author\_income \[**稿费收入统计**\]**

| **#** | **字段**           | **名称**     | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**      |
| ----- | ------------------ | ------------ | ---------------- | -------- | -------- | ---------- | ----------------- |
| 1     | id                 | 主键         | BIGINT UNSIGNED  | √        | √        |            |                   |
| 2     | author\_id         | 作家ID       | BIGINT UNSIGNED  |          | √        |            |                   |
| 3     | book\_id           | 小说ID       | BIGINT UNSIGNED  |          | √        |            |                   |
| 4     | income\_month      | 收入月份     | DATE             |          | √        |            |                   |
| 5     | pre\_tax\_income   | 税前收入     | INT UNSIGNED     |          | √        | 0          | 单位：分          |
| 6     | after\_tax\_income | 税后收入     | INT UNSIGNED     |          | √        | 0          | 单位：分          |
| 7     | pay\_status        | 支付状态     | TINYINT UNSIGNED |          | √        | 0          | 0-待支付 1-已支付 |
| 8     | confirm\_status    | 稿费确认状态 | TINYINT UNSIGNED |          | √        | 0          | 0-待确认 1-已确认 |
| 9     | detail             | 详情         | VARCHAR(255)     |          |          |            |                   |
| 10    | create\_time       | 创建时间     | DATETIME         |          |          |            |                   |
| 11    | update\_time       | 更新时间     | DATETIME         |          |          |            |                   |

**author\_income\_detail \[**稿费收入明细统计**\]**

| **#** | **字段**        | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | --------------- | -------- | --------------- | -------- | -------- | ---------- | ------------- |
| 1     | id              | 主键     | BIGINT UNSIGNED | √        | √        |            |               |
| 2     | author\_id      | 作家ID   | BIGINT UNSIGNED |          | √        |            |               |
| 3     | book\_id        | 小说ID   | BIGINT UNSIGNED |          | √        | 0          | 0表示全部作品 |
| 4     | income\_date    | 收入日期 | DATE            |          | √        |            |               |
| 5     | income\_account | 订阅总额 | INT UNSIGNED    |          | √        | 0          |               |
| 6     | income\_count   | 订阅次数 | INT UNSIGNED    |          | √        | 0          |               |
| 7     | income\_number  | 订阅人数 | INT UNSIGNED    |          | √        | 0          |               |
| 8     | create\_time    | 创建时间 | DATETIME        |          |          |            |               |
| 9     | update\_time    | 更新时间 | DATETIME        |          |          |            |               |

#### 支付模块

**pay\_alipay \[**支付宝支付**\]**

| **#** | **字段**        | **名称**          | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明**            |
| ----- | --------------- | ----------------- | --------------- | -------- | -------- | ---------- | ----------------------- |
| 1     | id              | 主键              | BIGINT UNSIGNED | √        | √        |            |                         |
| 2     | out\_trade\_no  | 商户订单号        | VARCHAR(64)     |          | √        |            |                         |
| 3     | trade\_no       | 支付宝交易号      | VARCHAR(64)     |          | √        |            |                         |
| 4     | buyer\_id       | 买家支付宝账号 ID | VARCHAR(16)     |          |          |            |                         |
| 5     | trade\_status   | 交易状态          | VARCHAR(32)     |          |          |            | TRADE\_SUCCESS-交易成功 |
| 6     | total\_amount   | 订单金额          | INT UNSIGNED    |          | √        |            | 单位：分                |
| 7     | receipt\_amount | 实收金额          | INT UNSIGNED    |          |          |            | 单位：分                |
| 8     | invoice\_amount | 开票金额          | INT UNSIGNED    |          |          |            |                         |
| 9     | gmt\_create     | 交易创建时间      | DATETIME        |          |          |            |                         |
| 10    | gmt\_payment    | 交易付款时间      | DATETIME        |          |          |            |                         |
| 11    | create\_time    | 创建时间          | DATETIME        |          |          |            |                         |
| 12    | update\_time    | 更新时间          | DATETIME        |          |          |            |                         |

**pay\_wechat \[**微信支付**\]**

| **#** | **字段**           | **名称**       | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明**                                                 |
| ----- | ------------------ | -------------- | --------------- | -------- | -------- | ---------- | ------------------------------------------------------------ |
| 1     | id                 | 主键           | BIGINT UNSIGNED | √        | √        |            |                                                              |
| 2     | out\_trade\_no     | 商户订单号     | VARCHAR(32)     |          | √        |            |                                                              |
| 3     | transaction\_id    | 微信支付订单号 | VARCHAR(32)     |          | √        |            |                                                              |
| 4     | trade\_type        | 交易类型       | VARCHAR(16)     |          |          |            | JSAPI-公众号支付 NATIVE-扫码支付 APP-APP支付 MICROPAY-付款码支付 MWEB-H5支付 FACEPAY-刷脸支付 |
| 5     | trade\_state       | 交易状态       | VARCHAR(32)     |          |          |            | SUCCESS-支付成功 REFUND-转入退款 NOTPAY-未支付 CLOSED-已关闭 REVOKED-已撤销（付款码支付） USERPAYING-用户支付中（付款码支付） PAYERROR-支付失败(其他原因，如银行返回失败) |
| 6     | trade\_state\_desc | 交易状态描述   | VARCHAR(255)    |          |          |            |                                                              |
| 7     | amount             | 订单总金额     | INT UNSIGNED    |          | √        |            | 单位：分                                                     |
| 8     | payer\_total       | 用户支付金额   | INT UNSIGNED    |          |          |            | 单位：分                                                     |
| 9     | success\_time      | 支付完成时间   | DATETIME        |          |          |            |                                                              |
| 10    | payer\_openid      | 支付者用户标识 | VARCHAR(128)    |          |          |            | 用户在直连商户appid下的唯一标识                              |
| 11    | create\_time       | 创建时间       | DATETIME        |          |          |            |                                                              |
| 12    | update\_time       | 更新时间       | DATETIME        |          |          |            |                                                              |

#### 系统模块

**sys\_user \[**系统用户**\]**

| **#** | **字段**     | **名称** | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | ------------ | -------- | ---------------- | -------- | -------- | ---------- | ------------- |
| 1     | id           |          | BIGINT UNSIGNED  | √        | √        |            |               |
| 2     | username     | 用户名   | VARCHAR(50)      |          | √        |            |               |
| 3     | password     | 密码     | VARCHAR(50)      |          | √        |            |               |
| 4     | name         | 真实姓名 | VARCHAR(100)     |          |          |            |               |
| 5     | sex          | 性别     | TINYINT UNSIGNED |          |          |            | 0-男 1-女     |
| 6     | birth        | 出身日期 | DATETIME         |          |          |            |               |
| 7     | email        | 邮箱     | VARCHAR(100)     |          |          |            |               |
| 8     | mobile       | 手机号   | VARCHAR(100)     |          |          |            |               |
| 9     | status       | 状态     | TINYINT UNSIGNED |          | √        | 1          | 0-禁用 1-正常 |
| 10    | create\_time | 创建时间 | DATETIME         |          |          |            |               |
| 11    | update\_time | 更新时间 | DATETIME         |          |          |            |               |

**sys\_role \[**角色**\]**

| **#** | **字段**     | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | -------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           |          | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | role\_name   | 角色名称 | VARCHAR(100)    |          | √        |            |              |
| 3     | role\_sign   | 角色标识 | VARCHAR(100)    |          |          |            |              |
| 4     | remark       | 备注     | VARCHAR(100)    |          |          |            |              |
| 5     | create\_time | 创建时间 | DATETIME        |          |          |            |              |
| 6     | update\_time | 更新时间 | DATETIME        |          |          |            |              |

**sys\_user\_role \[**用户与角色对应关系**\]**

| **#** | **字段**     | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | -------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           |          | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | user\_id     | 用户ID   | BIGINT UNSIGNED |          | √        |            |              |
| 3     | role\_id     | 角色ID   | BIGINT UNSIGNED |          | √        |            |              |
| 4     | create\_time | 创建时间 | DATETIME        |          |          |            |              |
| 5     | update\_time | 更新时间 | DATETIME        |          |          |            |              |

**sys\_menu \[**系统菜单**\]**

| **#** | **字段**     | **名称** | **数据类型**     | **主键** | **非空** | **默认值** | **备注说明**  |
| ----- | ------------ | -------- | ---------------- | -------- | -------- | ---------- | ------------- |
| 1     | id           |          | BIGINT UNSIGNED  | √        | √        |            |               |
| 2     | parent\_id   | 父菜单ID | BIGINT UNSIGNED  |          | √        | 0          | 一级菜单为0   |
| 3     | name         | 菜单名称 | VARCHAR(50)      |          | √        |            |               |
| 4     | url          | 菜单URL  | VARCHAR(200)     |          |          |            |               |
| 5     | type         | 类型     | TINYINT UNSIGNED |          | √        |            | 0-目录 1-菜单 |
| 6     | icon         | 菜单图标 | VARCHAR(50)      |          |          |            |               |
| 7     | sort         | 排序     | TINYINT UNSIGNED |          |          |            |               |
| 8     | create\_time | 创建时间 | DATETIME         |          |          |            |               |
| 9     | update\_time | 更新时间 | DATETIME         |          |          |            |               |

**sys\_role\_menu \[**角色与菜单对应关系**\]**

| **#** | **字段**     | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | -------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           |          | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | role\_id     | 角色ID   | BIGINT UNSIGNED |          | √        |            |              |
| 3     | menu\_id     | 菜单ID   | BIGINT UNSIGNED |          | √        |            |              |
| 4     | create\_time | 创建时间 | DATETIME        |          |          |            |              |
| 5     | update\_time | 更新时间 | DATETIME        |          |          |            |              |

**sys\_log \[**系统日志**\]**

| **#** | **字段**     | **名称** | **数据类型**    | **主键** | **非空** | **默认值** | **备注说明** |
| ----- | ------------ | -------- | --------------- | -------- | -------- | ---------- | ------------ |
| 1     | id           |          | BIGINT UNSIGNED | √        | √        |            |              |
| 2     | user\_id     | 用户id   | BIGINT UNSIGNED |          |          |            |              |
| 3     | username     | 用户名   | VARCHAR(50)     |          |          |            |              |
| 4     | operation    | 用户操作 | VARCHAR(50)     |          |          |            |              |
| 5     | time         | 响应时间 | INT UNSIGNED    |          |          |            |              |
| 6     | method       | 请求方法 | VARCHAR(200)    |          |          |            |              |
| 7     | params       | 请求参数 | VARCHAR(5000)   |          |          |            |              |
| 8     | ip           | IP地址   | VARCHAR(64)     |          |          |            |              |
| 9     | create\_time | 创建时间 | DATETIME        |          |          |            |              |



## 项目开发

### 开发环境

-   MySQL 8.0
-   Redis 7.0
-   Elasticsearch 8.2.0（选装）
-   RabbitMQ 3.10.2（选装）
-   XXL-JOB 2.3.1（选装）
-   JDK 17
-   Maven 3.8.5
-   IntelliJ IDEA 2021.3
-   Node 16.14

### IDEA 插件安装

使用 IntelliJ IDEA 开发的同学建议安装以下插件：

-   必装
    
    -   Alibaba Java Code Guidelines - 阿里巴巴 Java 代码规范
        
    -   SonarLint - 代码质量检测
        
    -   Save Actions - 代码自动格式化（[Java 代码格式](# Java 代码格式)）
        
    -   Git Commit Template - 使用规范模板创建 Git 提交消息（[Git 提交规范](#Git 提交规约)）
    
-   选装
    
    -   TONGYI Lingma - 基于通义大模型的智能编码辅助工具
        
    -   Translation - 翻译插件
        
    -   Maven Helper - 分析 Maven 依赖，解决 Jar 冲突
        
    -   EasyYapi - 帮助你导出文件中的 API 到 `yapi`/`postman`/`markdown` 或发起文件中的 API 请求
        
    -   Codota - 代码智能提示
        
    -   Search In Repository - 搜索 Maven 或者 NPM 的依赖信息
        
    -   CamelCase - 多种命名格式（下划线、驼峰等）之间切换
        
    -   Auto filling Java call arguments - 自动补全调用函数的参数
        
    -   GenerateO2O - 生成一个对象并自动填充另一个对象的值
        
    -   GenerateAllSetter - 一键调用一个对象的所有的set方法
        
    -   SequenceDiagram - 调用链路自动生成时序图
        
    -   Rainbow Brackets - 让你的括号变成不一样的颜色，防止错乱括号
        
    -   HighlightBracketPair - 括号开始和结尾，高亮显示
        
    -   Grep Console - 控制台日志 高亮
        
    -   Key promoter X - 鼠标操作的快捷键提示
        
    -   CodeGlance - 缩略图
        
    -   VisualGC - 实时垃圾回收监控
        
    -   arthas idea - java 在线诊断工具
        
    -   Alibaba Cloud Toolkit - 通过图形配置的方式连接到云端部署环境并将应用程序快速部署到云端
    
-   上班摸鱼
    
    -   Leetcode Editor IDEA 在线刷题
        
    -   GIdeaBrowser IDEA 内嵌 Web 浏览器
        

### 项目初始化

我们使用 Spring Initializr 来初始化我们的项目。

![Spring Initializr](pic/springbootinit.png)

操作步骤如下：

1.  导航到 [Spring Initializr](https://start.spring.io/)。该服务引入应用程序所需的所有依赖项，并自动完成大部分设置。
    
2.  选择 Gradle 或 Maven 以及要使用的语言。本项目选择 Maven 和 Java。
    
3.  选择 Spring Boot 的版本。本项目选择 3.0.0 版本。
    
4.  填写项目元数据。本项目选择 Java 17 版本。
    
5.  单击 ADD DEPENDENCIES 并选择项目依赖项。本项目选择的依赖如上图所示。
    
6.  单击 GENERATE，下载生成的 ZIP 文件，该文件是根据我们的选择来配置的 Spring Boot 应用程序存档。
    
7.  解压 ZIP 文件后导入我们的 IDE 中即可。
    

**注：如果我们的 IDE 具有 Spring Initializr 集成，可以直接从 IDE 中完成此过程**

### 项目配置和框架集成

#### 包结构创建

在项目 src/main/java 下面创建如下的包结构：

```
io
 +- github
     +- xxyopen   
        +- novel
            +- NovelApplication.java -- 项目启动类
            |
            +- core -- 项目核心模块，包括各种工具、配置和常量等
            |   +- common -- 业务无关的通用模块
            |   |   +- exception -- 通用异常处理
            |   |   +- constant -- 通用常量   
            |   |   +- req -- 通用请求数据格式封装，例如分页请求数据  
            |   |   +- resp -- 接口响应工具及响应数据格式封装 
            |   |   +- util -- 通用工具   
            |   | 
            |   +- auth -- 用户认证授权相关
            |   +- config -- 业务相关配置
            |   +- constant -- 业务相关常量         
            |   +- filter -- 过滤器 
            |   +- interceptor -- 拦截器
            |   +- task -- 定时任务
            |   +- util -- 业务相关工具 
            |   +- wrapper -- 装饰器
            |
            +- dto -- 数据传输对象，包括对各种 Http 请求和响应数据的封装
            |   +- req -- Http 请求数据封装
            |   +- resp -- Http 响应数据封装
            |
            +- dao -- 数据访问层，与底层 MySQL 进行数据交互
            +- manager -- 通用业务处理层，对第三方平台封装、对 Service 层通用能力的下沉以及对多个 DAO 的组合复用 
            +- service -- 相对具体的业务逻辑服务层  
            +- controller -- 主要是处理各种 Http 请求，各类基本参数校验，或者不复用的业务简单处理，返回 JSON 数据等
            |   +- front -- 小说门户相关接口
            |   +- author -- 作家管理后台相关接口
            |   +- admin -- 平台管理后台相关接口
            |   +- app -- app 接口
            |   +- applet -- 小程序接口
            |   +- open -- 开放接口，供第三方调用 
```

#### 通用请求/响应数据格式封装

1.  在`io.github.xxyopen.novel.core.common.req`包下创建分页请求数据格式封装类：

```java
/**
 * 分页请求数据格式封装，所有分页请求的 Dto 类都应继承该类
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
@Data
public class PageReqDto {

    /**
     * 请求页码，默认第 1 页
     * */
    private int pageNum = 1;

    /**
     * 每页大小，默认每页 10 条
     * */
    private int pageSize = 10;

    /**
     * 是否查询所有，默认不查所有
     * 为 true 时，pageNum 和 pageSize 无效
     * */
    private boolean fetchAll = false;
    
}
```

2.  在`io.github.xxyopen.novel.core.common.resp`包下创建分页响应数据格式封装类：

```java
/**
 * 分页响应数据格式封装
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
@Getter
public class PageRespDto<T> {

    /**
     * 页码
     */
    private final long pageNum;

    /**
     * 每页大小
     */
    private final long pageSize;

    /**
     * 总记录数
     */
    private final long total;

    /**
     * 分页数据集
     */
    private final List<? extends T> list;

    /**
     * 该构造函数用于通用分页查询的场景
     * 接收普通分页数据和普通集合
     */
    public PageRespDto(long pageNum, long pageSize, long total, List<T> list) {
        this.pageNum = pageNum;
        this.pageSize = pageSize;
        this.total = total;
        this.list = list;
    }

    public static <T> PageRespDto<T> of(long pageNum, long pageSize, long total, List<T> list) {
        return new PageRespDto<>(pageNum, pageSize, total, list);
    }

    /**
     * 获取分页数
     * */
    public long getPages() {
        if (this.pageSize == 0L) {
            return 0L;
        } else {
            long pages = this.total / this.pageSize;
            if (this.total % this.pageSize != 0L) {
                ++pages;
            }

            return pages;
        }
    }
}
```

#### Rest 接口响应工具及响应数据格式封装

1.  在`io.github.xxyopen.novel.core.common.constant`包下创建错误码枚举类：

```java
/**
 * 错误码枚举类。
 *
 * 错误码为字符串类型，共 5 位，分成两个部分：错误产生来源+四位数字编号。
 * 错误产生来源分为 A/B/C， A 表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付
 * 超时等问题； B 表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题； C 表示错误来源
 * 于第三方服务，比如 CDN 服务出错，消息投递超时等问题；四位数字编号从 0001 到 9999，大类之间的
 * 步长间距预留 100。
 *
 * 错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。
 * 在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码。
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
@Getter
@AllArgsConstructor
public enum ErrorCodeEnum {

    /**
     * 正确执行后的返回
     * */
    OK("00000","一切 ok"),

    /**
     * 一级宏观错误码，用户端错误
     * */
    USER_ERROR("A0001","用户端错误"),

    /**
     * 二级宏观错误码，用户注册错误
     * */
    USER_REGISTER_ERROR("A0100","用户注册错误"),

    /**
     * 二级宏观错误码，用户未同意隐私协议
     * */
    USER_NO_AGREE_PRIVATE_ERROR("A0101","用户未同意隐私协议"),

    /**
     * 二级宏观错误码，注册国家或地区受限
     * */
    USER_REGISTER_AREA_LIMIT_ERROR("A0102","注册国家或地区受限"),

    /**
     * 二级宏观错误码，用户请求参数错误
     * */
    USER_REQUEST_PARAM_ERROR("A0400","用户请求参数错误"),

    // ...省略若干用户端二级宏观错误码

    /**
     * 一级宏观错误码，系统执行出错
     * */
    SYSTEM_ERROR("B0001","系统执行出错"),

    /**
     * 二级宏观错误码，系统执行超时
     * */
    SYSTEM_TIMEOUT_ERROR("B0100","系统执行超时"),

    // ...省略若干系统执行二级宏观错误码

    /**
     * 一级宏观错误码，调用第三方服务出错
     * */
    THIRD_SERVICE_ERROR("C0001","调用第三方服务出错"),

    /**
     * 一级宏观错误码，中间件服务出错
     * */
    MIDDLEWARE_SERVICE_ERROR("C0100","中间件服务出错")

    // ...省略若干三方服务调用二级宏观错误码    

    ;

    /**
     * 错误码
     * */
    private String code;

    /**
     * 中文描述
     * */
    private String message;

}
```

2.  在`io.github.xxyopen.novel.core.common.resp`包下创建 Http Rest 响应工具及数据格式封装类：

```java
/**
 * Http Rest 响应工具及数据格式封装
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
@Getter
public class RestResp<T> {

    /**
     * 响应码
     */
    private String code;

    /**
     * 响应消息
     */
    private String message;

    /**
     * 响应数据
     */
    private T data;

    private RestResp() {
        this.code = ErrorCodeEnum.OK.getCode();
        this.message = ErrorCodeEnum.OK.getMessage();
    }

    private RestResp(ErrorCodeEnum errorCode) {
        this.code = errorCode.getCode();
        this.message = errorCode.getMessage();
    }

    private RestResp(T data) {
        this.data = data;
    }

    /**
     * 业务处理成功,无数据返回
     */
    public static RestResp<Void> ok() {
        return new RestResp<>();
    }

    /**
     * 业务处理成功，有数据返回
     */
    public static <T> RestResp<T> ok(T data) {
        return new RestResp<>(data);
    }

    /**
     * 业务处理失败
     */
    public static RestResp<Void> fail(ErrorCodeEnum errorCode) {
        return new RestResp<>(errorCode);
    }

    /**
     * 系统错误
     */
    public static RestResp<Void> error() {
        return new RestResp<>(ErrorCodeEnum.SYSTEM_ERROR);
    }

    /**
     * 判断是否成功
     */
    public boolean isOk() {
        return Objects.equals(this.code, ErrorCodeEnum.OK.getCode());
    }
    
}
```

#### 通用异常处理

在 Spring 3.2 中，新增了 [@ControllerAdvice](https://docs.spring.io/spring-framework/docs/6.0.0-SNAPSHOT/javadoc-api/org/springframework/web/bind/annotation/ControllerAdvice.html) 注解，用于定义适用于所有 @RequestMapping 方法的 @ExceptionHandler、@InitBinder 和 @ModelAttribute 方法。Spring Boot 默认情况下会映射到 /error 进行异常处理，但是提示十分不友好。我们可以使用该注解定义 @ExceptionHandler 方法来捕获 Controller 抛出的通用异常，并统一进行处理。

1.  在`io.github.xxyopen.novel.core.common.exception`包下创建自定义业务异常类：

```java
/**
 * 自定义业务异常，用于处理用户请求时，业务错误时抛出
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
@EqualsAndHashCode(callSuper = true)
@Data
public class BusinessException extends RuntimeException {

    private final ErrorCodeEnum errorCodeEnum;

    public BusinessException(ErrorCodeEnum errorCodeEnum) {
        // 不调用父类 Throwable的fillInStackTrace() 方法生成栈追踪信息，提高应用性能
        // 构造器之间的调用必须在第一行
        super(errorCodeEnum.getMessage(), null, false, false);
        this.errorCodeEnum = errorCodeEnum;
    }

}
```

2.  在`io.github.xxyopen.novel.core.common.exception`包下创建通用异常处理器，处理系统异常、数据校验异常和我们自定义的业务异常：

```java
/**
 * 通用的异常处理器
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
@Slf4j
@RestControllerAdvice
public class CommonExceptionHandler {

    /**
     * 处理数据校验异常
     * */
    @ExceptionHandler(BindException.class)
    public RestResp<;Void> handlerBindException(BindException e){
        log.error(e.getMessage(),e);
        return RestResp.fail(ErrorCodeEnum.USER_REQUEST_PARAM_ERROR);
    }

    /**
     * 处理业务异常
     * */
    @ExceptionHandler(BusinessException.class)
    public RestResp<;Void> handlerBusinessException(BusinessException e){
        log.error(e.getMessage(),e);
        return RestResp.fail(e.getErrorCodeEnum());
    }

    /**
     * 处理系统异常
     * */
    @ExceptionHandler(Exception.class)
    public RestResp<;Void> handlerException(Exception e){
        log.error(e.getMessage(),e);
        return RestResp.error();
    }

}
```

#### 常量类创建

1.  在`io.github.xxyopen.novel.core.common.constant`包下创建通用常量类和 API 路由常量类

```java
/**
 * 通用常量
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
public class CommonConsts {

    /**
     * 是
     * */
    public static final Integer YES = 1;

    /**
     * 否
     * */
    public static final Integer NO = 0;

    /**
     * 性别常量
     * */
    public enum SexEnum{

        /**
         * 男
         * */
        MALE(0,"男"),

        /**
         * 女
         * */
        FEMALE(1,"女");

        SexEnum(int code,String desc){
            this.code = code;
            this.desc = desc;
        }

        private int code;
        private String desc;

        public int getCode() {
            return code;
        }

        public String getDesc() {
            return desc;
        }

    }

    // ...省略若干常量
}
```

```java
/**
 * API 路由常量
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
public class ApiRouterConsts {

    /**
     * API请求路径前缀
     */
    String API_URL_PREFIX = "/api";

    /**
     * 前台门户系统请求路径前缀
     */
    String API_FRONT_URL_PREFIX = API_URL_PREFIX + "/front";

    /**
     * 作家管理系统请求路径前缀
     */
    String API_AUTHOR_URL_PREFIX = API_URL_PREFIX + "/author";

    /**
     * 平台后台管理系统请求路径前缀
     */
    String API_ADMIN_URL_PREFIX = API_URL_PREFIX + "/admin";

    /**
     * 首页模块请求路径前缀
     * */
    String HOME_URL_PREFIX = "/home";

    /**
     * 小说模块请求路径前缀
     * */
    String BOOK_URL_PREFIX = "/book";

    /**
     * 会员模块请求路径前缀
     * */
    String USER_URL_PREFIX = "/user";

    /**
     * 前台门户首页API请求路径前缀
     */
    String API_FRONT_HOME_URL_PREFIX = API_FRONT_URL_PREFIX + HOME_URL_PREFIX;

    /**
     * 前台门户小说相关API请求路径前缀
     */
    String API_FRONT_BOOK_URL_PREFIX = API_FRONT_URL_PREFIX + BOOK_URL_PREFIX;

    /**
     * 前台门户会员相关API请求路径前缀
     */
    String API_FRONT_USER_URL_PREFIX = API_FRONT_URL_PREFIX + USER_URL_PREFIX;

    // ...省略若干常量

}
```

2.  在`io.github.xxyopen.novel.core.constant`包下创建缓存常量类

```java
/**
 * 缓存相关常量
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
public class CacheConsts {

    /**
     * 本项目 Redis 缓存前缀
     * */
    public static final String REDIS_CACHE_PREFIX = "Cache::Novel::";


    /**
     * Caffeine 缓存管理器
     * */
    public static final String CAFFEINE_CACHE_MANAGER = "caffeineCacheManager";

    /**
     * Redis 缓存管理器
     * */
    public static final String REDIS_CACHE_MANAGER = "redisCacheManager";

    /**
     * 首页小说推荐缓存
     * */
    public static final String HOME_BOOK_CACHE_NAME = "homeBookCache";

    /**
     * 首页友情链接缓存
     * */
    public static final String HOME_FRIEND_LINK_CACHE_NAME = "homeFriendLinkCache";

    /**
     * 缓存配置常量
     */
    public enum CacheEnum {

        HOME_BOOK_CACHE(1,HOME_BOOK_CACHE_NAME,0,1),

        HOME_FRIEND_LINK_CACHE(2,HOME_FRIEND_LINK_CACHE_NAME,1000,1)

        ;

        /**
         * 缓存类型 0-本地 1-本地和远程 2-远程
         */
        private int type;
        /**
         * 缓存的名字
         */
        private String name;
        /**
         * 失效时间（秒） 0-永不失效
         */
        private int ttl;
        /**
         * 最大容量
         */
        private int maxSize;

        CacheEnum(int type, String name, int ttl, int maxSize) {
            this.type = type;
            this.name = name;
            this.ttl = ttl;
            this.maxSize = maxSize;
        }

        public boolean isLocal() {
            return type <;= 1;
        }

        public boolean isRemote() {
            return type >= 1;
        }

        public String getName() {
            return name;
        }

        public int getTtl() {
            return ttl;
        }

        public int getMaxSize() {
            return maxSize;
        }

    }

}
```

#### 日志配置

Spring Boot 默认使用的是 Logback 日志实现，会自动读取类路径下的 logback-spring.xml, logback-spring.groovy, logback.xml, 或 logback.groovy 配置文件。

我们在项目 src/resource 下面添加如下内容的日志配置文件 logback-spring.xml 即可：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- 彩色日志依赖的渲染类 -->
    <conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter"/>
    <conversionRule conversionWord="wex"
                    converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/>
    <conversionRule conversionWord="wEx"
                    converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/>
    <!-- 彩色日志格式 -->
    <property name="CONSOLE_LOG_PATTERN"
              value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/>

    <!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,%i索引【从数字0开始递增】,,, -->
    <!-- appender是configuration的子节点，是负责写日志的组件。 -->
    <!-- ConsoleAppender：把日志输出到控制台 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <!--
            <pattern>%d %p (%file:%line\)- %m%n</pattern>
             -->
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
            <!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 -->
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 -->
    <!-- 以下的大概意思是：1.先按日期存日志，日期变了，将前一天的日志文件名重命名为XXX%日期%索引，新的日志仍然是demo.log -->
    <!-- 2.如果日期没有发生变化，但是当前日志的文件大小超过1KB时，对当前日志进行分割 重命名 -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">

        <File>logs/novel.log</File>
        <!-- rollingPolicy:当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名。 -->
        <!-- TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 活动文件的名字会根据fileNamePattern的值，每隔一段时间改变一次 -->
            <!-- 文件名：logs/demo.2017-12-05.0.log -->
            <fileNamePattern>logs/debug.%d.%i.log</fileNamePattern>
            <!-- 每产生一个日志文件，该日志文件的保存期限为30天 -->
            <maxHistory>30</maxHistory>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <!-- maxFileSize:这是活动文件的大小，默认值是10MB，测试时可改成1KB看效果 -->
                <maxFileSize>10MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <!-- pattern节点，用来设置日志的输入格式 -->
            <pattern>
                %d %p (%file:%line\)- %m%n
            </pattern>
            <!-- 记录日志的编码:此处设置字符集 - -->
            <charset>UTF-8</charset>
        </encoder>
    </appender>
    <springProfile name="dev">
        <!-- ROOT 日志级别 -->
        <root level="INFO">
            <appender-ref ref="STDOUT"/>
        </root>
        <!-- 指定项目中某个包，当有日志操作行为时的日志记录级别 -->
        <!-- com.maijinjie.springboot 为根包，也就是只要是发生在这个根包下面的所有日志操作行为的权限都是DEBUG -->
        <!-- 级别依次为【从高到低】：FATAL > ERROR > WARN > INFO > DEBUG > TRACE -->
        <logger name="io.github.xxyopen" level="DEBUG" additivity="false">
            <appender-ref ref="STDOUT"/>
        </logger>
    </springProfile>

    <springProfile name="prod">
        <!-- ROOT 日志级别 -->
        <root level="INFO">
            <appender-ref ref="STDOUT"/>
            <appender-ref ref="FILE"/>
        </root>
        <!-- 指定项目中某个包，当有日志操作行为时的日志记录级别 -->
        <!-- com.maijinjie.springboot 为根包，也就是只要是发生在这个根包下面的所有日志操作行为的权限都是DEBUG -->
        <!-- 级别依次为【从高到低】：FATAL > ERROR > WARN > INFO > DEBUG > TRACE -->
        <logger name="io.github.xxyopen" level="ERROR" additivity="false">
            <appender-ref ref="STDOUT"/>
            <appender-ref ref="FILE"/>
        </logger>
    </springProfile>
</configuration>
```

#### 跨域配置

跨域是指浏览器从一个域名的网页去请求另一个域名的资源时，域名、端口、协议任一不同，都是跨域。在前后端分离的模式下，前后端的域名是不一致的，此时就会发生跨域访问问题。

跨域是出于浏览器的同源策略限制，同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。

我们可以通过前端配置、后端配置或 nginx 配置来解决跨域问题。

如果选择前端配置，我们可以使用 node 中间件 proxy 配置跨域，前端通过 node proxy 来转发我们的接口请求，和浏览器直接打交道的是 node proxy，这样可以避免浏览器的同源策略。配置示例如下：

```
proxy: {
  '/api': {
    target: 'http://localhost:8888',
    // 请求改变源，此时 nginx 可以获取到真实的请求 ip
    changeOrigin: true
  }
}
```

如果通过 nginx 配置来解决跨域问题，我们在配置 location 路径转发时需要加上如下的配置：

```
# 允许的请求头
add_header 'Access-Control-Allow-Methods' 'GET,OPTIONS,POST,PUT,DELETE' always;
add_header 'Access-Control-Allow-Credentials' 'true' always;
add_header 'Access-Control-Allow-Origin' '$http_origin' always;
add_header Access-Control-Allow-Headers $http_access_control_request_headers;
add_header Access-Control-Max-Age 3600;
# 头转发
proxy_set_header Host $host;
proxy_set_header X-Real-Ip $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_connect_timeout 1000;
proxy_read_timeout 1000;
# 跨域配置
if ($request_method = OPTIONS ) { return 200; }
```

因为我们项目的侧重点在后端，而且 Spring MVC 提供了跨域解决方案（[CORS](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing)）的支持。所以我们这里通过后端配置来解决跨域问题。

首先我们需要在 application.yml 配置文件中添加跨域相关的配置：

```yaml
# 项目配置
novel:
  # 跨域配置
  cors:
    # 允许跨域的域名
    allow-origins:
      - http://localhost:1024
      - http://localhost:8080
```

然后在`io.github.xxyopen.novel.core.config`包下创建 CorsProperties 类来绑定 CORS 配置属性:

```java
/**
 * 跨域配置属性
 *
 * @author xiongxiaoyang
 * @date 2022/5/17
 */
@ConfigurationProperties(prefix = "novel.cors")
@Data
public class CorsProperties {

    /**
     * 允许跨域的域名
     * */
    private List<String> allowOrigins;
}
```

最后在`io.github.xxyopen.novel.core.config`包下增加如下的 CORS 配置类：

```java
/**
 * 跨域配置
 *
 * @author xiongxiaoyang
 * @date 2022/5/13
 */
@Configuration
@EnableConfigurationProperties(CorsProperties.class)
@RequiredArgsConstructor
public class CorsConfig {

    private final CorsProperties corsProperties;

    @Bean
    public CorsFilter corsFilter() {
        CorsConfiguration config = new CorsConfiguration();
        // 允许的域,不要写*，否则cookie就无法使用了
        for (String allowOrigin : corsProperties.getAllowOrigins()) {
            config.addAllowedOrigin(allowOrigin);
        }
        // 允许的头信息
        config.addAllowedHeader("*");
        // 允许的请求方式
        config.addAllowedMethod("*");
        // 是否允许携带Cookie信息
        config.setAllowCredentials(true);

        UrlBasedCorsConfigurationSource configurationSource = new UrlBasedCorsConfigurationSource();
        // 添加映射路径，拦截一切请求
        configurationSource.registerCorsConfiguration("/**",config);
        return new CorsFilter(configurationSource);
    }
    
}
```

#### Mybatis 增强工具 MyBatis-Plus 集成

[MyBatis-Plus](https://baomidou.com/)是一个[MyBatis](https://www.mybatis.org/mybatis-3)的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。我们可以按照如下步骤集成到我们的项目中：

1.  添加 mybatis-plus 的启动器依赖

```xml
<dependency>
    <groupId>com.baomidou</groupId>
    <artifactId>mybatis-plus-boot-starter</artifactId>
    <version>3.5.3</version>
</dependency>
```

2.  配置 MapperScan 注解

```java
@SpringBootApplication
@MapperScan("io.github.xxyopen.novel.dao.mapper")
public class NovelApplication {

	public static void main(String[] args) {
		SpringApplication.run(NovelApplication.class, args);
	}

}
```

3.  因为我们系统涉及分页数据查询，所以我们还需要在`io.github.xxyopen.novel.core.config`包下配置 mybatis-plus 的分页插件：

```java
/**
 * Mybatis-Plus 配置类
 *
 * @author xiongxiaoyang
 * @date 2022/5/16
 */
@Configuration
public class MybatisPlusConfig {

    /**
     * 分页插件
     */
    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor() {
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));
        return interceptor;
    }

}
```

4.  数据源配置

YAML 是 JSON 的超集，一种用于指定分层配置数据的便捷格式。本项目中我们统一使用 YAML 格式的配置文件，所以先将 resources 目录下的 application.properties 文件重命名为 application.yml，

然后在 application.yml 配置文件中加入以下数据源配置：

```yaml
spring:
  datasource:
    url: jdbc:mysql://localhost:3306/novel?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=Asia/Shanghai
    username: root
    password: test123456
```

**注：根据实际的数据库环境来修改相应的IP、端口号、数据库名、用户名和密码**

#### 代码生成器 Mybatis-Plus-Generator 集成

1.  添加相关依赖

```xml
<dependency>
    <groupId>com.baomidou</groupId>
    <artifactId>mybatis-plus-generator</artifactId>
    <version>${mybatis-plus.version}</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>org.apache.velocity</groupId>
    <artifactId>velocity-engine-core</artifactId>
    <version>2.3</version>
    <scope>test</scope>
</dependency>
```

2.  在 test/resources/templates 下面创建以下模版文件

![gen-templates](pic/mybatisplusgen.png)

3.  在 test/java 下面创建代码生成器类

```java
/**
 * 代码生成器
 *
 * @author xiongxiaoyang
 * @date 2022/5/11
 */
public class Generator {

    private static final String USERNAME = System.getenv().get("USER");

    /**
     * 项目信息
     */
    private static final String PROJECT_PATH = System.getProperty("user.dir");
    private static final String JAVA_PATH = "/src/main/java";
    private static final String RESOURCE_PATH = "/src/main/resources";
    private static final String BASE_PACKAGE = "io.github.xxyopen.novel";

    /**
     * 数据库信息
     */
    private static final String DATABASE_IP = "127.0.0.1";
    private static final String DATABASE_PORT = "3306";
    private static final String DATABASE_NAME = "novel";
    private static final String DATABASE_USERNAME = "root";
    private static final String DATABASE_PASSWORD = "test123456";


    public static void main(String[] args) {

        // 传入需要生成的表名，多个用英文逗号分隔，所有用 all 表示
        genCode("sys_user");

    }


    /**
     * 代码生成
     */
    private static void genCode(String tables) {

        // 全局配置
        FastAutoGenerator.create(String.format("jdbc:mysql://%s:%s/%s?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=Asia/Shanghai", DATABASE_IP, DATABASE_PORT, DATABASE_NAME), DATABASE_USERNAME, DATABASE_PASSWORD)
                .globalConfig(builder -> {
                    builder.author(USERNAME) // 设置作者
                            .fileOverride()
                            // kotlin
                            //.enableSwagger() // 开启 swagger 模式
                            .fileOverride() // 覆盖已生成文件
                            .commentDate("yyyy/MM/dd")
                            .outputDir(PROJECT_PATH + JAVA_PATH); // 指定输出目录
                })
                // 包配置
                .packageConfig(builder -> builder.parent(BASE_PACKAGE) // 设置父包名
                        .entity("dao.entity")
                        .service("service")
                        .serviceImpl("service.impl")
                        .mapper("dao.mapper")
                        .controller("controller.front")
                        .pathInfo(Collections.singletonMap(OutputFile.mapperXml, PROJECT_PATH + RESOURCE_PATH + "/mapper")))
                // 模版配置
                .templateConfig(builder -> builder.disable(TemplateType.SERVICE)
                        .disable(TemplateType.SERVICEIMPL)
                        .disable(TemplateType.CONTROLLER))
                // 策略配置
                .strategyConfig(builder -> builder.addInclude(getTables(tables)) // 设置需要生成的表名
                        .controllerBuilder()
                        .enableRestStyle()
                        .serviceBuilder()
                        .formatServiceFileName("%sService")
                ) // 开启生成@RestController 控制器
                //.templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker引擎模板，默认的是Velocity引擎模板
                .execute();

    }

    /**
     * 处理 all 和多表情况
     */
    protected static List<String> getTables(String tables) {
        return "all".equals(tables) ? Collections.emptyList() : Arrays.asList(tables.split(","));
    }

}
```

4.  修改 Generator 类中数据库相关配置，选择我们需要创建的表名（all)，运行 main 方法生成代码

#### 本地缓存 Caffeine 集成和配置

Caffeine 是 Java 8 对 Google Guava 缓存的重写，是一个提供了近乎最佳命中率的高性能的缓存库。我们按照如下步骤集成和配置：

1.  添加 spring-boot-starter-cache 依赖

使用 spring-boot-starter-cache “Starter” 可以快速添加基本缓存依赖项。 starter 引入了 spring-context-support。如果我们手动添加依赖项，则必须包含 spring-context-support 才能使用 JCache 或 Caffeine 支持。

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>
```

2.  添加 caffeine 依赖

```xml
<dependency>
    <groupId>com.github.ben-manes.caffeine</groupId>
    <artifactId>caffeine</artifactId>
</dependency>
```

3.  自定义缓存管理器

```java
/**
    * Caffeine 缓存管理器
    */
@Bean
public CacheManager caffeineCacheManager() {
    SimpleCacheManager cacheManager = new SimpleCacheManager();

    List<CaffeineCache> caches = new ArrayList<>(CacheConsts.CacheEnum.values().length);
    for (CacheConsts.CacheEnum c : CacheConsts.CacheEnum.values()) {
        if (c.isLocal()) {
            Caffeine<Object, Object> caffeine = Caffeine.newBuilder().recordStats().maximumSize(c.getMaxSize());
            if (c.getTtl() > 0) {
                caffeine.expireAfterWrite(Duration.ofSeconds(c.getTtl()));
            }
            caches.add(new CaffeineCache(c.getName(), caffeine.build()));
        }
    }

    cacheManager.setCaches(caches);
    return cacheManager;
}
```

4.  使用 @EnableCaching 注解开启缓存

```java
@SpringBootApplication
@MapperScan("io.github.xxyopen.novel.dao.mapper")
@EnableCaching
@Slf4j
public class NovelApplication {

	public static void main(String[] args) {
		SpringApplication.run(NovelApplication.class, args);
	}

	@Bean
	public CommandLineRunner commandLineRunner(ApplicationContext context){
		return args -> {
			Map<String, CacheManager> beans = context.getBeansOfType(CacheManager.class);
			log.info("加载了如下缓存管理器：");
			beans.forEach((k,v)->{
				log.info("{}:{}",k,v.getClass().getName());
				log.info("缓存：{}",v.getCacheNames());
			});

		};
	}

}
```

这样我们就可以使用 Spring Cache 的注解（例如 @Cacheable）开发了。

#### 分布式缓存 Redis 集成和配置

本地缓存虽然有着访问速度快的优点，但无法进行大数据的存储。并且当我们集群部署多个服务节点，或者后期随着业务发展进行服务拆分后，没法共享缓存和保证缓存数据的一致性。 本地缓存的数据还会随应用程序的重启而丢失，这样对于需要持久化的数据满足不了需求，还会导致重启后数据库瞬时压力过大。

所以本地缓存一般适合于缓存只读数据，如统计类数据，或者每个部署节点独立的数据。其它情况就需要用到分布式缓存了。

分布式缓存的集成步骤和本地缓存基本差不多，除了替换 caffeine 的依赖项为我们 redis 的依赖和配置上我们自定义的 redis 缓存管理器外，还要在配置文件中加入 redis 的连接配置：

1.  加入依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

2.  配置 redis 缓存管理器

```java
/**
 * 缓存配置类
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
@Configuration
public class CacheConfig {

    /**
     * Caffeine 缓存管理器
     */
    @Bean
    @Primary
    public CacheManager caffeineCacheManager() {
        SimpleCacheManager cacheManager = new SimpleCacheManager();

        List<CaffeineCache> caches = new ArrayList<>(CacheConsts.CacheEnum.values().length);
        for (CacheConsts.CacheEnum c : CacheConsts.CacheEnum.values()) {
            if (c.isLocal()) {
                Caffeine<Object, Object> caffeine = Caffeine.newBuilder().recordStats().maximumSize(c.getMaxSize());
                if (c.getTtl() > 0) {
                    caffeine.expireAfterWrite(Duration.ofSeconds(c.getTtl()));
                }
                caches.add(new CaffeineCache(c.getName(), caffeine.build()));
            }
        }

        cacheManager.setCaches(caches);
        return cacheManager;
    }

    /**
     * Redis 缓存管理器
     */
    @Bean
    public CacheManager redisCacheManager(RedisConnectionFactory connectionFactory) {
        RedisCacheWriter redisCacheWriter = RedisCacheWriter.nonLockingRedisCacheWriter(connectionFactory);

        RedisCacheConfiguration defaultCacheConfig = RedisCacheConfiguration.defaultCacheConfig()
                .disableCachingNullValues().prefixCacheNameWith(CacheConsts.REDIS_CACHE_PREFIX);

        Map<String, RedisCacheConfiguration> cacheMap = new LinkedHashMap<>(CacheConsts.CacheEnum.values().length);
        for (CacheConsts.CacheEnum c : CacheConsts.CacheEnum.values()) {
            if (c.isRemote()) {
                if (c.getTtl() > 0) {
                    cacheMap.put(c.getName(), RedisCacheConfiguration.defaultCacheConfig().disableCachingNullValues()
                            .prefixCacheNameWith(CacheConsts.REDIS_CACHE_PREFIX).entryTtl(Duration.ofSeconds(c.getTtl())));
                } else {
                    cacheMap.put(c.getName(), RedisCacheConfiguration.defaultCacheConfig().disableCachingNullValues()
                            .prefixCacheNameWith(CacheConsts.REDIS_CACHE_PREFIX));
                }
            }
        }

        RedisCacheManager redisCacheManager = new RedisCacheManager(redisCacheWriter, defaultCacheConfig, cacheMap);
        redisCacheManager.setTransactionAware(true);
        redisCacheManager.initializeCaches();
        return redisCacheManager;
    }

}
```

3.  application.yml 中加入 redis 连接配置信息

```yaml
spring:
  data:
    # Redis 配置
    redis:
      host: 127.0.0.1
      port: 6379
      password: 123456
```

#### 搜索引擎 Elasticsearch 集成与配置

##### 介绍

Elastic Stack 是一个可以帮助我们构建搜索体验、解决问题并取得成功的搜索平台。核心产品包括 Elasticsearch、Kibana、Beats 和 Logstash（也称为 [ELK Stack](https://www.elastic.co/cn/what-is/elk-stack)）等等。能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。

Elasticsearch 和 Kibana 都是在免费开源的基础上构建而成，适用于各种各样的用例，从日志开始，到能够想到的任何项目，无一不能胜任。

Elasticsearch 是一个基于 JSON 的分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储数据，帮助发现意料之中以及意料之外的情况。

Kibana 是一个免费且开放的用户界面，能够对 Elasticsearch 数据进行可视化，并在 Elastic Stack 中进行导航。我们可以进行各种操作，从跟踪查询负载，到理解请求如何流经整个应用，都能轻松完成。

##### 集成与配置



**安装分词器**

```
docker cp ./elasticsearch-analysis-ik-8.6.2.zip novel-elasticsearch:/usr/share/elasticsearch/plugins/
docker exec -it novel-elasticsearch /bin/bash
cd plugins
mkdir ik
unzip elasticsearch-analysis-ik-8.6.2.zip -d ik
rm elasticsearch-analysis-ik-8.6.2.zip
cd /usr/share/elasticsearch/bin
elasticsearch-plugin list
exit
docker restart novel-elasticsearch
```



1.  Elasticsearch 和 Kibana 安装，如果不想在本地安装 Elasticsearch 和 Kibana，可以使用官方提供的免费试用版 [Elastic Cloud](https://www.elastic.co/cn/cloud/?elektra=home&storm=cloud)
    
2.  Kibana 中创建索引:
    

```sh
PUT /book
{
  "mappings" : {
    "properties" : {
      "id" : {
        "type" : "long"
      },
      "authorId" : {
        "type" : "long"
      },
      "authorName" : {
        "type" : "text",
        "analyzer": "ik_smart"
      },
      "bookName" : {
        "type" : "text",
        "analyzer": "ik_smart"
      },
      "bookDesc" : {
        "type" : "text",
        "analyzer": "ik_smart"
      },
      "bookStatus" : {
        "type" : "short"
      },
      "categoryId" : {
        "type" : "integer"
      },
      "categoryName" : {
        "type" : "text",
        "analyzer": "ik_smart"
      },
      "lastChapterId" : {
        "type" : "long"
      },
      "lastChapterName" : {
        "type" : "text",
        "analyzer": "ik_smart"
      },
      "lastChapterUpdateTime" : {
        "type": "long"
      },
      "picUrl" : {
        "type" : "keyword",
        "index" : false,
        "doc_values" : false
      },
      "score" : {
        "type" : "integer"
      },
      "wordCount" : {
        "type" : "integer"
      },
      "workDirection" : {
        "type" : "short"
      },
      "visitCount" : {
        "type": "long"
      }
    }
  }
}
```

3.  项目添加如下依赖：

```xml
<dependencies>

    <dependency>
      <groupId>co.elastic.clients</groupId>
      <artifactId>elasticsearch-java</artifactId>
      <version>8.2.0</version>
    </dependency>

    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>2.12.3</version>
    </dependency>

</dependencies>
```

4.  在 application.yml 中配置如下连接信息：

```yaml
spring:
  elasticsearch:
    uris:
      - https://my-deployment-ce7ca3.es.us-central1.gcp.cloud.es.io:9243
    username: elastic
    password: qTjgYVKSuExX
```

5.  配置 [JacksonJsonpMapper](#全新的-elasticsearch-java-api-client):

```java
/**
 * elasticsearch 相关配置
 *
 * @author xiongxiaoyang
 * @date 2022/5/23
 */
@Configuration
public class EsConfig {

    /**
     * 解决 ElasticsearchClientConfigurations 修改默认 ObjectMapper 配置的问题
     */
    @Bean
    JacksonJsonpMapper jacksonJsonpMapper() {
        return new JacksonJsonpMapper();
    }

}
```

#### Spring AMQP 集成与配置

##### 介绍

AMQP（高级消息队列协议）是一个异步消息传递所使用的应用层协议规范，为面向消息的中间件设计，不受产品和开发语言的限制. Spring AMQP 将核心 Spring 概念应用于基于 AMQP 消息传递解决方案的开发。

RabbitMQ 是基于 AMQP 协议的轻量级、可靠、可扩展、可移植的消息中间件，Spring 使用 RabbitMQ 通过 AMQP 协议进行通信。Spring Boot 为通过 RabbitMQ 使用 AMQP 提供了多种便利，包括 spring-boot-starter-amqp “Starter”。

##### 集成与配置

1.  可通过如下 Docker 命令 安装 RabbiMQ：

```sh
 docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.10-management
```

2.  登录 RabbiMQ 的 web 管理界面，创建虚拟主机`novel`:

![RabbitMQ](pic/rabbitmq.png)

3.  项目中加入如下的 maven 依赖：

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

4.  在 application.yml 配置文件中加入 RabbitMQ 的连接配置：

```yaml
spring:
  rabbitmq:
    addresses: "amqp://guest:guest@47.106.243.172"
    virtual-host: novel
    template:
      retry:
        # 开启重试
        enabled: true
        # 最大重试次数
        max-attempts: 3
        # 第一次和第二次重试之间的持续时间
        initial-interval: "3s"
```

5.  在 Spring Beans 中注入 AmqpTemplate 发送消息

#### 分布式任务调度平台 XXL-JOB 集成与配置

##### 介绍

XXL-JOB 是一个开箱即用的开源分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。由调度模块和执行模块构成：

-   调度模块（调度中心）：

负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块； 支持可视化、简单且动态的管理调度信息，包括任务新建，更新，删除，GLUE开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器Failover。

-   执行模块（执行器）：

负责接收调度请求并执行任务逻辑。任务模块专注于任务的执行等操作，开发和维护更加简单和高效； 接收“调度中心”的执行请求、终止请求和日志请求等。

![XXL-JOB 架构图](pic/xxljob.png)

XXL-JOB 将调度行为抽象形成“调度中心”公共平台，而平台自身并不承担业务逻辑，“调度中心”负责发起调度请求。

将任务抽象成分散的JobHandler，交由“执行器”统一管理，“执行器”负责接收调度请求并执行对应的JobHandler中业务逻辑。

因此，“调度”和“任务”两部分可以相互解耦，提高系统整体稳定性和扩展性；

XXL-JOB 的主要功能特性如下：

1.  简单：支持通过 Web 页面对任务进行 CRUD 操作，操作简单，一分钟上手；
2.  动态：支持动态修改任务状态、启动/停止任务，以及终止运行中任务，即时生效；
3.  调度中心 HA（中心式）：调度采用中心式设计，“调度中心”自研调度组件并支持集群部署，可保证调度中心 HA；
4.  执行器 HA（分布式）：任务分布式执行，任务”执行器”支持集群部署，可保证任务执行 HA；
5.  注册中心: 执行器会周期性自动注册任务, 调度中心将会自动发现注册的任务并触发执行。同时，也支持手动录入执行器地址；
6.  弹性扩容缩容：一旦有新执行器机器上线或者下线，下次调度时将会重新分配任务；
7.  触发策略：提供丰富的任务触发策略，包括：Cron 触发、固定间隔触发、固定延时触发、API（事件）触发、人工触发、父子任务触发；
8.  调度过期策略：调度中心错过调度时间的补偿处理策略，包括：忽略、立即补偿触发一次等；
9.  阻塞处理策略：调度过于密集执行器来不及处理时的处理策略，策略包括：单机串行（默认）、丢弃后续调度、覆盖之前调度；
10.  任务超时控制：支持自定义任务超时时间，任务运行超时将会主动中断任务；
11.  任务失败重试：支持自定义任务失败重试次数，当任务失败时将会按照预设的失败重试次数主动进行重试；其中分片任务支持分片粒度的失败重试；
12.  任务失败告警；默认提供邮件方式失败告警，同时预留扩展接口，可方便的扩展短信、钉钉等告警方式；
13.  路由策略：执行器集群部署时提供丰富的路由策略，包括：第一个、最后一个、轮询、随机、一致性 HASH、最不经常使用、最近最久未使用、故障转移、忙碌转移等；
14.  分片广播任务：执行器集群部署时，任务路由策略选择”分片广播”情况下，一次任务调度将会广播触发集群中所有执行器执行一次任务，可根据分片参数开发分片任务；
15.  动态分片：分片广播任务以执行器为维度进行分片，支持动态扩容执行器集群从而动态增加分片数量，协同进行业务处理；在进行大数据量业务操作时可显著提升任务处理能力和速度。
16.  故障转移：任务路由策略选择”故障转移”情况下，如果执行器集群中某一台机器故障，将会自动Failover切换到一台正常的执行器发送调度请求。
17.  任务进度监控：支持实时监控任务进度；
18.  Rolling 实时日志：支持在线查看调度结果，并且支持以 Rolling 方式实时查看执行器输出的完整的执行日志；
19.  GLUE：提供Web IDE，支持在线开发任务逻辑代码，动态发布，实时编译生效，省略部署上线的过程。支持30个版本的历史版本回溯。
20.  脚本任务：支持以GLUE模式开发和运行脚本任务，包括 Shell、Python、NodeJS、PHP、PowerShell等类型脚本;
21.  命令行任务：原生提供通用命令行任务Handler（Bean任务，”CommandJobHandler”）；业务方只需要提供命令行即可；
22.  任务依赖：支持配置子任务依赖，当父任务执行结束且执行成功后将会主动触发一次子任务的执行, 多个子任务用逗号分隔；
23.  一致性：“调度中心”通过DB锁保证集群分布式调度的一致性, 一次任务调度只会触发一次执行；
24.  自定义任务参数：支持在线配置调度任务入参，即时生效；
25.  调度线程池：调度系统多线程触发调度运行，确保调度精确执行，不被堵塞；
26.  数据加密：调度中心和执行器之间的通讯进行数据加密，提升调度信息安全性；
27.  邮件报警：任务失败时支持邮件报警，支持配置多邮件地址群发报警邮件；
28.  推送 maven 中央仓库: 将会把最新稳定版推送到 maven 中央仓库, 方便用户接入和使用;
29.  运行报表：支持实时查看运行数据，如任务数量、调度次数、执行器数量等；以及调度报表，如调度日期分布图，调度成功分布图等；
30.  全异步：任务调度流程全异步化设计实现，如异步调度、异步运行、异步回调等，有效对密集调度进行流量削峰，理论上支持任意时长任务的运行；
31.  跨语言：调度中心与执行器提供语言无关的 RESTful API 服务，第三方任意语言可据此对接调度中心或者实现执行器。除此之外，还提供了 “多任务模式”和“httpJobHandler”等其他跨语言方案；
32.  国际化：调度中心支持国际化设置，提供中文、英文两种可选语言，默认为中文；
33.  容器化：提供官方 docker 镜像，并实时更新推送 dockerhub，进一步实现产品开箱即用；
34.  线程池隔离：调度线程池进行隔离拆分，慢任务自动降级进入”Slow”线程池，避免耗尽调度线程，提高系统稳定性；
35.  用户管理：支持在线管理系统用户，存在管理员、普通用户两种角色；
36.  权限控制：执行器维度进行权限控制，管理员拥有全量权限，普通用户需要分配执行器权限后才允许相关操作；

##### 集成与配置

1.  初始化如下的`调度数据库`：

```sql
#
# XXL-JOB v2.4.0-SNAPSHOT
# Copyright (c) 2015-present, xuxueli.

CREATE database if NOT EXISTS `xxl_job` default character set utf8mb4 collate utf8mb4_unicode_ci;
use `xxl_job`;

SET NAMES utf8mb4;

CREATE TABLE `xxl_job_info` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_group` int(11) NOT NULL COMMENT '执行器主键ID',
  `job_desc` varchar(255) NOT NULL,
  `add_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `author` varchar(64) DEFAULT NULL COMMENT '作者',
  `alarm_email` varchar(255) DEFAULT NULL COMMENT '报警邮件',
  `schedule_type` varchar(50) NOT NULL DEFAULT 'NONE' COMMENT '调度类型',
  `schedule_conf` varchar(128) DEFAULT NULL COMMENT '调度配置，值含义取决于调度类型',
  `misfire_strategy` varchar(50) NOT NULL DEFAULT 'DO_NOTHING' COMMENT '调度过期策略',
  `executor_route_strategy` varchar(50) DEFAULT NULL COMMENT '执行器路由策略',
  `executor_handler` varchar(255) DEFAULT NULL COMMENT '执行器任务handler',
  `executor_param` varchar(512) DEFAULT NULL COMMENT '执行器任务参数',
  `executor_block_strategy` varchar(50) DEFAULT NULL COMMENT '阻塞处理策略',
  `executor_timeout` int(11) NOT NULL DEFAULT '0' COMMENT '任务执行超时时间，单位秒',
  `executor_fail_retry_count` int(11) NOT NULL DEFAULT '0' COMMENT '失败重试次数',
  `glue_type` varchar(50) NOT NULL COMMENT 'GLUE类型',
  `glue_source` mediumtext COMMENT 'GLUE源代码',
  `glue_remark` varchar(128) DEFAULT NULL COMMENT 'GLUE备注',
  `glue_updatetime` datetime DEFAULT NULL COMMENT 'GLUE更新时间',
  `child_jobid` varchar(255) DEFAULT NULL COMMENT '子任务ID，多个逗号分隔',
  `trigger_status` tinyint(4) NOT NULL DEFAULT '0' COMMENT '调度状态：0-停止，1-运行',
  `trigger_last_time` bigint(13) NOT NULL DEFAULT '0' COMMENT '上次调度时间',
  `trigger_next_time` bigint(13) NOT NULL DEFAULT '0' COMMENT '下次调度时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `job_group` int(11) NOT NULL COMMENT '执行器主键ID',
  `job_id` int(11) NOT NULL COMMENT '任务，主键ID',
  `executor_address` varchar(255) DEFAULT NULL COMMENT '执行器地址，本次执行的地址',
  `executor_handler` varchar(255) DEFAULT NULL COMMENT '执行器任务handler',
  `executor_param` varchar(512) DEFAULT NULL COMMENT '执行器任务参数',
  `executor_sharding_param` varchar(20) DEFAULT NULL COMMENT '执行器任务分片参数，格式如 1/2',
  `executor_fail_retry_count` int(11) NOT NULL DEFAULT '0' COMMENT '失败重试次数',
  `trigger_time` datetime DEFAULT NULL COMMENT '调度-时间',
  `trigger_code` int(11) NOT NULL COMMENT '调度-结果',
  `trigger_msg` text COMMENT '调度-日志',
  `handle_time` datetime DEFAULT NULL COMMENT '执行-时间',
  `handle_code` int(11) NOT NULL COMMENT '执行-状态',
  `handle_msg` text COMMENT '执行-日志',
  `alarm_status` tinyint(4) NOT NULL DEFAULT '0' COMMENT '告警状态：0-默认、1-无需告警、2-告警成功、3-告警失败',
  PRIMARY KEY (`id`),
  KEY `I_trigger_time` (`trigger_time`),
  KEY `I_handle_code` (`handle_code`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_log_report` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `trigger_day` datetime DEFAULT NULL COMMENT '调度-时间',
  `running_count` int(11) NOT NULL DEFAULT '0' COMMENT '运行中-日志数量',
  `suc_count` int(11) NOT NULL DEFAULT '0' COMMENT '执行成功-日志数量',
  `fail_count` int(11) NOT NULL DEFAULT '0' COMMENT '执行失败-日志数量',
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `i_trigger_day` (`trigger_day`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_logglue` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_id` int(11) NOT NULL COMMENT '任务，主键ID',
  `glue_type` varchar(50) DEFAULT NULL COMMENT 'GLUE类型',
  `glue_source` mediumtext COMMENT 'GLUE源代码',
  `glue_remark` varchar(128) NOT NULL COMMENT 'GLUE备注',
  `add_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_registry` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `registry_group` varchar(50) NOT NULL,
  `registry_key` varchar(255) NOT NULL,
  `registry_value` varchar(255) NOT NULL,
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `i_g_k_v` (`registry_group`,`registry_key`,`registry_value`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_group` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `app_name` varchar(64) NOT NULL COMMENT '执行器AppName',
  `title` varchar(12) NOT NULL COMMENT '执行器名称',
  `address_type` tinyint(4) NOT NULL DEFAULT '0' COMMENT '执行器地址类型：0=自动注册、1=手动录入',
  `address_list` text COMMENT '执行器地址列表，多地址逗号分隔',
  `update_time` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(50) NOT NULL COMMENT '账号',
  `password` varchar(50) NOT NULL COMMENT '密码',
  `role` tinyint(4) NOT NULL COMMENT '角色：0-普通用户、1-管理员',
  `permission` varchar(255) DEFAULT NULL COMMENT '权限：执行器ID列表，多个逗号分割',
  PRIMARY KEY (`id`),
  UNIQUE KEY `i_username` (`username`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

CREATE TABLE `xxl_job_lock` (
  `lock_name` varchar(50) NOT NULL COMMENT '锁名称',
  PRIMARY KEY (`lock_name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

INSERT INTO `xxl_job_group`(`id`, `app_name`, `title`, `address_type`, `address_list`, `update_time`) VALUES (1, 'xxl-job-executor-sample', '示例执行器', 0, NULL, '2018-11-03 22:21:31' );
INSERT INTO `xxl_job_info`(`id`, `job_group`, `job_desc`, `add_time`, `update_time`, `author`, `alarm_email`, `schedule_type`, `schedule_conf`, `misfire_strategy`, `executor_route_strategy`, `executor_handler`, `executor_param`, `executor_block_strategy`, `executor_timeout`, `executor_fail_retry_count`, `glue_type`, `glue_source`, `glue_remark`, `glue_updatetime`, `child_jobid`) VALUES (1, 1, '测试任务1', '2018-11-03 22:21:31', '2018-11-03 22:21:31', 'XXL', '', 'CRON', '0 0 0 * * ? *', 'DO_NOTHING', 'FIRST', 'demoJobHandler', '', 'SERIAL_EXECUTION', 0, 0, 'BEAN', '', 'GLUE代码初始化', '2018-11-03 22:21:31', '');
INSERT INTO `xxl_job_user`(`id`, `username`, `password`, `role`, `permission`) VALUES (1, 'admin', 'e10adc3949ba59abbe56e057f20f883e', 1, NULL);
INSERT INTO `xxl_job_lock` ( `lock_name`) VALUES ( 'schedule_lock');

commit;
```

**注：调度中心支持集群部署，集群情况下各节点务必连接同一个 mysql 实例，如果 mysql 做主从，调度中心集群节点务必强制走主库。**

2.  Docker 镜像方式搭建调度中心：

```sh
/**
* 如需自定义 mysql 等配置，可通过 "-e PARAMS" 指定，参数格式 PARAMS="--key=value  --key2=value2" ；
* 如需自定义 JVM 内存参数 等配置，可通过 "-e JAVA_OPTS" 指定，参数格式 JAVA_OPTS="-Xmx512m" ；
*/
docker run \
 -e PARAMS=' \
 --spring.datasource.url=jdbc:mysql://47.106.243.172:3306/xxl_job?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai \
 --spring.datasource.username=test \
 --spring.datasource.password=test!1234 \
 --xxl.job.accessToken=123' \
 -p 8080:8080 \
 -v /tmp:/data/applogs \
 --name xxl-job-admin \
 -d xuxueli/xxl-job-admin:{指定版本} 
```

**注：如上所示，数据库密码中如果包含特殊字符(例如，& 或 ！)，需要对特殊字符进行转义，PARAMS 参数值一定要使用使用单引号而不能使用双引号。**

| 常用转义字符 | 作用                                                         |
| ------------ | ------------------------------------------------------------ |
| 反斜杠（\\） | 使反斜杠后面的一个变量变为单纯的字符串，如果放在引号里面，是不起作用的 |
| 单引号（’’） | 转义其中所有的变量为单纯的字符串                             |
| 双引号（""） | 保留其中的变量属性，不进行转义处理                           |

调度中心访问地址：http://ip:8080/xxl-job-admin (该地址执行器将会使用到，作为回调地址)

默认登录账号 “admin/123456”，登录后如下图所示：

![XXL-JOB 首页](pic/xxljob1.png)

3.  项目中引入`xxl-job-core`的 maven 依赖：

```xml
<dependency>
    <groupId>com.xuxueli</groupId>
    <artifactId>xxl-job-core</artifactId>
    <version>2.3.1</version>
</dependency>
```

4.  application.yml 中加入执行器配置：

```yaml
# XXL-JOB 配置
xxl:
  job:
    admin:
      ### 调度中心部署根地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；
      addresses: http://127.0.0.1:8080/xxl-job-admin
    executor:
      ### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册
      appname: xxl-job-executor-novel
      ### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；
      logpath: logs/xxl-job/jobhandler
    ### xxl-job, access token
    accessToken: 123
```

5.  在`io.github.xxyopen.novel.core.config`包下创建 XXL-JOB 配置类配置执行器组件：

```java
/**
 * XXL-JOB 配置类
 *
 * @author xiongxiaoyang
 * @date 2022/5/31
 */
@Configuration
@Slf4j
public class XxlJobConfig {

    @Value("${xxl.job.admin.addresses}")
    private String adminAddresses;

    @Value("${xxl.job.accessToken}")
    private String accessToken;

    @Value("${xxl.job.executor.appname}")
    private String appname;

    @Value("${xxl.job.executor.logpath}")
    private String logPath;

    @Bean
    public XxlJobSpringExecutor xxlJobExecutor() {
        log.info(">>>>>>>>>>> xxl-job config init.");
        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();
        xxlJobSpringExecutor.setAdminAddresses(adminAddresses);
        xxlJobSpringExecutor.setAccessToken(accessToken);
        xxlJobSpringExecutor.setAppname(appname);
        xxlJobSpringExecutor.setLogPath(logPath);
        return xxlJobSpringExecutor;
    }

}
```

### 接口开发

#### 接口规约

1.  协议：生产环境必须使用 HTTPS。
    
2.  路径：每一个 API 需对应一个路径，表示 API 具体的请求地址：
    
    a） 代表一种资源，只能为名词，推荐使用复数，不能为动词，请求方法已经表达动作意义。
    
    b） URL 路径不能使用大写，单词如果需要分隔，统一使用下划线。
    
    c） 路径禁止携带表示请求内容类型的后缀，比如".json",".xml"，通过 accept 头表达即可。
    
3.  请求方法：对具体操作的定义，常见的请求方法如下：
    
    a） GET：从服务器取出资源。
    
    b） POST：在服务器新建一个资源。
    
    c） PUT：在服务器更新资源。
    
    d） DELETE：从服务器删除资源。
    
4.  请求内容： URL 带的参数必须无敏感信息或符合安全要求； body 里带参数时必须设置 Content-Type。
    
5.  响应体：响应体 body 可放置多种数据类型，由 Content-Type 头来确定。
    

#### Service/DAO 层方法命名规约

1.  获取单个对象的方法用 get 做前缀。
    
2.  获取多个对象的方法用 list 做前缀，复数结尾，如： listObjects。
    
3.  获取统计值的方法用 count 做前缀。
    
4.  插入的方法用 save/insert 做前缀。
    
5.  删除的方法用 remove/delete 做前缀。
    
6.  修改的方法用 update 做前缀。
    

#### 首页相关接口开发

首页 UI 图如下：

![首页 UI 图](pic/home.png)

从上图可以看出首页包括 `小说推荐`（包括轮播图、周推、强推等）、`新闻公告`、`点击榜`、`新书榜`、`更新榜`（包括最新更新列表） 和 `友情链接` 6个内容区域的展示，所以我们需要开发 6 个相关的 API 查询接口以提供数据给前端。

首先，我们需要在 controller、service、service.impl 包下创建首页模块、新闻模块和小说模块的 API 控制器 Controller、业务服务类 Service 以及服务实现类 ServiceImpl。

**注：首页是我们小说门户的入口，承载着我们系统很大一部分流量，并且内容不需要实时更新。所以首页相关内容的查询最好都做缓存处理。**

##### 首页小说推荐查询接口开发

首页小说推荐的数据主要保存在在数据库\*\*home\_book \[**首页小说推荐**\]\*\*表中，该查询是一个从服务器取出资源的操作，所以该请求方法需要使用 GET 类型。具体实现步骤如下：

1.  首先我们需要在`io.github.xxyopen.novel.manager`包下创建首页推荐小说的缓存管理类如下：

```java
/**
 * 首页推荐小说 缓存管理类
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
@Component
@RequiredArgsConstructor
public class HomeBookCacheManager {

    private final HomeBookMapper homeBookMapper;

    private final BookInfoMapper bookInfoMapper;

    /**
     * 查询首页小说推荐，并放入缓存中
     */
    @Cacheable(cacheManager = CacheConsts.CAFFEINE_CACHE_MANAGER
            , value = CacheConsts.HOME_BOOK_CACHE_NAME)
    public List<HomeBookRespDto> listHomeBooks() {
        // 从首页小说推荐表中查询出需要推荐的小说
        List<;HomeBook> homeBooks = homeBookMapper.selectList(null);

        // 获取推荐小说ID列表
        if (!CollectionUtils.isEmpty(homeBooks)) {
            List<;Long> bookIds = homeBooks.stream()
                    .map(HomeBook::getBookId)
                    .toList();

            // 根据小说ID列表查询相关的小说信息列表
            QueryWrapper<BookInfo> bookInfoQueryWrapper = new QueryWrapper<>();
            bookInfoQueryWrapper.in("id", bookIds);
            List<BookInfo> bookInfos = bookInfoMapper.selectList(bookInfoQueryWrapper);

            // 组装 HomeBookRespDto 列表数据并返回
            if(!CollectionUtils.isEmpty(bookInfos)){
                Map<Long, BookInfo> bookInfoMap = bookInfos.stream()
                        .collect(Collectors.toMap(BookInfo::getId, Function.identity()));
                return homeBooks.stream().map(v -> {
                    BookInfo bookInfo = bookInfoMap.get(v.getBookId());
                    HomeBookRespDto bookRespDto = new HomeBookRespDto();
                    bookRespDto.setBookId(v.getBookId());
                    bookRespDto.setBookName(bookInfo.getBookName());
                    bookRespDto.setPicUrl(bookInfo.getPicUrl());
                    bookRespDto.setAuthorName(bookInfo.getAuthorName());
                    bookRespDto.setBookDesc(bookInfo.getBookDesc());
                    return bookRespDto;
                }).toList();

            }

        }

        return Collections.emptyList();
    }

}
```

该缓存管理类包含了一个查询首页小说推荐数据的方法，该方法执行数据库查询逻辑并进行简单的处理得到我们需要的数据格式并通过 @Cacheable 注解缓存起来。 该方法下次再被调用时会直接从缓存中拿取数据而不需要再一次查询数据库并处理，大大减轻了数据库的压力。

2.  然后我们在首页模块业务类`HomeService`中定义首页小说推荐查询的业务方法如下：

```java
/**
 * 首页模块 服务类
 *
 * @author xiongxiaoyang
 * @date 2022/5/13
 */
public interface HomeService {

    /**
     * 查询首页小说推荐列表
     *
     * @return 首页小说推荐列表的 rest 响应结果
     * */
    RestResp<List<HomeBookRespDto>> listHomeBooks();
}
```

3.  接着我们在首页模块业务实现类`HomeServiceImpl`中实现`HomeService`中定义的抽象方法，通过调用`HomeBookCacheManager`的`listHomeBooks`方法获取到所需数据并返回：

```java
/**
 * 首页模块 服务实现类
 *
 * @author xiongxiaoyang
 * @date 2022/5/13
 */
@Service
@RequiredArgsConstructor
public class HomeServiceImpl implements HomeService {

    private final HomeBookCacheManager homeBookCacheManager;

    @Override
    public RestResp<List<HomeBookRespDto>> listHomeBooks() {
        return RestResp.ok(homeBookCacheManager.listHomeBooks());
    }
}
```

4.  最后我们在首页模块的 API 控制器`HomeController`中定义 GET 类型的查询接口，调用 service 中的相应业务方法获得首页小说推荐数据并返回给前端：

```java
/**
 * 首页模块 API 接口
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
@RestController
@RequestMapping(ApiRouterConsts.API_FRONT_HOME_URL_PREFIX)
@RequiredArgsConstructor
public class HomeController {

    private final HomeService homeService;

    /**
     * 首页小说推荐查询接口
     * */
    @GetMapping("books")
    public RestResp<List<HomeBookRespDto>> listHomeBooks(){
        return homeService.listHomeBooks();
    }
}
```

#### 登录注册相关接口开发

JWT（JSON Web Token）是一种开放的[RFC 7519](https://datatracker.ietf.org/doc/html/rfc7519)行业标准方法，它定义了一种紧凑的、自包含的方式，用于作为 JSON 对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数字签名的。服务端只生成和验证 JWT，客户端保存 JWT，所以 JWT 是无状态的。

由于 JWT 的无状态性，特别适用于分布式站点的单点登录（SSO）场景，已经成为了目前分布式服务权限控制解决方案的事实标准。我们 novel 项目是一个多系统并且后期会拓展为微服务架构的项目，所以使用 JWT 来实现登录认证。

[JJWT](https://github.com/jwtk/jjwt) 是一个在 JVM 和 Android 上创建和验证 JWT 非常易于使用和理解的库，JJWT 是完全基于 JWT、JWS、JWE、JWK 和 JWA RFC 规范的纯 Java 实现，并且在 Apache 2.0 许可条款下开源，目前在 JAVA 应用程序中广泛使用。novel 项目集成了该库以实现 JWT 的生成和验证。

注册和登录的 UI 图如下：

![注册 UI 图](pic/register.png)

![登录 UI 图](pic/login.png)

##### 获取图片验证码接口开发

从注册的 UI 图中可以看出我们需要一个图形验证码来防止用户利用机器人自动注册。该图形验证码由服务端生成，当用户申请注册时必须带上验证码，由服务端来校验验证码的有效性，只有验证码匹配才能允许用户注册。获取图片验证码接口开发步骤如下：

1.  图形验证码属于一种图片资源，所以我们首先需要在 controller、service、service.impl 包下创建资源（Resource，处理图片/视频/文档等）模块的 API 控制器 Controller、业务服务类 Service 以及服务实现类 ServiceImpl。
    
2.  接着我们需要在`io.github.xxyopen.novel.core.common.util`包下创建图形验证码工具类来生成随机校验码和对应的 Base64 编码后的图片：
    

```java
/**
 * 图片验证码工具类
 *
 * @author xiongxiaoyang
 * @date 2022/5/17
 */
@UtilityClass
public class ImgVerifyCodeUtils {

    /**
     * 随机产生只有数字的字符串
     */
    private final String randNumber = "0123456789";

    /**
     * 图片宽
     */
    private final int width = 100;

    /**
     * 图片高
     */
    private final int height = 38;

    private final Random random = new Random();

    /**
     * 获得字体
     */
    private Font getFont() {
        return new Font("Fixed", Font.PLAIN, 23);
    }


    /**
     * 生成校验码图片
     */
    public String genVerifyCodeImg(String verifyCode) throws IOException {
        // BufferedImage类是具有缓冲区的Image类,Image类是用于描述图像信息的类
        BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_BGR);
        // 产生Image对象的Graphics对象,改对象可以在图像上进行各种绘制操作
        Graphics g = image.getGraphics();
        //图片大小
        g.fillRect(0, 0, width, height);
        //字体大小
        //字体颜色
        g.setColor(new Color(204, 204, 204));
        // 绘制干扰线
        // 干扰线数量
        int lineSize = 40;
        for (int i = 0; i <= lineSize; i++) {
            drawLine(g);
        }
        // 绘制随机字符
        drawString(g, verifyCode);
        g.dispose();
        //将图片转换成Base64字符串
        ByteArrayOutputStream stream = new ByteArrayOutputStream();
        ImageIO.write(image, "JPEG", stream);
        return Base64.getEncoder().encodeToString(stream.toByteArray());
    }

    /**
     * 绘制字符串
     */
    private void drawString(Graphics g, String verifyCode) {
        for (int i = 1; i <= verifyCode.length(); i++) {
            g.setFont(getFont());
            g.setColor(new Color(random.nextInt(101), random.nextInt(111), random
                    .nextInt(121)));
            g.translate(random.nextInt(3), random.nextInt(3));
            g.drawString(String.valueOf(verifyCode.charAt(i - 1)), 13 * i, 23);
        }
    }

    /**
     * 绘制干扰线
     */
    private void drawLine(Graphics g) {
        int x = random.nextInt(width);
        int y = random.nextInt(height);
        int xl = random.nextInt(13);
        int yl = random.nextInt(15);
        g.drawLine(x, y, x + xl, y + yl);
    }

    /**
     * 获取随机的校验码
     */
    public String getRandomVerifyCode(int num) {
        int randNumberSize = randNumber.length();
        StringBuilder verifyCode = new StringBuilder();
        for (int i = 0; i < num; i++) {
            String rand = String.valueOf(randNumber.charAt(random.nextInt(randNumberSize)));
            verifyCode.append(rand);
        }
        return verifyCode.toString();
    }

}
```

3.  然后，我们在`io.github.xxyopen.novel.manager`包下创建验证码管理类，用于生成、校验和删除验证码（不限于图形验证码）：

```java
/**
 * 验证码 管理类
 *
 * @author xiongxiaoyang
 * @date 2022/5/12
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class VerifyCodeManager {

    private final StringRedisTemplate stringRedisTemplate;

    /**
     * 生成图形验证码，并放入 Redis 中
     */
    public String genImgVerifyCode(String sessionId) throws IOException {
        String verifyCode = ImgVerifyCodeUtils.getRandomVerifyCode(4);
        String img = ImgVerifyCodeUtils.genVerifyCodeImg(verifyCode);
        stringRedisTemplate.opsForValue().set(CacheConsts.IMG_VERIFY_CODE_CACHE_KEY + sessionId
                , verifyCode, Duration.ofMinutes(5));
        return img;
    }

    /**
     * 校验图形验证码
     */
    public boolean imgVerifyCodeOk(String sessionId, String verifyCode) {
        return Objects.equals(
                stringRedisTemplate.opsForValue().get(CacheConsts.IMG_VERIFY_CODE_CACHE_KEY + sessionId)
                , verifyCode);
    }

    /**
     * 从 Redis 中删除验证码
     */
    public void removeImgVerifyCode(String sessionId) {
        stringRedisTemplate.delete(CacheConsts.IMG_VERIFY_CODE_CACHE_KEY + sessionId);
    }
```

**注：我们在保存验证码的时候需要一个全局唯一的 sessionId 字符串用于标识该验证码属于哪个浏览器会话，该 sessionId 会在验证码返回给前端的时候一并返回，在用户提交注册的时候，该 sessionId 会和验证码一起提交用于校验**

4.  接着，我们在资源模块业务类`ResourceService`中定义获取图片验证码的业务方法如下：

```java
/**
 * 获取图片验证码
 *
 * @throws IOException 验证码图片生成失败
 * @return Base64编码的图片
 */
RestResp<ImgVerifyCodeRespDto> getImgVerifyCode() throws IOException;
```

5.  接着，我们在资源模块业务实现类`ResourceServiceImpl`中实现`ResourceService`中定义的抽象方法，调用`VerifyCodeManager`中获取图形验证码方法并返回结果：

```java
@Override
public RestResp<ImgVerifyCodeRespDto> getImgVerifyCode() throws IOException {
    String sessionId = IdWorker.get32UUID();
    return RestResp.ok(ImgVerifyCodeRespDto.builder()
            .sessionId(sessionId)
            .img(verifyCodeManager.genImgVerifyCode(sessionId))
            .build());
}
```

6.  最后，我们在资源模块的 API 控制器`ResourceController`中定义 GET 类型的查询接口，调用 service 中的相应业务方法获得图形验证码数据并返回给前端：

```java
/**
 * 获取图片验证码接口
 */
@GetMapping("img_verify_code")
public RestResp<ImgVerifyCodeRespDto> getImgVerifyCode() throws IOException {
    return resourceService.getImgVerifyCode();
}
```

##### 注册接口开发

用户注册需要在在数据库\*\*user\_info \[**用户信息**\]\*\*表中插入一条用户数据，是一个在服务器新建资源的操作，所以该请求方法需要使用 POST 类型。具体实现步骤如下：

1.  首先我们在配置文件`application.yml`中定义 JWT 相关配置：

```yaml
# 项目配置
novel:
  # JWT 密钥
  jwt:
    secret: E66559580A1ADF48CDD928516062F12E
```

**注：目前只有 JWT 密钥的配置，后期会拓展过期时间等其他配置**

2.  然后，我们在`io.github.xxyopen.novel.core.util`包下创建 JWT 工具类，用于 JWT 的生成和解析：

```java
/**
 * JWT 工具类
 *
 * @author xiongxiaoyang
 * @date 2022/5/17
 */
@ConditionalOnProperty("novel.jwt.secret")
@Component
@Slf4j
public class JwtUtils {

    /**
     * 注入JWT加密密钥
     */
    @Value("${novel.jwt.secret}")
    private String secret;

    /**
     * 定义系统标识头常量
     */
    private static final String HEADER_SYSTEM_KEY = "systemKeyHeader";

    /**
     * 根据用户 ID 生成 JWT
     * @param uid 用户 ID
     * @param systemKey 系统标识
     * @return JWT
     */
    public String generateToken(Long uid, String systemKey) {
        return Jwts.builder()
                .setHeaderParam(HEADER_SYSTEM_KEY, systemKey)
                .setSubject(uid.toString())
                .signWith(Keys.hmacShaKeyFor(secret.getBytes(StandardCharsets.UTF_8)))
                .compact();
    }

    /**
     * 解析 JWT 返回用户 ID
     * @param token JWT
     * @param systemKey 系统标识
     * @return 用户 ID
     */
    public Long parseToken(String token, String systemKey) {
        Jws<Claims> claimsJws;
        try {
            claimsJws = Jwts.parserBuilder()
                    .setSigningKey(Keys.hmacShaKeyFor(secret.getBytes(StandardCharsets.UTF_8)))
                    .build()
                    .parseClaimsJws(token);
            // OK, we can trust this JWT
            // 判断该 JWT 是否属于指定系统
            if (Objects.equals(claimsJws.getHeader().get(HEADER_SYSTEM_KEY), systemKey)) {
                return Long.parseLong(claimsJws.getBody().getSubject());
            }
        } catch (JwtException e) {
            log.warn("JWT解析失败:{}", token);
            // don't trust the JWT!
        }
        return null;
    }

}
```

3.  接着我们需要在用户模块业务类`UserService`中定义注册的业务方法如下：

```java
/**
 * 用户注册
 *
 * @param dto 注册参数
 * @return JWT
 */
RestResp<UserRegisterRespDto> register(UserRegisterReqDto dto);
```

4.  接着我们在用户模块业务实现类`UserServiceImpl`中实现`UserService`中定义的抽象方法，对验证码、手机号进行校验。校验成功，则保存用户信息到数据库，并删除验证码和使用 JWT 工具类生成 JWT 字符串返回；校验失败，则返回相应的错误码给前端，具体代码如下：

```java
@Override
public RestResp<UserRegisterRespDto> register(UserRegisterReqDto dto) {
    // 校验图形验证码是否正确
    if (!verifyCodeManager.imgVerifyCodeOk(dto.getSessionId(), dto.getVelCode())) {
        // 图形验证码校验失败
        throw new BusinessException(ErrorCodeEnum.USER_VERIFY_CODE_ERROR);
    }

    // 校验手机号是否已注册
    QueryWrapper<UserInfo> queryWrapper = new QueryWrapper<>();
    queryWrapper.eq(DatabaseConsts.UserInfoTable.COLUMN_USERNAME, dto.getUsername())
            .last(DatabaseConsts.SqlEnum.LIMIT_1.getSql());
    if (userInfoMapper.selectCount(queryWrapper) > 0) {
        // 手机号已注册
        throw new BusinessException(ErrorCodeEnum.USER_NAME_EXIST);
    }

    // 注册成功，保存用户信息
    UserInfo userInfo = new UserInfo();
    userInfo.setPassword(DigestUtils.md5DigestAsHex(dto.getPassword().getBytes(StandardCharsets.UTF_8)));
    userInfo.setUsername(dto.getUsername());
    userInfo.setNickName(dto.getUsername());
    userInfo.setCreateTime(LocalDateTime.now());
    userInfo.setUpdateTime(LocalDateTime.now());
    userInfo.setSalt("0");
    userInfoMapper.insert(userInfo);

    // 删除验证码
    verifyCodeManager.removeImgVerifyCode(dto.getSessionId());

    // 生成JWT 并返回
    return RestResp.ok(
            UserRegisterRespDto.builder()
                    .token(jwtUtils.generateToken(userInfo.getId(), SystemConfigConsts.NOVEL_FRONT_KEY))
                    .uid(userInfo.getId())
                    .build()
    );

}
```

5.  最后，我们在用户模块 API 控制器`UserController`中定义 POST 类型的注册接口，调用用户模块 service 中的相应业务方法注册用户：

```java
/**
    * 用户注册接口
    */
@PostMapping("register")
public RestResp<UserRegisterRespDto> register(@Valid @RequestBody UserRegisterReqDto dto) {
    return userService.register(dto);
}
```

##### 登录接口开发

用户登录是一个特殊接口，不是单独请求一个资源，而是对于用户信息验证，创建一个 JWT，而且登录提交的数据中还包含敏感数据（密码）。URL 带的参数必须无敏感信息或符合安全要求，所以我们需要定义 POST 类型的接口来处理登录请求。具体实现步骤如下：

1.  首先我们需要在用户模块业务类`UserService`中定义登录的业务方法如下：

```java
/**
 * 用户登录
 *
 * @param dto 登录参数
 * @return JWT + 昵称
*/
RestResp<UserLoginRespDto> login(UserLoginReqDto dto);
```

2.  接着我们在用户模块业务实现类`UserServiceImpl`中实现`UserService`中定义的抽象方法，对登录用户名密码进行校验。校验通过，则生成 JWT 字符串返回；校验失败，则返回对应的错误码：

```java
@Override
public RestResp<UserLoginRespDto> login(UserLoginReqDto dto) {
    // 查询用户信息
    QueryWrapper<UserInfo> queryWrapper = new QueryWrapper<>();
    queryWrapper.eq(DatabaseConsts.UserInfoTable.COLUMN_USERNAME, dto.getUsername())
            .last(DatabaseConsts.SqlEnum.LIMIT_1.getSql());
    UserInfo userInfo = userInfoMapper.selectOne(queryWrapper);
    if (Objects.isNull(userInfo)) {
        // 用户不存在
        throw new BusinessException(ErrorCodeEnum.USER_ACCOUNT_NOT_EXIST);
    }

    // 判断密码是否正确
    if (!Objects.equals(userInfo.getPassword()
            , DigestUtils.md5DigestAsHex(dto.getPassword().getBytes(StandardCharsets.UTF_8)))) {
        // 密码错误
        throw new BusinessException(ErrorCodeEnum.USER_PASSWORD_ERROR);
    }

    // 登录成功，生成JWT并返回
    return RestResp.ok(UserLoginRespDto.builder()
            .token(jwtUtils.generateToken(userInfo.getId(), SystemConfigConsts.NOVEL_FRONT_KEY))
            .uid(userInfo.getId())
            .nickName(userInfo.getNickName()).build());
}
```

3.  最后，我们在用户模块 API 控制器`UserController`中定义 POST 类型的登录接口，调用用户模块 service 中的相应业务方法：

```java
/**
 * 用户登录接口
 */
@PostMapping("login")
public RestResp<UserLoginRespDto> login(@Valid @RequestBody UserLoginReqDto dto) {
    return userService.login(dto);
}
```

#### 小说详情页相关接口开发

小说详情页 UI 图如下：

![小说详情页 UI 图](pic/book_detail.png)

从上图可以看出小说详情页包括 `小说信息`（包括作家信息）、`最新章节`、`作品评论`、`同类推荐`四个内容区域的展示，而评论区还包含了评论发表、评论修改和评论删除的功能。所以我们需要开发与小说详情页相关的 4 个 API 查询接口、1 个 API 增加接口、1 个 API 修改接口和 1 个 API 删除接口提供给前端。

##### 小说评论发表接口开发

评论发表需要在数据库\*\*book\_comment \[**小说评论**\]\*\*表中插入一条评论数据，是一个在服务器新建资源的操作，所以该请求方法需要使用 POST 类型。具体实现步骤如下：

1.  首先我们需要在小说模块业务类`BookService`中定义发表评论的业务方法如下：

```java
/**
 * 发表评论
 *
 * @param dto 评论相关 DTO
 * @return void
 */
RestResp<Void> saveComment(UserCommentReqDto dto);
```

2.  接着我们在小说模块业务实现类`BookServiceImpl`中实现`BookService`中定义的抽象方法，将用户对小说的评论数据保存到数据库中：

```java
@Override
public RestResp<Void> saveComment(UserCommentReqDto dto) {
    // 校验用户是否已发表评论
    QueryWrapper<BookComment> queryWrapper = new QueryWrapper<>();
    queryWrapper.eq(DatabaseConsts.BookCommentTable.COLUMN_USER_ID,dto.getUserId())
            .eq(DatabaseConsts.BookCommentTable.COLUMN_BOOK_ID,dto.getBookId());
    if(bookCommentMapper.selectCount(queryWrapper) > 0){
        // 用户已发表评论
        return RestResp.fail(ErrorCodeEnum.USER_COMMENTED);
    }
    BookComment bookComment = new BookComment();
    bookComment.setBookId(dto.getBookId());
    bookComment.setUserId(dto.getUserId());
    bookComment.setCommentContent(dto.getCommentContent());
    bookComment.setCreateTime(LocalDateTime.now());
    bookComment.setUpdateTime(LocalDateTime.now());
    bookCommentMapper.insert(bookComment);
    return RestResp.ok();
}
```

**注：保存评论之前我们需要对用户是否已发表评论进行校验，每个用户只能对同一本书发表一条评论。**

3.  最后，由于发表评论的行为属于用户（需要校验登录权限），所以我们在用户模块 API 控制器`UserController`中定义 POST 类型的增加接口，调用小说模块 service 中的相应业务方法保存小说评论数据：

```java
/**
 * 发表评论接口
 */
@PostMapping("comment")
public RestResp<Void> comment(@Valid @RequestBody UserCommentReqDto dto) {
    dto.setUserId(UserHolder.getUserId());
    return bookService.saveComment(dto);
}
```

##### 小说评论修改接口开发

评论修改需要更新数据库\*\*book\_comment \[**小说评论**\]\*\*表中的评论数据，是一个在服务器更新资源的操作，所以该请求方法需要使用 PUT 类型。具体实现步骤如下：

1.  首先我们需要在小说模块业务类`BookService`中定义修改评论的业务方法如下：

```java
/**
 * 修改评论
 * @param userId 用户ID
 * @param id 评论ID
 * @param content 修改后的评论内容
 * @return void
 * */
RestResp<Void> updateComment(Long userId, Long id, String content);
```

2.  接着我们在小说模块业务实现类`BookServiceImpl`中实现`BookService`中定义的抽象方法，更新数据表中的评论数据：

```java
@Override
public RestResp<Void> updateComment(Long userId, Long id, String content) {
    QueryWrapper<BookComment> queryWrapper = new QueryWrapper<>();
    queryWrapper.eq(DatabaseConsts.CommonColumnEnum.ID.getName(), id)
            .eq(DatabaseConsts.BookCommentTable.COLUMN_USER_ID,userId);
    BookComment bookComment = new BookComment();
    bookComment.setCommentContent(content);
    bookCommentMapper.update(bookComment,queryWrapper);
    return RestResp.ok();
}
```

**注：用户只能更新自己的小说评论，所以更新评论表中数据的 where 条件不但需要小说ID还需要加上用户ID**

3.  最后，由于修改评论的行为属于用户（需要校验登录权限），所以我们在用户模块 API 控制器`UserController`中定义 PUT 类型的修改接口，调用小说模块 service 中的相应业务方法来更新小说评论数据：

```java
/**
 * 修改评论接口
 */
@PutMapping("comment/{id}")
public RestResp<Void> updateComment(@PathVariable Long id, String content) {
    return bookService.updateComment(UserHolder.getUserId(), id, content);
}
```

##### 小说评论删除接口开发

评论删除需要删除数据库\*\*book\_comment \[**小说评论**\]\*\*表中的评论数据，是一个从服务器删除资源的操作，所以该请求方法需要使用 DELETE 类型。具体实现步骤如下：

1.  首先我们需要在小说模块业务类`BookService`中定义删除评论的业务方法如下：

```java
/**
 * 删除评论
 * @param userId 评论用户ID
 * @param commentId 评论ID
 * @return void
 * */
RestResp<Void> deleteComment(Long userId, Long commentId);
```

2.  接着我们在小说模块业务实现类`BookServiceImpl`中实现`BookService`中定义的抽象方法，删除数据表中的评论数据：

```java
@Override
public RestResp<Void> deleteComment(Long userId, Long commentId) {
    QueryWrapper<BookComment> queryWrapper = new QueryWrapper<>();
    queryWrapper.eq(DatabaseConsts.CommonColumnEnum.ID.getName(), commentId)
            .eq(DatabaseConsts.BookCommentTable.COLUMN_USER_ID,userId);
        bookCommentMapper.delete(queryWrapper);
    return RestResp.ok();
}
```

**注：用户只能删除自己的小说评论，所以删除评论表中数据的 where 条件不但需要小说ID还需要加上用户ID**

3.  最后，由于删除评论的行为属于用户（需要校验登录权限），所以我们在用户模块 API 控制器`UserController`中定义 DELETE 类型的删除接口，调用小说模块 service 中的相应业务方法来删除小说评论数据：

```java
/**
 * 删除评论接口
 */
@DeleteMapping("comment/{id}")
public RestResp<Void> deleteComment(@PathVariable Long id) {
    return bookService.deleteComment(UserHolder.getUserId(), id);
}
```

##### 小说最新评论列表查询接口开发

最新评论列表查询需要查询数据库\*\*book\_comment \[**小说评论**\]\*\*表中的评论数据，是一个从服务器取出资源的操作，所以该请求方法需要使用 GET 类型。具体实现步骤如下：

1.  首先我们需要在小说模块业务类`BookService`中定义查询最新评论列表的业务方法如下：

```java
/**
 * 小说最新评论查询
 *
 * @param bookId 小说ID
 * @return 小说最新评论数据
 */
RestResp<BookCommentRespDto> listNewestComments(Long bookId);
```

2.  接着我们在小说模块业务实现类`BookServiceImpl`中实现`BookService`中定义的抽象方法，查询数据表中的最新评论列表数据：

```java
@Override
public RestResp<BookCommentRespDto> listNewestComments(Long bookId) {
    // 查询评论总数
    QueryWrapper<BookComment> commentCountQueryWrapper = new QueryWrapper<>();
    commentCountQueryWrapper.eq(DatabaseConsts.BookCommentTable.COLUMN_BOOK_ID, bookId);
    Long commentTotal = bookCommentMapper.selectCount(commentCountQueryWrapper);
    BookCommentRespDto bookCommentRespDto = BookCommentRespDto.builder().commentTotal(commentTotal).build();
    if (commentTotal > 0) {

        // 查询最新的评论列表
        QueryWrapper<BookComment> commentQueryWrapper = new QueryWrapper<>();
        commentQueryWrapper.eq(DatabaseConsts.BookCommentTable.COLUMN_BOOK_ID, bookId)
                .orderByDesc(DatabaseConsts.CommonColumnEnum.CREATE_TIME.getName())
                .last(DatabaseConsts.SqlEnum.LIMIT_5.getSql());
        List<BookComment> bookComments = bookCommentMapper.selectList(commentQueryWrapper);

        // 查询评论用户信息，并设置需要返回的评论用户名
        List<Long> userIds = bookComments.stream().map(BookComment::getUserId).toList();
        List<UserInfo> userInfos = userDaoManager.listUsers(userIds);
        Map<Long, String> userInfoMap = userInfos.stream().collect(Collectors.toMap(UserInfo::getId, UserInfo::getUsername));
        List<BookCommentRespDto.CommentInfo> commentInfos = bookComments.stream()
                .map(v -> BookCommentRespDto.CommentInfo.builder()
                        .id(v.getId())
                        .commentUserId(v.getUserId())
                        .commentUser(userInfoMap.get(v.getUserId()))
                        .commentContent(v.getCommentContent())
                        .commentTime(v.getCreateTime()).build()).toList();
        bookCommentRespDto.setComments(commentInfos);
    } else {
        bookCommentRespDto.setComments(Collections.emptyList());
    }
    return RestResp.ok(bookCommentRespDto);
}
```

3.  最后，我们在小说模块 API 控制器`BookController`中定义 GET 类型的查询接口，调用 service 中的相应业务方法来查询小说最新评论列表数据：

```java
/**
 * 小说最新评论查询接口
 */
@GetMapping("comment/newest_list")
public RestResp<BookCommentRespDto> listNewestComments(Long bookId) {
    return bookService.listNewestComments(bookId);
}
```

4.  因为小说评论的用户名（手机号）属于敏感数据，我们不应该直接返回给前端。所以我们还需要定义一个 JSON 序列化器在 Spring MVC 序列化我们返回的 Java 对象为 JSON 字符串时格式化一下用户名，隐藏中间的 4 位数字为 `****`。代码如下：

```java
/**
 * 用户名序列化器（敏感信息，不应该在页面上完全显示）
 *
 * @author xiongxiaoyang
 * @date 2022/5/20
 */
public class UsernameSerializer extends JsonSerializer<String> {

    @Override
    public void serialize(String s, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
        jsonGenerator.writeString(s.substring(0,4) + "****" + s.substring(8));
    }

}
```

```java
/**
 * 小说评论 响应DTO
 * @author xiongxiaoyang
 * @date 2022/5/17
 */
@Data
@Builder
public class BookCommentRespDto {

    private Long commentTotal;

    private List<CommentInfo> comments;

    @Data
    @Builder
    public static class CommentInfo {

        private Long id;

        private String commentContent;

        @JsonSerialize(using = UsernameSerializer.class)
        private String commentUser;

        private Long commentUserId;

        @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss")
        private LocalDateTime commentTime;

    }

}
```



## 项目优化

### 使用策略模式重构多系统环境下的用户认证授权

#### 需求

小说精品屋由前台门户系统、作家后台管理系统、平台后台管理系统和爬虫管理系统以及后面可能会扩展的漫画系统和视频系统等多个子系统构成，是一个复杂的多系统环境。平台端的后台管理系统和爬虫管理系统账号是独立的，用户端其它子系统要求统一账号登录。那么我们应该如何设计才能统一对这些系统进行认证授权呢 ？

#### 实现思路

我们提供平台管理后台、爬虫管理后台和单点登录三个登录入口，前端在每个登录入口登录成功之后都会获得后端返回的 token，这个时候需要分别保存起来， 在请求相应系统的后端接口时，通过请求头携带上相应的 token。

后端需要配置一个统一的拦截器，根据请求的 URI 识别出相应系统类型，并对这些 token 进行解析得到 userId。这个时候就可以根据用户来鉴权，如果用户有权访问，则放行。否则，返回一个相应的错误码给前端。具体代码如下：

```java
public class AuthInterceptor implements HandlerInterceptor {

    private final JwtUtils jwtUtils;

    private final ObjectMapper objectMapper;

    @SuppressWarnings("NullableProblems")
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        // 校验登录 token
        String token = request.getHeader(SystemConfigConsts.HTTP_AUTH_HEADER_NAME);
        if (!Objects.isNull(token)) {
            String requestUri = request.getRequestURI();
            if (requestUri.contains(ApiRouterConsts.API_FRONT_URL_PREFIX)) {
                // 校验门户系统用户权限
                Long userId = jwtUtils.parseToken(token, SystemConfigConsts.NOVEL_FRONT_KEY);
                if (!Objects.isNull(userId)) {
                    // TODO 查询用户信息并校验账号状态是否正常
                    // TODO 其它权限校验
                    // 认证成功
                    return HandlerInterceptor.super.preHandle(request, response, handler);
                }
            }else if (requestUri.contains(ApiRouterConsts.API_AUTHOR_URL_PREFIX)){
                // TODO 校验作家后台管理系统用户权限

            }else if (requestUri.contains(ApiRouterConsts.API_ADMIN_URL_PREFIX)){
                // TODO 校验平台后台管理系统用户权限
            }
            //。。。更多系统权限校验
            // 完整实现可能至少几百行的代码

        }
        response.setCharacterEncoding(StandardCharsets.UTF_8.name());
        response.setContentType(MediaType.APPLICATION_JSON_VALUE);
        response.getWriter().write(objectMapper.writeValueAsString(RestResp.fail(ErrorCodeEnum.USER_LOGIN_EXPIRED)));
        return false;
    }
}
```

此时，可以简单的实现基本的权限拦截功能。但是因为所有系统的认证授权逻辑都在这一个方法中，代码及其臃肿难以维护。每当某一系统授权逻辑发生变化或者新增加了一个子系统，都需要修改此处的代码。修改之前不但必须先完全理解这一大段代码，正确定位到需要修改的位置，而且极其容易影响到不相干的其它系统认证授权功能。久而久之就没有人愿意维护这部分代码了。为了解决这个问题，下面我们使用策略模式来重构该功能。

#### 策略模式定义

> 策略模式定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。

策略模式的核心在于封装变化，在我们系统中就是定义多个不同系统的认证授权策略（算法族），分别封装成独立的类。拦截器（客户）在运行时根据具体的请求 URI 来动态调用相应系统的认证授权算法。当某一系统的认证授权逻辑发生变化或增加新的子系统时，我们只需要修改或增加相应的策略类，而不会影响到其它的策略类（子系统）和客户（拦截器）。

#### 重构步骤

1.  在`io.github.xxyopen.novel.core.auth`包下创建 AuthStrategy 接口，该接口定义了一个默认的方法实现用户端所有子系统都需要的统一账号认证逻辑和一个封装各个系统独立认证授权逻辑的待实现方法（例如，作家管理系统还需要验证作家账号是否存在和作家状态是否正常）：

```java
/**
 * 策略模式实现用户认证授权功能
 *
 * @author xiongxiaoyang
 * @date 2022/5/18
 */
public interface AuthStrategy {

    /**
     * 用户认证授权
     *
     * @param token      登录 token
     * @param requestUri 请求的 URI
     * @throws BusinessException 认证失败则抛出业务异常
     */
    void auth(String token, String requestUri) throws BusinessException;

    /**
     * 前台多系统单点登录统一账号认证（门户系统、作家系统以及后面会扩展的漫画系统和视频系统等）
     *
     * @param jwtUtils             jwt 工具
     * @param userInfoCacheManager 用户缓存管理对象
     * @param token                token 登录 token
     * @return 用户ID
     */
    default Long authSSO(JwtUtils jwtUtils, UserInfoCacheManager userInfoCacheManager,
        String token) {
        if (!StringUtils.hasText(token)) {
            // token 为空
            throw new BusinessException(ErrorCodeEnum.USER_LOGIN_EXPIRED);
        }
        Long userId = jwtUtils.parseToken(token, SystemConfigConsts.NOVEL_FRONT_KEY);
        if (Objects.isNull(userId)) {
            // token 解析失败
            throw new BusinessException(ErrorCodeEnum.USER_LOGIN_EXPIRED);
        }
        UserInfoDto userInfo = userInfoCacheManager.getUser(userId);
        if (Objects.isNull(userInfo)) {
            // 用户不存在
            throw new BusinessException(ErrorCodeEnum.USER_ACCOUNT_NOT_EXIST);
        }
        // 设置 userId 到当前线程
        UserHolder.setUserId(userId);
        // 返回 userId
        return userId;
    }

}
```

2.  接着在该包下创建各个系统的认证授权策略类，实现上述的 AuthStrategy 接口：

```java
/**
 * 前台门户系统 认证授权策略
 *
 * @author xiongxiaoyang
 * @date 2022/5/18
 */
@Component
@RequiredArgsConstructor
public class FrontAuthStrategy implements AuthStrategy {

    private final JwtUtils jwtUtils;

    private final UserInfoCacheManager userInfoCacheManager;

    @Override
    public void auth(String token, String requestUri) throws BusinessException {
        // 统一账号认证
        authSSO(jwtUtils, userInfoCacheManager, token);
    }

}
```

```java
/**
 * 作家后台管理系统 认证授权策略
 *
 * @author xiongxiaoyang
 * @date 2022/5/18
 */
@Component
@RequiredArgsConstructor
public class AuthorAuthStrategy implements AuthStrategy {

    private final JwtUtils jwtUtils;

    private final UserInfoCacheManager userInfoCacheManager;

    private final AuthorInfoCacheManager authorInfoCacheManager;

    /**
     * 不需要进行作家权限认证的 URI
     */
    private static final List<String> EXCLUDE_URI = List.of(
        ApiRouterConsts.API_AUTHOR_URL_PREFIX + "/register",
        ApiRouterConsts.API_AUTHOR_URL_PREFIX + "/status"
    );

    @Override
    public void auth(String token, String requestUri) throws BusinessException {
        // 统一账号认证
        Long userId = authSSO(jwtUtils, userInfoCacheManager, token);
        if (EXCLUDE_URI.contains(requestUri)) {
            // 该请求不需要进行作家权限认证
            return;
        }
        // 作家权限校验
        AuthorInfoDto authorInfo = authorInfoCacheManager.getAuthor(userId);
        if (Objects.isNull(authorInfo)) {
            // 作家账号不存在，无权访问作家专区
            throw new BusinessException(ErrorCodeEnum.USER_UN_AUTH);
        }

        // 设置作家ID到当前线程
        UserHolder.setAuthorId(authorInfo.getId());
    }
    
}
```

```java
/**
 * 平台后台管理系统 认证授权策略
 *
 * @author xiongxiaoyang
 * @date 2022/5/18
 */
@Component
@RequiredArgsConstructor
public class AdminAuthStrategy implements AuthStrategy {

    @Override
    public void auth(String token, String requestUri) throws BusinessException {
        // TODO 平台后台 token 校验
    }
    
}
```

3.  最后在拦截器中根据请求 URI 动态调用相应策略：

```java
/**
 * 认证授权 拦截器
 * 为了注入其它的 Spring beans，需要通过 @Component 注解将该拦截器注册到 Spring 上下文
 *
 * @author xiongxiaoyang
 * @date 2022/5/18
 */
@Component
@RequiredArgsConstructor
public class AuthInterceptor implements HandlerInterceptor {

    //Spring构造器注入
    private final Map<String,AuthStrategy> authStrategy;

    private final ObjectMapper objectMapper;

    @SuppressWarnings("NullableProblems")
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        // 获取登录 JWT
        String token = request.getHeader(SystemConfigConsts.HTTP_AUTH_HEADER_NAME);

        // 获取请求的 URI
        String requestUri = request.getRequestURI();

        // 根据请求的 URI 得到认证策略
        String subUri = requestUri.substring(ApiRouterConsts.API_URL_PREFIX.length() + 1);
        String systemName = subUri.substring(0,subUri.indexOf("/"));
        String authStrategyName = String.format("%sAuthStrategy",systemName);

        // 开始认证
        try {
            authStrategy.get(authStrategyName).auth(token);
            return HandlerInterceptor.super.preHandle(request, response, handler);
        }catch (BusinessException exception){
            // 认证失败
            response.setCharacterEncoding(StandardCharsets.UTF_8.name());
            response.setContentType(MediaType.APPLICATION_JSON_VALUE);
            response.getWriter().write(objectMapper.writeValueAsString(RestResp.fail(exception.getErrorCodeEnum())));
            return false;
        }
    }

    @SuppressWarnings("NullableProblems")
    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        // 清理当前线程保存的用户数据
        UserHolder.clear();
        HandlerInterceptor.super.postHandle(request, response, handler, modelAndView);
    }
}
```

### 使用装饰者模式解决表单形式传参的 XSS 攻击

#### XSS 攻击定义

> 跨站脚本攻击（XSS），是最普遍的 Web 应用安全漏洞。能够使得攻击者嵌入恶意脚本代码到正常用户会访问到的页面中，当正常用户访问该页面时，则可导致嵌入的恶意脚本代码的执行，从而达到恶意攻击用户的目的。

例如，在 novel 项目中，如果没有预防 XSS 攻击的话。恶意用户进入到我们小说评论区，发表如下评论：

```js
<script>
    // 获取当前登录用户的认证 token
    token = localStorage.getItem('Authorization');
    // TODO 通过 ajax 请求发送该 token 到恶意用户的指定服务器
</script>
```

当其他正常用户登录成功进入到小说评论区后，会自动执行上述的 javascript 脚本，自己的登录 token 会被发送到攻击者的服务器上。攻击者拿到该 token 后即可利用该 token 来冒充正常用户进行一系列例如资金转账等危险操作。

攻击者还可以利用该漏洞在我们系统中插入恶意内容（例如广告）、重定向用户（重定向到黄赌毒网站）等。

注：人们经常将跨站脚本攻击（Cross Site Scripting）缩写为 CSS，但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为 XSS。

#### 装饰者模式定义

> 动态将责任附加到对象上。想要扩展功能，装饰者提供有别于继承的另一种选择。

装饰者可以在被装饰者的行为前面与/或后面加上自己的行为，甚至将被装饰者的行为整个取代掉，而达到特定的目的。

Spring MVC 是通过 HttpServletRequest 的 getParameterValues 方法来获取用户端的请求参数并绑定到我们 @RequestMapping 方法定义的对象上。所以我们可以装饰 HttpServletRequest 对象，在 getParameterValues 方法里加上自己的行为（对请求参数值里面的特殊字符进行转义）来解决 XSS 攻击。

由于 Servlet Api 提供了 HttpServletRequest 接口的便捷实现 HttpServletRequestWrapper 类，该类已经实现了装饰者模式，我们直接继承该类并重写里面的 getParameterValues 方法即可。

#### 实现步骤

1.  新建 XssHttpServletRequestWrapper 装饰者类继承 HttpServletRequestWrapper 类，并重写 getParameterValues 方法，对里面字符串的特殊字符进行转义：

```java
public class XssHttpServletRequestWrapper extends HttpServletRequestWrapper {

    private static final Map<String,String> REPLACE_RULE = new HashMap<>();

    static {
        REPLACE_RULE.put("<", "&amp;lt;");
        REPLACE_RULE.put(">", "&amp;gt;");
    }

    public XssHttpServletRequestWrapper(HttpServletRequest request) {
        super(request);
    }

    @Override
    public String[] getParameterValues(String name) {
        String[] values = super.getParameterValues(name);
        if (values != null) {
            int length = values.length;
            String[] escapeValues = new String[length];
            for (int i = 0; i < length; i++) {
                escapeValues[i] = values[i];
                int index = i;
                REPLACE_RULE.forEach((k, v)-> escapeValues[index] = escapeValues[index].replaceAll(k, v));
            }
            return escapeValues;
        }
        return new String[0];
    }
}
```

2.  新建 XssFilter 过滤器，使用 XssHttpServletRequestWrapper 装饰者对象替换掉 HttpServletRequest 被装饰者对象：

```java
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        XssHttpServletRequestWrapper xssRequest = new XssHttpServletRequestWrapper((HttpServletRequest) servletRequest);
        filterChain.doFilter(xssRequest, servletResponse);
    }
```

### 使用模版方法模式实现可拓展的消息发送器

#### 背景

随着系统业务的发展，为了更好的用户体验，需要在包括会员注册成功、代币充值成功、秒杀活动即将开始、账户封禁、小说下架等特定事件发生时发送各种类型的消息，包括系统通知、邮件、短信、微信通知等，每种事件发生时需要发送的消息格式都不一样，需要发送的消息类型也不一样，而且这些需求可能随时都会发生变化，那么如何设计一个灵活的消息发送系统来应对这种多变的需求呢？为了解决这个问题，我们使用模版方法模式进行设计。

#### 模版方法模式定义

> 在一个方法中定义一个算法的骨架，而将一些步骤延续到子类中。模版方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。有了模版方法，我们可以像专家一样复用代码，同时保持对算法的控制。

#### 实现思路

在我们系统中，消息发送的算法（发送的步骤）是一致的，大概分为以下 5 个步骤：

1.  获取消息标题模版
2.  获取消息内容模版
3.  解析消息模版，得到最终需要发送的消息标题
4.  解析消息内容，得到最终需要发送的消息内容
5.  发送消息

这个时候我们可以定义一个抽象的消息发送器 `AbstractMessageSender`，并在消息发送的模版方法 `sendMessage` 中封装消息发送的算法，为了防止子类修改该模版中定义的算法，我们还需要将 `sendMessage` 方法声明为 `final`。

```java
public abstract class AbstractMessageSender implements MessageSender {

    /**
     * 定义消息发送的模版，子类不能修改此模版
     */
    @Override
    public final void sendMessage(Long toUserId, Object... args) {
        // 1.获取消息标题模版
        String titleTemplate = getTitleTemplate();
        // 2.获取消息内容模版
        String contentTemplate = getContentTemplate();
        // 3.解析消息模版，得到最终需要发送的消息标题
        String title = resolveTitle(titleTemplate, args);
        // 4.解析消息内容，得到最终需要发送的消息内容
        String content = resolveContent(contentTemplate, args);
        // 5.发送消息
        sendMessage(toUserId, title, content);
    }

}
```

不同类型的消息决定了消息实际送达的位置不一样，例如：系统通知需要将消息保存到数据库、邮件消息需要发送到用户的邮箱、短信消息需要发送到对方的手机号、微信通知需要发送到对方的微信等等。所以消息发送算法中的第 5 个步骤应该定义成抽象的方法，然后由不同子类型的消息发送器（邮件发送器、系统通知发送器等）去实现该步骤。

```java
public abstract class AbstractMailSender extends AbstractMessageSender {

    @Override
    protected void sendMessage(Long toUserId, String messageTitle, String messageContent) {
        // TODO 根据消息接收方的用户ID查询出消息接收方的邮件地址
        String toEmail = "xxyopen@foxmail.com";
        // 开始发送邮件
        log.info("发送 HTML 邮件开始：{},{},{}", toEmail, messageTitle, messageContent);
        // 使用 MimeMessage，MIME 协议
        MimeMessage message = mailSender.createMimeMessage();
        MimeMessageHelper helper;
        // MimeMessageHelper 帮助我们设置更丰富的内容
        try {
            helper = new MimeMessageHelper(message, true);
            helper.setFrom(new InternetAddress(mailProperties.username(), mailProperties.nickname(), "UTF-8"));
            helper.setTo(toEmail);
            helper.setSubject(messageTitle);
            // 第二个参数 true 代表支持 html
            helper.setText(messageContent, true);
            mailSender.send(message);
            log.info("发送 HTML 邮件 to {} 成功", toEmail);
        } catch (Exception e) {
            // 邮件发送失败不会重试
            log.error("发送 HTML 邮件 to {} 失败", toEmail, e);
        }
    }

}
```

不同类型（系统通知、邮件、短信、微信通知等）的消息以及不同发送时机（会员注册成功、代币充值成功、秒杀活动即将开始、账户封禁、小说下架等）的消息决定了不同的消息格式（消息标题格式和消息内容格式），这些消息格式没有规律可循，只有具体的消息发送器才知道，所以消息发送算法中的第 1 个和第 2 个步骤需要定义成抽象的，然后由每个具体的消息发送器来制定消息模版。

```java
public class RegisterMailSender extends AbstractMailSender {

    @Override
    protected String getTitleTemplate() {
        return "欢迎来到小说精品屋";
    }

    @Override
    protected String getContentTemplate() {
        return """
                <div>
                    感谢你注册小说精品屋！你的账户现在处于活动状态。
                </div>
                <ul>
                    <li> 你的账户电子邮件：{}
                    <li> 你的账户用户名：{}
                </ul>
                <div style="padding: 10px 0 50px 0; text-align: center;">
                    <a style="background: #0274be; color: #fff; padding: 12px 30px; text-decoration: none; border-radius: 3px; letter-spacing: 0.3px;" href="{}" target="_blank" rel="noopener">
                        登录我们的网站
                    </a>
                </div>
                
                如果你有任何问题，请通过 {} 与我们联系。
            """;
    }

}
```

对于相同类型和相同发送时机的消息来说，虽然消息标题和消息内容的格式相同，但是文本内容可能是不同的，所以还需要第 3 步将消息标题模版解析成最终需要发送的消息标题和第 4 步将消息内容模版解析成最终需要发送的消息内容才能执行真正消息发送的逻辑。

虽然如此，但是在这种情况下消息标题的内容大部分都是固定的，所以在抽象的消息发送器 `AbstractMessageSender`中会实现一个默认的消息标题解析逻辑：直接返回消息模版内容，不做任何解析；消息内容大部分虽然是动态的，但也是有规律可循的，所以在抽象的消息发送器 `AbstractMessageSender`中会实现一个可以满足大部分需求的消息内容解析逻辑：直接使用动态参数列表替换消息内容模版中的占位符。特定的消息发送器可以自定义消息标题模版和消息内容模版的解析逻辑。

```java
public abstract class AbstractMessageSender implements MessageSender {

    /**
     * 通过给定的参数列表解析消息标题模版，默认固定标题，不需要解析，可以由子类来拓展它的功能
     *
     * @param titleTemplate 消息标题模版
     * @param arguments     用来解析的参数列表
     * @return 解析后的消息标题
     */
    protected String resolveTitle(String titleTemplate, Object... arguments) {
        return titleTemplate;
    }

    /**
     * 通过给定的参数列表解析消息内容模版，默认实现是使用参数列表来替换消息内容模版中的占位符，可以由子类来拓展它的功能
     * <p>
     * 子类可以根据第一个/前几个参数去数据库中查询动态内容，然后重组参数列表
     *
     * @param contentTemplate 消息内容模版
     * @param args            用来解析的参数列表
     * @return 解析后的消息内容
     */
    protected String resolveContent(String contentTemplate, Object... args) {
        if (args.length > 0) {
            StringBuilder formattedContent = new StringBuilder(contentTemplate);
            for (Object arg : args) {
                int start = formattedContent.indexOf(PLACEHOLDER);
                formattedContent.replace(start, start + PLACEHOLDER.length(),
                    String.valueOf(arg));
            }
            return formattedContent.toString();
        }
        return contentTemplate;
    }
    
}
```

```java
public class RegisterMailSender extends AbstractMailSender {

    @Override
    protected String getTitleTemplate() {
        return "欢迎来到小说精品屋";
    }

    @Override
    protected String getContentTemplate() {
        return """
                <div>
                    感谢你注册小说精品屋！你的账户现在处于活动状态。
                </div>
                <ul>
                    <li> 你的账户电子邮件：{}
                    <li> 你的账户用户名：{}
                </ul>
                <div style="padding: 10px 0 50px 0; text-align: center;">
                    <a style="background: #0274be; color: #fff; padding: 12px 30px; text-decoration: none; border-radius: 3px; letter-spacing: 0.3px;" href="{}" target="_blank" rel="noopener">
                        登录我们的网站
                    </a>
                </div>
                
                如果你有任何问题，请通过 {} 与我们联系。
            """;
    }

    @Override
    protected String resolveContent(String content, Object... args) {
        // TODO 去数据库/配置文件中查询网站配置
        String websiteLink = "https://www.xxyopen.com";
        String websiteEmail = "xxyopen@foxmail.com";
        return super.resolveContent(content,
            Stream.of(args, new Object[]{websiteLink, websiteEmail}).flatMap(Arrays::stream).toArray());
    }

}
```

这个时候，如果需求发生变化，需要新增一个消息类型，或者新增一个需要发送消息的事件，我们只需要创建相应的消息发送器，不需要修改之前的代码，而且新创建的消息发送器可以做到只提供消息标题模版和消息内容模版即可正常工作的程度。大大提高了程序的可拓展性和代码最大程度的复用。

#### 实现步骤

1.  创建消息发送器接口 `MessageSender`，定义消息发送的模版方法。

```java
/**
 * 消息发送器接口，用来发送各种消息
 * <p>
 * 消息按类型分系统通知、邮件、短信、小程序通知等，按发送时机分注册成功消息、充值成功消息、活动通知消息、账户封禁消息、小说下架消息等
 *
 * @author xiongxiaoyang
 * @date 2023/3/25
 */
public interface MessageSender {

    /**
     * 发送消息，支持动态消息标题和动态消息内容
     *
     * @param toUserId 消息接收方的用户ID
     * @param args     用来动态生成消息标题和消息内容的参数列表
     */
    void sendMessage(Long toUserId, Object... args);

}
```

2.  创建抽象的消息发送器 `AbstractMessageSender`，实现消息发送的算法。

```java
/**
 * 抽象的消息发送器
 * <p>
 * 遵循松耦合的设计原则，所有的属性都使用构造函数注入，与 Spring 框架解藕
 * <p>
 * 所有的消息发送器既可以注册到 Spring 容器中，作为 Spring 的一个组件使用，也可以直接通过 new 对象的方式使用
 * <p>
 * 每种类型的消息发送时机可能都不一样，不同类型和发送时机的消息格式可能也不一样，所以由各个子类去拓展消息的格式
 *
 * @author xiongxiaoyang
 * @date 2023/3/24
 */
public abstract class AbstractMessageSender implements MessageSender {

    private static final String PLACEHOLDER = "{}";

    /**
     * 定义消息发送的模版，子类不能修改此模版
     */
    @Override
    public final void sendMessage(Long toUserId, Object... args) {
        // 1.获取消息标题模版
        String titleTemplate = getTitleTemplate();
        // 2.获取消息内容模版
        String contentTemplate = getContentTemplate();
        // 3.解析消息模版，得到最终需要发送的消息标题
        String title = resolveTitle(titleTemplate, args);
        // 4.解析消息内容，得到最终需要发送的消息内容
        String content = resolveContent(contentTemplate, args);
        // 5.发送消息
        sendMessage(toUserId, title, content);
    }

    /**
     * 发送消息，具体发送到哪里由子类决定
     *
     * @param toUserId       消息接收方的用户ID
     * @param messageTitle   消息标题
     * @param messageContent 消息内容
     */
    protected abstract void sendMessage(Long toUserId, String messageTitle, String messageContent);

    /**
     * 获取消息标题的模版，具体如何制定模版由子类决定
     *
     * @return 消息标题
     */
    protected abstract String getTitleTemplate();

    /**
     * 获取消息内容的模版，具体如何制定模版由子类决定
     *
     * @return 消息内容
     */
    protected abstract String getContentTemplate();

    /**
     * 通过给定的参数列表解析消息标题模版，默认固定标题，不需要解析，可以由子类来拓展它的功能
     *
     * @param titleTemplate 消息标题模版
     * @param arguments     用来解析的参数列表
     * @return 解析后的消息标题
     */
    protected String resolveTitle(String titleTemplate, Object... arguments) {
        return titleTemplate;
    }

    /**
     * 通过给定的参数列表解析消息内容模版，默认实现是使用参数列表来替换消息内容模版中的占位符，可以由子类来拓展它的功能
     * <p>
     * 子类可以根据第一个/前几个参数去数据库中查询动态内容，然后重组参数列表
     *
     * @param contentTemplate 消息内容模版
     * @param args            用来解析的参数列表
     * @return 解析后的消息内容
     */
    protected String resolveContent(String contentTemplate, Object... args) {
        if (args.length > 0) {
            StringBuilder formattedContent = new StringBuilder(contentTemplate);
            for (Object arg : args) {
                int start = formattedContent.indexOf(PLACEHOLDER);
                formattedContent.replace(start, start + PLACEHOLDER.length(),
                    String.valueOf(arg));
            }
            return formattedContent.toString();
        }
        return contentTemplate;
    }

}
```

3.  创建抽象的邮件发送器 `AbstractMailSender` 和系统通知发送器 `AbstractSysNoticeSender`，分别发送邮件和系统通知。

```java
/**
 * 抽象的邮件消息发送者
 *
 * @author xiongxiaoyang
 * @date 2023/3/24
 */
@Slf4j
@RequiredArgsConstructor
public abstract class AbstractMailSender extends AbstractMessageSender {

    private final MailProperties mailProperties;

    private final JavaMailSender mailSender;

    @Override
    protected void sendMessage(Long toUserId, String messageTitle, String messageContent) {
        // TODO 根据消息接收方的用户ID查询出消息接收方的邮件地址
        String toEmail = "xxyopen@foxmail.com";
        // 开始发送邮件
        log.info("发送 HTML 邮件开始：{},{},{}", toEmail, messageTitle, messageContent);
        // 使用 MimeMessage，MIME 协议
        MimeMessage message = mailSender.createMimeMessage();
        MimeMessageHelper helper;
        // MimeMessageHelper 帮助我们设置更丰富的内容
        try {
            helper = new MimeMessageHelper(message, true);
            helper.setFrom(new InternetAddress(mailProperties.username(), mailProperties.nickname(), "UTF-8"));
            helper.setTo(toEmail);
            helper.setSubject(messageTitle);
            // 第二个参数 true 代表支持 html
            helper.setText(messageContent, true);
            mailSender.send(message);
            log.info("发送 HTML 邮件 to {} 成功", toEmail);
        } catch (Exception e) {
            // 邮件发送失败不会重试
            log.error("发送 HTML 邮件 to {} 失败", toEmail, e);
        }
    }

}
```

```java
/**
 * 抽象的系统通知发送者
 *
 * @author xiongxiaoyang
 * @date 2023/3/24
 */
@Slf4j
public abstract class AbstractSysNoticeSender extends AbstractMessageSender {

    @Override
    protected void sendMessage(Long toUserId, String messageTitle, String messageContent) {
        // 生成消息的发送时间
        LocalDateTime messageDateTime = LocalDateTime.now();
        // TODO 在数据库系统通知表中插入一条记录
        log.info("系统通知发送成功，{},{},{},{}", toUserId, messageDateTime.format(DateTimeFormatter.ISO_DATE_TIME),
            messageTitle, messageContent);
    }

}
```

4.  创建注册成功的邮件发送器 `RegisterMailSender` 和秒杀活动的系统通知发送器 `SeckillSystemNoticeSender`。

```java
/**
 * 注册成功的邮件发送器
 *
 * @author xiongxiaoyang
 * @date 2023/3/24
 */
@Component(value = MessageSenderTypeConsts.REGISTER_MAIL_SENDER)
@EnableConfigurationProperties(MailProperties.class)
public class RegisterMailSender extends AbstractMailSender {

    public RegisterMailSender(MailProperties mailProperties, JavaMailSender mailSender) {
        super(mailProperties, mailSender);
    }

    @Override
    protected String getTitleTemplate() {
        return "欢迎来到小说精品屋";
    }

    @Override
    protected String getContentTemplate() {
        return """
                <div>
                    感谢你注册小说精品屋！你的账户现在处于活动状态。
                </div>
                <ul>
                    <li> 你的账户电子邮件：{}
                    <li> 你的账户用户名：{}
                </ul>
                <div style="padding: 10px 0 50px 0; text-align: center;">
                    <a style="background: #0274be; color: #fff; padding: 12px 30px; text-decoration: none; border-radius: 3px; letter-spacing: 0.3px;" href="{}" target="_blank" rel="noopener">
                        登录我们的网站
                    </a>
                </div>
                
                如果你有任何问题，请通过 {} 与我们联系。
            """;
    }

    @Override
    protected String resolveContent(String content, Object... args) {
        // TODO 去数据库/配置文件中查询网站配置
        String websiteLink = "https://www.xxyopen.com";
        String websiteEmail = "xxyopen@foxmail.com";
        return super.resolveContent(content,
            Stream.of(args, new Object[]{websiteLink, websiteEmail}).flatMap(Arrays::stream).toArray());
    }

}
```

```java
/**
 * 秒杀活动的系统通知发送器
 *
 * @author xiongxiaoyang
 * @date 2023/3/24
 */
@Component(value = MessageSenderTypeConsts.SECKILL_SYS_NOTICE_SENDER)
public class SeckillSystemNoticeSender extends AbstractSysNoticeSender {

    @Override
    protected String getTitleTemplate() {
        return "秒杀即将开始";
    }

    @Override
    protected String getContentTemplate() {
        return "{}秒杀，{}即将开始，不要错过哦！点击 {} 前往。";
    }

}
```

5.  消息发送测试

```java
@RunWith(SpringRunner.class)
@SpringBootTest(classes = NovelApplication.class)
public class MessageSenderTest{

    @Autowired
    private Map<String, AbstractMessageSender> messageSenders;

    @Test
    public void test{
        MessageSender registerMailSender = messageSenders.get(
            MessageSenderTypeConsts.REGISTER_MAIL_SENDER);
        if (Objects.nonNull(registerMailSender)) {
            registerMailSender.sendMessage(11111L, "xxyopen@foxmail.com", "xxyopen");
        }
        MessageSender seckillSysNoticeSender = messageSenders.get(
            MessageSenderTypeConsts.SECKILL_SYS_NOTICE_SENDER);
        if (Objects.nonNull(registerMailSender)) {
            seckillSysNoticeSender.sendMessage(11111L, "全场商品", "今晚 9 点", "www.xxyopen.com");
        }
    }

}
```

### 一行代码解决 JSON 形式传参的 XSS 攻击

#### 问题

前后端分离项目，对于 POST 和 PUT 类型的请求方法，后端基本都是通过 @RequestBody 注解接收 application/json 格式的请求数据，所以以前通过过滤器 + 装饰器 HttpServletRequestWrapper 来解决 XSS 攻击的方式并不适用。在 Spring Boot 中，我们可以通过配置全局的 Json 反序列化器转义特殊字符来解决 XSS 攻击。

#### 实现代码

```java
/**
 * JSON 全局反序列化器
 *
 * @author xiongxiaoyang
 * @date 2022/5/21
 */
@JsonComponent
public class GlobalJsonDeserializer {

    /**
     * 字符串反序列化器
     * 过滤特殊字符，解决 XSS 攻击
     */
    public static class StringDeserializer extends JsonDeserializer<String> {

        @Override
        public String deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JacksonException {
// 实际代码就这一行
            return jsonParser.getValueAsString()
                    .replace("<", "&amp;lt;")
                    .replace(">", "&amp;gt;");
        }
    }
}
```

### 集成 Elasticsearch 8，实现搜索引擎动态切换

1.  [搜索引擎 Elasticsearch 集成与配置](#搜索引擎 Elasticsearch 集成与配置)
    
2.  在 application.yml 中增加 `spring.elasticsearch.enable` 配置项用来控制 Elasticsearch 搜索引擎功能是否开启：


```yaml
spring:
  elasticsearch:
    # 是否开启 elasticsearch 搜索引擎功能：true-开启 false-不开启
    enable: false
```

3.  新建搜索服务类：

```java
/**
 * 搜索 服务类
 *
 * @author xiongxiaoyang
 * @date 2022/5/23
 */
public interface SearchService {

    /**
     * 小说搜索
     *
     * @param condition 搜索条件
     * @return 搜索结果
     */
    RestResp<PageRespDto<BookInfoRespDto>> searchBooks(BookSearchReqDto condition);

}
```

4.  新建`数据库搜索`服务实现类，实现从数据库中检索小说的业务逻辑，由配置项`spring.elasticsearch.enable`控制当 elasticsearch 关闭时生效：

```java
/**
 * 数据库搜索 服务实现类
 *
 * @author xiongxiaoyang
 * @date 2022/5/23
 */
@ConditionalOnProperty(prefix = "spring.elasticsearch", name = "enable", havingValue = "false")
@Service
@RequiredArgsConstructor
@Slf4j
public class DbSearchServiceImpl implements SearchService {

    private final BookInfoMapper bookInfoMapper;

    @Override
    public RestResp<PageRespDto<BookInfoRespDto>> searchBooks(BookSearchReqDto condition) {
        Page<BookInfoRespDto> page = new Page<>();
        page.setCurrent(condition.getPageNum());
        page.setSize(condition.getPageSize());
        List<BookInfo> bookInfos = bookInfoMapper.searchBooks(page, condition);
        return RestResp.ok(PageRespDto.of(condition.getPageNum(), condition.getPageSize(), page.getTotal()
                , bookInfos.stream().map(v -> BookInfoRespDto.builder()
                        .id(v.getId())
                        .bookName(v.getBookName())
                        .categoryId(v.getCategoryId())
                        .categoryName(v.getCategoryName())
                        .authorId(v.getAuthorId())
                        .authorName(v.getAuthorName())
                        .wordCount(v.getWordCount())
                        .lastChapterName(v.getLastChapterName())
                        .build()).toList()));
    }

}
```

5.  新建`Elasticsearch 搜索引擎搜索`服务实现类，实现从 Elasticsearch 中检索小说的业务逻辑，由配置项`spring.elasticsearch.enable`控制当 elasticsearch 开启时生效：

```java
/**
 * Elasticsearch 搜索 服务实现类
 *
 * @author xiongxiaoyang
 * @date 2022/5/23
 */
@ConditionalOnProperty(prefix = "spring.elasticsearch", name = "enable", havingValue = "true")
@Service
@RequiredArgsConstructor
@Slf4j
public class EsSearchServiceImpl implements SearchService {

    private final ElasticsearchClient esClient;

    @SneakyThrows
    @Override
    public RestResp<PageRespDto<BookInfoRespDto>> searchBooks(BookSearchReqDto condition) {

        SearchResponse<EsBookDto> response = esClient.search(s -> {

                    SearchRequest.Builder searchBuilder = s.index(EsConsts.IndexEnum.BOOK.getName());
                    buildSearchCondition(condition, searchBuilder);
                    // 排序
                    if (!StringUtils.isBlank(condition.getSort())) {
                        searchBuilder.sort(o ->
                                o.field(f -> f.field(StringUtils
                                                .underlineToCamel(condition.getSort().split(" ")[0]))
                                        .order(SortOrder.Desc))
                        );
                    }
                    // 分页
                    searchBuilder.from((condition.getPageNum() - 1) * condition.getPageSize())
                            .size(condition.getPageSize());

                    return searchBuilder;
                },
                EsBookDto.class
        );

        TotalHits total = response.hits().total();

        List<BookInfoRespDto> list = new ArrayList<>();
        List<Hit<EsBookDto>> hits = response.hits().hits();
        for (Hit<EsBookDto> hit : hits) {
            EsBookDto book = hit.source();
            assert book != null;
            list.add(BookInfoRespDto.builder()
                    .id(book.getId())
                    .bookName(book.getBookName())
                    .categoryId(book.getCategoryId())
                    .categoryName(book.getCategoryName())
                    .authorId(book.getAuthorId())
                    .authorName(book.getAuthorName())
                    .wordCount(book.getWordCount())
                    .lastChapterName(book.getLastChapterName())
                    .build());
        }
        assert total != null;
        return RestResp.ok(PageRespDto.of(condition.getPageNum(), condition.getPageSize(), total.value(), list));
    
    }

    /**
    * 构建查询条件
    */
    private void buildSearchCondition(BookSearchReqDto condition, SearchRequest.Builder searchBuilder) {

        BoolQuery boolQuery = BoolQuery.of(b -> {

            if (!StringUtils.isBlank(condition.getKeyword())) {
                // 关键词匹配
                b.must((q -> q.multiMatch(t -> t
                        .fields("bookName^2","authorName^1.8","bookDesc^0.1")
                        .query(condition.getKeyword())
                )
                ));
            }

            // 精确查询
            if (Objects.nonNull(condition.getWorkDirection())) {
                b.must(TermQuery.of(m -> m
                        .field("workDirection")
                        .value(condition.getWorkDirection())
                )._toQuery());
            }

            if (Objects.nonNull(condition.getCategoryId())) {
                b.must(TermQuery.of(m -> m
                        .field("categoryId")
                        .value(condition.getCategoryId())
                )._toQuery());
            }

            // 范围查询
            if (Objects.nonNull(condition.getWordCountMin())) {
                b.must(RangeQuery.of(m -> m
                        .field("wordCount")
                        .gte(JsonData.of(condition.getWordCountMin()))
                )._toQuery());
            }

            if (Objects.nonNull(condition.getWordCountMax())) {
                b.must(RangeQuery.of(m -> m
                        .field("wordCount")
                        .lt(JsonData.of(condition.getWordCountMax()))
                )._toQuery());
            }

            if (Objects.nonNull(condition.getUpdateTimeMin())) {
                b.must(RangeQuery.of(m -> m
                        .field("lastChapterUpdateTime")
                        .gte(JsonData.of(condition.getUpdateTimeMin().getTime()))
                )._toQuery());
            }

            return b;

        });

        searchBuilder.query(q -> q.bool(boolQuery));

    }
}
```

6.  `BookController` 中注入 `SearchService` bean，调用`searchBooks`方法实现按配置动态切换搜索引擎的功能：

```java
public class BookController {

    private final SearchService searchService;

    /**
     * 小说搜索接口
     */
    @GetMapping("search_list")
    public RestResp<PageRespDto<BookInfoRespDto>> searchBooks(BookSearchReqDto condition) {
        return searchService.searchBooks(condition);
    }

}
```

### 使用 RabbitMQ 刷新 ES/Redis/Caffeine 等小说副本数据

在 novel 分布式环境中，数据库中的小说信息可能会在多个地方保存一份副本数据。例如，为了减轻数据库压力，提高并发和系统性能的本地缓存 Caffeine 和分布式缓存 Redis、为了实现小说全文高级检索的 Elasticsearch 搜索引擎等。有时为了应对小说详情页的高并发访问和 SEO 优化，我们还会选择为每一本小说生成静态化的页面，通过 Nginx 或 CDN 来访问。

此时，如果小说信息发生变更，那么如何通知所有的副本数据和静态页面更新呢？如果随着业务的发展和系统的演进，我们需要在 MongoDB 中增加一份存储副本，那么怎么在不修改调用方（所有小说信息发生变更的地方。例如，作家更新小说信息、作家发布新的章节或平台下架违规小说等场景）代码，不影响原先功能（其它副本数据的刷新）的同时，又能及时刷新 MongoDB 中的副本数据，实现模块间的解耦呢？

我们通过消息中间件来解决以上问题，实现步骤如下：

1.  [Spring AMQP 集成与配置](#Spring AMQP 集成与配置)
    
2.  在`io.github.xxyopen.novel.core.constant`包下创建 AMQP 相关常量类：
    

```java
/**
 * AMQP 相关常量
 *
 * @author xiongxiaoyang
 * @date 2022/5/25
 */
public class AmqpConsts {

    /**
     * 小说信息改变 MQ
     * */
    public static class BookChangeMq{

        /**
         * 小说信息改变交换机
         * */
        public static final String EXCHANGE_NAME = "EXCHANGE-BOOK-CHANGE";

        /**
         * Elasticsearch book 索引更新的队列
         * */
        public static final String QUEUE_ES_UPDATE = "QUEUE-ES-BOOK-UPDATE";

        /**
         * Redis book 缓存更新的队列
         * */
        public static final String QUEUE_REDIS_UPDATE = "QUEUE-REDIS-BOOK-UPDATE";

        // ... 其它的更新队列

    }

}
```

3.  在`io.github.xxyopen.novel.core.config`包下创建 AMQP 配置类，配置各个交换机、队列以及绑定关系：

```java
/**
 * AMQP 配置类
 *
 * @author xiongxiaoyang
 * @date 2022/5/25
 */
@Configuration
public class AmqpConfig {

    /**
     * 小说信息改变交换机
     */
    @Bean
    public FanoutExchange bookChangeExchange() {
        return new FanoutExchange(AmqpConsts.BookChangeMq.EXCHANGE_NAME);
    }

    /**
     * Elasticsearch book 索引更新队列
     */
    @Bean
    public Queue esBookUpdateQueue() {
        return new Queue(AmqpConsts.BookChangeMq.QUEUE_ES_UPDATE);
    }

    /**
     * Elasticsearch book 索引更新队列绑定到小说信息改变交换机
     */
    @Bean
    public Binding esBookUpdateQueueBinding() {
        return BindingBuilder.bind(esBookUpdateQueue()).to(bookChangeExchange());
    }

    // ... 其它的更新队列以及绑定关系

}
```

4.  在`io.github.xxyopen.novel.manager.mq`包下创建 AMQP 消息管理类，用来发送各种 AMQP 消息：

```java
/**
 * AMQP 消息管理类
 *
 * @author xiongxiaoyang
 * @date 2022/5/25
 */
@Component
@RequiredArgsConstructor
public class AmqpMsgManager {

    private final AmqpTemplate amqpTemplate;

    @Value("${spring.amqp.enable}")
    private String enableAmqp;

    /**
     * 发送小说信息改变消息
     */
    public void sendBookChangeMsg(Long bookId) {
        if (Objects.equals(enableAmqp, CommonConsts.TRUE)) {
            sendAmqpMessage(amqpTemplate, AmqpConsts.BookChangeMq.EXCHANGE_NAME, null, bookId);
        }
    }

    private void sendAmqpMessage(AmqpTemplate amqpTemplate, String exchange, String routingKey, Object message) {
        // 如果在事务中则在事务执行完成后再发送，否则可以直接发送
        if (TransactionSynchronizationManager.isActualTransactionActive()) {
            TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() {
                @Override
                public void afterCommit() {
                    amqpTemplate.convertAndSend(exchange, routingKey, message);
                }
            });
            return;
        }
        amqpTemplate.convertAndSend(exchange, routingKey, message);
    }

}
```

5.  在小说信息更新后，发送 AMQP 消息：

```java
@Transactional(rollbackFor = Exception.class)
@Override
public RestResp<Void> saveBookChapter(ChapterAddReqDto dto) {
    // 1) 保存章节相关信息到小说章节表
    //  a) 查询最新章节号
    int chapterNum = 0;
    QueryWrapper<BookChapter> chapterQueryWrapper = new QueryWrapper<>();
    chapterQueryWrapper.eq(DatabaseConsts.BookChapterTable.COLUMN_BOOK_ID,dto.getBookId())
            .orderByDesc(DatabaseConsts.BookChapterTable.COLUMN_CHAPTER_NUM)
            .last(DatabaseConsts.SqlEnum.LIMIT_1.getSql());
    BookChapter bookChapter = bookChapterMapper.selectOne(chapterQueryWrapper);
    if(Objects.nonNull(bookChapter)){
        chapterNum = bookChapter.getChapterNum() + 1;
    }
    //  b) 设置章节相关信息并保存
    BookChapter newBookChapter = new BookChapter();
    newBookChapter.setBookId(dto.getBookId());
    newBookChapter.setChapterName(dto.getChapterName());
    newBookChapter.setChapterNum(chapterNum);
    newBookChapter.setWordCount(dto.getChapterContent().length());
    newBookChapter.setIsVip(dto.getIsVip());
    newBookChapter.setCreateTime(LocalDateTime.now());
    newBookChapter.setUpdateTime(LocalDateTime.now());
    bookChapterMapper.insert(newBookChapter);

    // 2) 保存章节内容到小说内容表
    BookContent bookContent = new BookContent();
    bookContent.setContent(dto.getChapterContent());
    bookContent.setChapterId(newBookChapter.getId());
    bookContent.setCreateTime(LocalDateTime.now());
    bookContent.setUpdateTime(LocalDateTime.now());
    bookContentMapper.insert(bookContent);

    // 3) 更新小说表最新章节信息和小说总字数信息
    //  a) 更新小说表关于最新章节的信息
    BookInfoRespDto bookInfo = bookInfoCacheManager.getBookInfo(dto.getBookId());
    BookInfo newBookInfo = new BookInfo();
    newBookInfo.setId(dto.getBookId());
    newBookInfo.setLastChapterId(newBookChapter.getId());
    newBookInfo.setLastChapterName(newBookChapter.getChapterName());
    newBookInfo.setLastChapterUpdateTime(LocalDateTime.now());
    newBookInfo.setWordCount(bookInfo.getWordCount() + newBookChapter.getWordCount());
    newBookChapter.setUpdateTime(LocalDateTime.now());
    bookInfoMapper.updateById(newBookInfo);
    //  b) 刷新小说信息缓存
    bookInfoCacheManager.cachePutBookInfo(dto.getBookId());
    //  c) 发送小说信息更新的 MQ 消息
    amqpMsgManager.sendBookChangeMsg(dto.getBookId());
    return RestResp.ok();
}
```

6.  在`io.github.xxyopen.novel.core.listener`包下创建 Rabbit 队列监听器，监听各个 RabbitMQ 队列的消息并处理：

```java
/**
 * Rabbit 队列监听器
 *
 * @author xiongxiaoyang
 * @date 2022/5/25
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class RabbitQueueListener {

    private final BookInfoMapper bookInfoMapper;

    private final ElasticsearchClient esClient;

    /**
     * 监听小说信息改变的 ES 更新队列，更新最新小说信息到 ES
     * */
    @RabbitListener(queues = AmqpConsts.BookChangeMq.QUEUE_ES_UPDATE)
    @SneakyThrows
    public void updateEsBook(Long bookId) {
        BookInfo bookInfo = bookInfoMapper.selectById(bookId);
        IndexResponse response = esClient.index(i -> i
                .index(EsConsts.BookIndex.INDEX_NAME)
                .id(bookInfo.getId().toString())
                .document(EsBookDto.build(bookInfo))
        );
        log.info("Indexed with version " + response.version());
    }

    // ... 监听其它队列，刷新其它副本数据

}
```

此时，如果需要更新其它副本数据，只需要配置更新队列和增加监听器，不需要修改任何业务代码，而且任意副本的数据刷新互不影响，真正实现了模块间的解耦。

**注：当服务集群部署时，由于多个消费者绑定同一个队列是无法同时消费的，一个消息只能被一个消费者消费，所以刷新本地缓存的 MQ 队列命名应该使用`固定名 + 唯一随机值`这种动态形式。这样每次启动会生成一个新的队列，我们需要设置该队列的 autoDelete = true，让所有消费客户端连接断开时自动删除该队列。**

### 使用 XXL-JOB 优化 Elasticsearch 数据同步任务

1.  [分布式任务调度平台 XXL-JOB 集成与配置](#分布式任务调度平台 XXL-JOB 集成与配置)
    
2.  登录调度中心后台，新增 novel 项目任务执行器：
    

![创建任务执行器](pic/xxljobexe.png)

**注：AppName 的值需要和 novel 项目 application.yml 配置文件中配置的值保持一致。**

3.  新增 Elasticsearch 数据同步任务：

![创建任务](pic/xxljobtask.png)

4.  修改`io.github.xxyopen.novel.core.task`包下的 Elasticsearch 数据同步任务（`@Scheduled` 注解 替换为 `@XxlJob` 注解）：

```java
/**
 * 小说数据同步到 Elasticsearch 任务
 *
 * @author xiongxiaoyang
 * @date 2022/5/23
 */
@ConditionalOnProperty(prefix = "spring.elasticsearch", name = "enable", havingValue = "true")
@Component
@RequiredArgsConstructor
@Slf4j
public class BookToEsTask {

    private final BookInfoMapper bookInfoMapper;

    private final ElasticsearchClient elasticsearchClient;

    @SneakyThrows
    @XxlJob("saveToEsJobHandler") // 此处需要和调度中心创建任务时填写的 JobHandler 值保持一致
    public ReturnT<String> saveToEs() {
         try {
            QueryWrapper<BookInfo> queryWrapper = new QueryWrapper<>();
            List<BookInfo> bookInfos;
            long maxId = 0;
            for (; ; ) {
                queryWrapper.clear();
                queryWrapper
                        .orderByAsc(DatabaseConsts.CommonColumnEnum.ID.getName())
                        .gt(DatabaseConsts.CommonColumnEnum.ID.getName(), maxId)
                        .last(DatabaseConsts.SqlEnum.LIMIT_30.getSql());
                bookInfos = bookInfoMapper.selectList(queryWrapper);
                if (bookInfos.isEmpty()) {
                    break;
                }
                BulkRequest.Builder br = new BulkRequest.Builder();

                for (BookInfo book : bookInfos) {
                    br.operations(op -> op
                            .index(idx -> idx
                                    .index(EsConsts.BookIndex.INDEX_NAME)
                                    .id(book.getId().toString())
                                    .document(EsBookDto.build(book))
                            )
                    ).timeout(Time.of(t -> t.time("10s")));
                    maxId = book.getId();
                }

                BulkResponse result = elasticsearchClient.bulk(br.build());

                // Log errors, if any
                if (result.errors()) {
                    log.error("Bulk had errors");
                    for (BulkResponseItem item : result.items()) {
                        if (item.error() != null) {
                            log.error(item.error().reason());
                        }
                    }
                }
            }
            return ReturnT.SUCCESS;
        } catch (Exception e) {
            log.error(e.getMessage(), e);
            return ReturnT.FAIL;
        }
    }

}

```

5.  查看任务执行器，可以发现已经有一台机器自动注册：

![在线注册机器](pic/xxljobonline.png)

6.  进入任务管理，我们可以启动 Elasticsearch 数据同步任务，由配置的 Cron 表达式进行任务调度；也可以选择手动触发一次任务执行：

![任务启动](pic/xxljobtaskexe.png)

此时，我们可以在任意时刻手动同步数据库的小说数据到 Elasticsearch 搜索引擎中，极大的方便了我们的开发测试工作。

### 使用 Sentinel 实现接口防刷和限流

#### 问题

novel 作为一个互联网系统，经常会遇到非法爬虫（例如，盗版小说网站）来爬取我们系统的小说数据，这种爬虫行为有时会高达每秒几百甚至上千次访问。防刷的目的是为了限制这些爬虫请求我们接口的频率，如果我们不做接口防刷限制的话，我们系统很容易就会被爬虫干倒。

限流的目的是在流量高峰期间，根据我们系统的承受能力，限制同时请求的数量，保证多余的请求会阻塞一段时间再处理，不简单粗暴的直接返回错误信息让客户端重试，同时又能起到流量削峰的作用。

很多时候，我们都是尽量将请求拦截在系统上游，比如在反向代理层通过 Nginx + Lua + Redis 来实现限流功能，这个在后面部署篇章里面会详细地讲解如何实现。如果我们系统还没有使用类似于 Nginx 一样的反向代理，又或者我们想实现更复杂的流量控制，想要一个人性化的控制面板来动态限流和实时监控，那么我们可以使用阿里巴巴开源的高可用流控防护组件 Sentinel 来实现。

#### Sentinel 介绍

Sentinel 是一个面向云原生微服务的高可用流控防护组件，以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。

Sentinel 有两个重要的概念，`资源`和`规则`：

**资源**是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。

**规则**是围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。

Sentinel 具有以下特征:

-   丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。
    
-   完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。
    
-   广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Apache Dubbo、gRPC、Quarkus 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。同时 Sentinel 提供 Java/Go/C++ 等多语言的原生实现。
    
-   完善的 SPI 扩展机制：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。
    

Sentinel 分为`核心库`和`控制台`两部分，`核心库`不依赖`控制台`，但是结合`控制台`可以取得最好的效果:

-   核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。
    
-   控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。
    

#### 使用 Sentinel 核心库实现接口防刷和限流

1.  引入 Sentinel 相关依赖：

```xml
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-core</artifactId>
    <version>${sentinel.version}</version>
</dependency>
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-parameter-flow-control</artifactId>
    <version>${sentinel.version}</version>
</dependency>
```

2.  在`io.github.xxyopen.novel.core.config.WebConfig`中注册一个全局的拦截器拦截所有的请求：

```java
// 流量限制拦截器
registry.addInterceptor(flowLimitInterceptor)
        .addPathPatterns("/**")
        .order(0);
```

3.  拦截器中定义资源和规则，资源在`preHandle`方法中定义，为所有请求的入口，`接口限流规则`和`接口防刷规则`通过`static 代码块`在类加载时初始化：

```java
/**
 * 流量限制 拦截器
 * 实现接口防刷和限流
 *
 * @author xiongxiaoyang
 * @date 2022/6/1
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class FlowLimitInterceptor implements HandlerInterceptor {

    private final ObjectMapper objectMapper;

    /**
     * novel 项目所有的资源
     */
    private static final String NOVEL_RESOURCE = "novelResource";

    static {
        // 接口限流规则：所有的请求，限制每秒最多只能通过 2000 个，超出限制匀速排队
        List<FlowRule> rules = new ArrayList<>();
        FlowRule rule1 = new FlowRule();
        rule1.setResource(NOVEL_RESOURCE);
        rule1.setGrade(RuleConstant.FLOW_GRADE_QPS);
        // Set limit QPS to 2000.
        rule1.setCount(2000);
        rule1.setControlBehavior(RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER);
        rules.add(rule1);
        FlowRuleManager.loadRules(rules);

        // 接口防刷规则 1：所有的请求，限制每个 IP 每秒最多只能通过 50 个，超出限制直接拒绝
        ParamFlowRule rule2 = new ParamFlowRule(NOVEL_RESOURCE)
                .setParamIdx(0)
                .setCount(50);
        // 接口防刷规则 2：所有的请求，限制每个 IP 每分钟最多只能通过 1000 个，超出限制直接拒绝
        ParamFlowRule rule3 = new ParamFlowRule(NOVEL_RESOURCE)
                .setParamIdx(0)
                .setCount(1000)
                .setDurationInSec(60);
        ParamFlowRuleManager.loadRules(Arrays.asList(rule2, rule3));
    }

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        String ip = IpUtils.getRealIp(request);
        Entry entry = null;
        try {
            // 若需要配置例外项，则传入的参数只支持基本类型。
            // EntryType 代表流量类型，其中系统规则只对 IN 类型的埋点生效
            // count 大多数情况都填 1，代表统计为一次调用。
            entry = SphU.entry(NOVEL_RESOURCE, EntryType.IN, 1, ip);
            // Your logic here.
            return HandlerInterceptor.super.preHandle(request, response, handler);
        } catch (BlockException ex) {
            // Handle request rejection.
            log.info("IP:{}被限流了！", ip);
            response.setCharacterEncoding(StandardCharsets.UTF_8.name());
            response.setContentType(MediaType.APPLICATION_JSON_VALUE);
            response.getWriter().write(objectMapper.writeValueAsString(RestResp.fail(ErrorCodeEnum.USER_REQ_MANY)));
        } finally {
            // 注意：exit 的时候也一定要带上对应的参数，否则可能会有统计错误。
            if (entry != null) {
                entry.exit(1, ip);
            }
        }
        return false;
    }

}
```

规则属性说明：

| 属性              | 说明                                                         | 默认值   |
| ----------------- | ------------------------------------------------------------ | -------- |
| resource          | 资源名，必填                                                 |          |
| count             | 限流阈值，必填                                               |          |
| grade             | 限流模式                                                     | QPS 模式 |
| durationInSec     | 统计窗口时间长度（单位为秒），1.6.0 版本开始支持             | 1s       |
| controlBehavior   | 流控效果（支持快速失败和匀速排队模式），1.6.0 版本开始支持   | 快速失败 |
| maxQueueingTimeMs | 最大排队等待时长（仅在匀速排队模式生效），1.6.0 版本开始支持 | 0ms      |
| paramIdx          | 热点参数的索引，必填，对应 `SphU.entry(xxx, args)` 中的参数索引位置 |          |
| paramFlowItemList | 参数例外项，可以针对指定的参数值单独设置限流阈值，不受前面 `count` 阈值的限制。**仅支持基本类型和字符串类型** |          |
| clusterMode       | 是否是集群参数流控规则                                       | `false`  |
| clusterConfig     | 集群流控相关配置                                             |          |

我们还可以通过 Sentinel 提供的`注解支持模块`来定义我们的资源，如下所示，helloWorld() 方法成了我们的一个资源：

```java
@SentinelResource("HelloWorld")
public void helloWorld() {
    // 资源中的逻辑
    System.out.println("hello world");
}
```

**注：注解支持模块需要配合 Spring AOP 或者 AspectJ 一起使用。**

此时，我们已经实现了接口防刷和限流的功能，如果我们需要实时监控和管理限流规则，那么我们可以按如下步骤接入 Sentinel 开源控制台：

-   下载控制台 jar 包并在本地启动（账号/密码：sentinel/sentinel）

```
java -Dserver.port=8081 -Dcsp.sentinel.dashboard.server=localhost:8081 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.4.jar
```

-   novel 项目引入 Transport 模块来与 Sentinel 控制台进行通信


```xml
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-transport-simple-http</artifactId>
    <version>1.8.4</version>
</dependency>
```

-   novel 项目启动时加入 JVM 参数 `-Dcsp.sentinel.dashboard.server=localhost:8081` 指定控制台地址和端口
-   确保 novel 项目有访问量

完成以上步骤后即可在 Sentinel 控制台上看到对应的应用，机器列表页面可以看到对应的机器。

### 集成 ShardingSphere-JDBC 优化小说内容存储

#### 背景

传统的将数据集中存储至单一节点的解决方案，在性能、可用性和运维成本这三方面已经难于满足海量数据的场景。

从性能方面来说，由于关系型数据库大多采用 B+ 树类型的索引，在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，进而导致查询性能的下降； 同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈。

从可用性的方面来讲，服务化的无状态性，能够达到较小成本的随意扩容，这必然导致系统的最终压力都落在数据库之上。 而单一的数据节点，或者简单的主从架构，已经越来越难以承担。数据库的可用性，已成为整个系统的关键。

从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，对于 DBA 的运维压力就会增大。 数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。一般来讲，单一数据库实例的数据的阈值在 1TB 之内，是比较合理的范围。

数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。通过分库和分表进行数据的拆分来使得各个表的数据量保持在阈值以下，以及对流量进行疏导应对高访问量，是应对高并发和海量数据系统的有效手段。分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈。

小说数据有着内容多、增长速度快的特点，一本主流的完结小说一般所需存储空间大概在 5MB 以上。一个主流的小说网站在发展中后期，数据量是远远超过单一数据库实例的阈值的，所以我们对小说内容进行分库分表存储是非常有必要的。在发展初期，我们的数据量还不是很大，可以先将小说内容分表存储以减轻数据库单表压力以及为后期的数据库分库做准备。等数据量即将超过阈值时，再迁移到不同的数据库实例上。

**注：数据分片分为按照业务将表进行归类，分布到不同的数据库中的垂直分片和通过某个字段（或某几个字段）按照某种规则将数据分散至多个库或表中的水平分片。**

#### Apache ShardingSphere 介绍

Apache ShardingSphere 产品定位为 Database Plus，它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库。ShardingSphere 站在数据库的上层视角，关注他们之间的协作多于数据库自身，由 JDBC、Proxy 和 Sidecar（规划中）这 3 款既能够独立部署，又支持混合部署配合使用的产品组成。 它们均提供标准化的基于数据库作为存储节点的增量功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。

ShardingSphere-JDBC 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。

ShardingSphere-Proxy 定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。

ShardingSphere-Sidecar 定位为 Kubernetes 的云原生数据库代理，以 Sidecar 的形式代理所有对数据库的访问。 通过无中心、零侵入的方案提供与数据库交互的啮合层，即 Database Mesh，又可称数据库网格。

连接、增量 和 可插拔 是 Apache ShardingSphere 的核心概念：

-   连接：通过对数据库协议、SQL 方言以及数据库存储的灵活适配，快速的连接应用与多模式的异构数据库；
    
-   增量：获取数据库的访问流量，并提供流量重定向（数据分片、读写分离、影子库）、流量变形（数据加密、数据脱敏）、流量鉴权（安全、审计、权限）、流量治理（熔断、限流）以及流量分析（服务质量分析、可观察性）等透明化增量功能；
    
-   可插拔：项目采用微内核 + 三层可插拔模型，使内核、功能组件以及生态对接完全能够灵活的方式进行插拔式扩展，开发者能够像使用积木一样定制属于自己的独特系统。
    

Apache ShardingSphere 的数据分片模块透明化了分库分表所带来的影响，让使用方尽量像使用一个数据库一样使用水平分片之后的数据库集群。

#### 集成步骤

1.  MySQL 执行以下的数据迁移脚本：

```sql
DROP PROCEDURE
IF
	EXISTS createBookChapterTable;
-- 创建小说章节表的存储过程
CREATE PROCEDURE createBookChapterTable ( ) BEGIN
	-- 定义变量
	DECLARE
		i INT DEFAULT 0;
	DECLARE
		tableName CHAR ( 13 ) DEFAULT NULL;
	WHILE
			i < 10 DO
			
			SET tableName = concat( 'book_chapter', i );
		
			SET @stmt = concat( 'create table ', tableName, '(
				`id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
				`book_id` bigint(20) unsigned NOT NULL COMMENT \'小说ID\',
				`chapter_num` smallint(5) unsigned NOT NULL COMMENT \'章节号\',
				`chapter_name` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT \'章节名\',
				`word_count` int(10) unsigned NOT NULL COMMENT \'章节字数\',
				`is_vip` tinyint(3) unsigned NOT NULL DEFAULT \'0\' COMMENT \'是否收费;1-收费 0-免费\',
				`create_time` datetime DEFAULT NULL,
				`update_time` datetime DEFAULT NULL,
				PRIMARY KEY (`id`) USING BTREE,
				UNIQUE KEY `uk_bookId_chapterNum` (`book_id`,`chapter_num`) USING BTREE,
				UNIQUE KEY `pk_id` (`id`) USING BTREE,
				KEY `idx_bookId` (`book_id`) USING BTREE
			) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT=\'小说章节\'' );
			PREPARE stmt 
			FROM
				@stmt;
			EXECUTE stmt;
			DEALLOCATE PREPARE stmt;
			
			SET i = i + 1;
		
	END WHILE;
END;
CALL createBookChapterTable ( );

DROP PROCEDURE
IF
	EXISTS createBookContentTable;
-- 创建小说内容表的存储过程
CREATE PROCEDURE createBookContentTable ( ) BEGIN
	-- 定义变量
	DECLARE
		i INT DEFAULT 0;
	DECLARE
		tableName CHAR ( 13 ) DEFAULT NULL;
	WHILE
			i < 10 DO
			
			SET tableName = concat( 'book_content', i );
		
			SET @stmt = concat( 'create table ', tableName, '(
				`id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \'主键\',
				`chapter_id` bigint(20) unsigned NOT NULL COMMENT \'章节ID\',
				`content` mediumtext CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT \'小说章节内容\',
				`create_time` datetime DEFAULT NULL,
				`update_time` datetime DEFAULT NULL,
				PRIMARY KEY (`id`) USING BTREE,
				UNIQUE KEY `uk_chapterId` (`chapter_id`) USING BTREE,
				UNIQUE KEY `pk_id` (`id`) USING BTREE
			) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT=\'小说内容\'' );
			PREPARE stmt 
			FROM
				@stmt;
			EXECUTE stmt;
			DEALLOCATE PREPARE stmt;
			
			SET i = i + 1;
		
	END WHILE;
END;
CALL createBookContentTable ( );

DROP PROCEDURE
IF
	EXISTS copyBookChapterData;
-- 迁移小说章节数据的存储过程
CREATE PROCEDURE copyBookChapterData ( ) BEGIN
	-- 定义变量
	DECLARE
		s INT DEFAULT 0;
	DECLARE
		chapterId BIGINT;
	DECLARE
		bookId BIGINT;
	DECLARE
		chapterNum SMALLINT;
	DECLARE
		chapterName VARCHAR ( 100 );
	DECLARE
		wordCount INT DEFAULT 0;
	DECLARE
		isVip TINYINT ( 64 ) DEFAULT 0;
	DECLARE
		createTime datetime DEFAULT NULL;
	DECLARE
		updateTime datetime DEFAULT NULL;
	DECLARE
		tableNumber INT DEFAULT 0;
	DECLARE
		tableName CHAR ( 13 ) DEFAULT NULL;
	-- 定义游标
	DECLARE
		report CURSOR FOR SELECT
		id,
		book_id,
		chapter_num,
		chapter_name,
		word_count,
		is_vip,
		create_time,
		update_time 
	FROM
		book_chapter;
	-- 声明当游标遍历完后将标志变量置成某个值
	DECLARE
		CONTINUE HANDLER FOR NOT FOUND 
		SET s = 1;
	-- 打开游标
	OPEN report;
	-- 将游标中的值赋值给变量，注意：变量名不要和返回的列名同名，变量顺序要和sql结果列的顺序一致
	FETCH report INTO chapterId,
	bookId,
	chapterNum,
	chapterName,
	wordCount,
	isVip,
	createTime,
	updateTime;
	-- 循环遍历
	WHILE
			s <> 1 DO
			-- 执行业务逻辑
			
			SET tableNumber = bookId % 10;
		
			SET tableName = concat( 'book_chapter', tableNumber );
			
			SET @stmt = concat(
				'insert into ',
				tableName,
				'(`id`, `book_id`, `chapter_num`, `chapter_name`, `word_count`, `is_vip`, `create_time`, `update_time`) VALUES (',
				chapterId,
				', ',
				bookId,
				', ',
				chapterNum,
				', \'',
				chapterName,
				'\', ',
				wordCount,
				', ',
				isVip,
				', \'',
				createTime,
				'\', \'',
				updateTime,
				'\')' 
			);
			PREPARE stmt 
			FROM
				@stmt;
			EXECUTE stmt;
			DEALLOCATE PREPARE stmt;
			FETCH report INTO chapterId,
			bookId,
			chapterNum,
			chapterName,
			wordCount,
			isVip,
			createTime,
			updateTime;
		
	END WHILE;
	-- 关闭游标
	CLOSE report;
END;
CALL copyBookChapterData ( );

DROP PROCEDURE
IF
	EXISTS copyBookContentData;
-- 迁移小说内容数据的存储过程
CREATE PROCEDURE copyBookContentData ( ) BEGIN
	-- 定义变量
	DECLARE
		s INT DEFAULT 0;
	DECLARE
		contentId BIGINT;
	DECLARE
		chapterId BIGINT;
	DECLARE
		bookContent MEDIUMTEXT;
	DECLARE
		createTime datetime DEFAULT NULL;
	DECLARE
		updateTime datetime DEFAULT NULL;
	DECLARE
		tableNumber INT DEFAULT 0;
	DECLARE
		tableName CHAR ( 13 ) DEFAULT NULL;
	-- 定义游标
	DECLARE
		report CURSOR FOR SELECT
		id,
		chapter_id,
		content,
		create_time,
		update_time 
	FROM
		book_content;
	-- 声明当游标遍历完后将标志变量置成某个值
	DECLARE
		CONTINUE HANDLER FOR NOT FOUND 
		SET s = 1;
	-- 打开游标
	OPEN report;
	-- 将游标中的值赋值给变量，注意：变量名不要和返回的列名同名，变量顺序要和sql结果列的顺序一致
	FETCH report INTO contentId,
	chapterId,
	bookContent,
	createTime,
	updateTime;
	-- 循环遍历
	WHILE
			s <> 1 DO
			-- 执行业务逻辑
			
			SET tableNumber = chapterId % 10;
		
			SET tableName = concat( 'book_content', tableNumber );
			
			SET bookContent = REPLACE ( bookContent, '\'', "\\'" );
			
			SET @stmt = concat(
				'insert into ',
				tableName,
				'(`id`, `chapter_id`, `content`) VALUES (',
				contentId,
				', ',
				chapterId,
				',\'',
				bookContent,
				'\')' 
			);
			PREPARE stmt 
			FROM
				@stmt;
			EXECUTE stmt;
			DEALLOCATE PREPARE stmt;
			FETCH report INTO contentId,
			chapterId,
			bookContent,
			createTime,
			updateTime;
		
	END WHILE;
	-- 关闭游标
	CLOSE report;
END;
CALL copyBookContentData ( );
```

2.  引入 ShardingSphere-JDBC 官方提供的 Spring Boot Starter 依赖：

```xml
<dependency>
    <groupId>org.apache.shardingsphere</groupId>
    <artifactId>shardingsphere-jdbc-core-spring-boot-starter</artifactId>
    <version>5.1.1</version>
</dependency>
```

3.  application.yml 中添加 ShardingSphere-JDBC 的配置：

```yaml
spring:
  shardingsphere:
    # 是否开启 shardingsphere
    enabled: false
    props:
      # 是否在日志中打印 SQL
      sql-show: true
    # 模式配置
    mode:
      # 单机模式
      type: Standalone
      repository:
        # 文件持久化
        type: File
        props:
          # 元数据存储路径
          path: .shardingsphere
      # 使用本地配置覆盖持久化配置
      overwrite: true
    # 数据源配置
    datasource:
      names: ds_0
      ds_0:
        type: com.zaxxer.hikari.HikariDataSource
        driverClassName: com.mysql.cj.jdbc.Driver
        jdbcUrl: jdbc:mysql://localhost:3306/novel_test?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: test123456
    # 规则配置
    rules:
      # 数据分片
      sharding:
        tables:
          # book_content 表
          book_content:
            # 数据节点
            actual-data-nodes: ds_$->{0}.book_content$->{0..9}
            # 分表策略
            table-strategy:
              standard:
                # 分片列名称
                sharding-column: chapter_id
                # 分片算法名称
                sharding-algorithm-name: bookContentSharding
        sharding-algorithms:
          bookContentSharding:
            # 行表达式分片算法，使用 Groovy 的表达式，提供对 SQL 语句中的 = 和 IN 的分片操作支持
            type: INLINE
            props:
              # 分片算法的行表达式
              algorithm-expression: book_content$->{chapter_id % 10}
```

配置是 ShardingSphere-JDBC 中唯一与应用开发者交互的模块，通过它可以快速清晰的理解 ShardingSphere-JDBC 所提供的功能。

-   模式配置： Apache ShardingSphere 提供的 3 种运行模式分别是适用于集成测试的环境启动，方便开发人员在整合功能测试中集成 Apache ShardingSphere 而无需清理运行痕迹`内存模式`、能够将数据源和规则等元数据信息持久化，但无法将元数据同步至多个 Apache ShardingSphere 实例，无法在集群环境中相互感知的`单机模式`和提供了多个 Apache ShardingSphere 实例之间的元数据共享和分布式场景下状态协调能力的`集群模式`。
    
-   数据源配置：包括使用本地数据源配置（本项目中）和使用 JNDI 数据源的配置。如果计划使用 JNDI 配置数据库，在应用容器（如 Tomcat）中使用 ShardingSphere-JDBC 时， 可使用 spring.shardingsphere.datasource.${datasourceName}.jndiName 来代替数据源的一系列配置。
    
-   规则配置：规则是 Apache ShardingSphere 面向可插拔的一部分，包括数据分片、读写分离、高可用、数据加密、影子库、SQL 解析、混合规则等。
    

以下是数据分片的配置项说明：

```
# 标准分片表配置
spring.shardingsphere.rules.sharding.tables.<table-name>.actual-data-nodes= # 由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持 inline 表达式。缺省表示使用已知数据源与逻辑表名称生成数据节点，用于广播表（即每个库中都需要一个同样的表用于关联查询，多为字典表）或只分库不分表且所有库的表结构完全一致的情况

# 分库策略，缺省表示使用默认分库策略，以下的分片策略只能选其一

# 用于单分片键的标准分片场景
spring.shardingsphere.rules.sharding.tables.<table-name>.database-strategy.standard.sharding-column= # 分片列名称
spring.shardingsphere.rules.sharding.tables.<table-name>.database-strategy.standard.sharding-algorithm-name= # 分片算法名称

# 用于多分片键的复合分片场景
spring.shardingsphere.rules.sharding.tables.<table-name>.database-strategy.complex.sharding-columns= # 分片列名称，多个列以逗号分隔
spring.shardingsphere.rules.sharding.tables.<table-name>.database-strategy.complex.sharding-algorithm-name= # 分片算法名称

# 用于 Hint 的分片策略
spring.shardingsphere.rules.sharding.tables.<table-name>.database-strategy.hint.sharding-algorithm-name= # 分片算法名称

# 分表策略，同分库策略
spring.shardingsphere.rules.sharding.tables.<table-name>.table-strategy.xxx= # 省略

# 自动分片表配置
spring.shardingsphere.rules.sharding.auto-tables.<auto-table-name>.actual-data-sources= # 数据源名

spring.shardingsphere.rules.sharding.auto-tables.<auto-table-name>.sharding-strategy.standard.sharding-column= # 分片列名称
spring.shardingsphere.rules.sharding.auto-tables.<auto-table-name>.sharding-strategy.standard.sharding-algorithm-name= # 自动分片算法名称

# 分布式序列策略配置
spring.shardingsphere.rules.sharding.tables.<table-name>.key-generate-strategy.column= # 分布式序列列名称
spring.shardingsphere.rules.sharding.tables.<table-name>.key-generate-strategy.key-generator-name= # 分布式序列算法名称

spring.shardingsphere.rules.sharding.binding-tables[0]= # 绑定表规则列表
spring.shardingsphere.rules.sharding.binding-tables[1]= # 绑定表规则列表
spring.shardingsphere.rules.sharding.binding-tables[x]= # 绑定表规则列表

spring.shardingsphere.rules.sharding.broadcast-tables[0]= # 广播表规则列表
spring.shardingsphere.rules.sharding.broadcast-tables[1]= # 广播表规则列表
spring.shardingsphere.rules.sharding.broadcast-tables[x]= # 广播表规则列表

spring.shardingsphere.sharding.default-database-strategy.xxx= # 默认数据库分片策略
spring.shardingsphere.sharding.default-table-strategy.xxx= # 默认表分片策略
spring.shardingsphere.sharding.default-key-generate-strategy.xxx= # 默认分布式序列策略
spring.shardingsphere.sharding.default-sharding-column= # 默认分片列名称

# 分片算法配置
spring.shardingsphere.rules.sharding.sharding-algorithms.<sharding-algorithm-name>.type= # 分片算法类型
spring.shardingsphere.rules.sharding.sharding-algorithms.<sharding-algorithm-name>.props.xxx= # 分片算法属性配置

# 分布式序列算法配置
spring.shardingsphere.rules.sharding.key-generators.<key-generate-algorithm-name>.type= # 分布式序列算法类型
spring.shardingsphere.rules.sharding.key-generators.<key-generate-algorithm-name>.props.xxx= # 分布式序列算法属性配置
```

其中，分片算法分为包含取模分片、哈希取模分片、基于分片容量的范围分片、基于分片边界的范围分片、自动时间段分片在内的`自动分片算法`和包含行表达式分片、时间范围分片在内的`标准分片算法`以及`复合分片算法`和`Hint 分片算法`。我们还可以自定义类分片算法，通过配置分片策略类型和算法类名，实现自定义扩展。

分布式序列算法包括雪花算法和 UUID。

### 集成 Spring Boot Admin 实现应用管理和监控功能

#### Spring Boot Actuator 介绍

当我们将应用程序投入生产时，Spring Boot 包含了许多可以帮助我们对其进行监控和管理的`生产就绪功能`，我们可以选择使用 HTTP 端点或 JMX 来管理和监控我们的应用程序。

Spring Boot Actuator 模块提供了 Spring Boot 的所有`生产就绪功能`，我们通过添加 spring-boot-starter-actuator `Starter`依赖来启用这些功能。

`端点`（endpoints）让我们可以监控应用程序并与之交互。Spring Boot 包含许多内置端点，并允许我们添加自己的端点。例如，health 端点提供基本的应用程序健康信息。我们可以单独`启用`或`禁用`每一个端点并通过 HTTP 或 JMX `公开`它们（使它们可以远程访问）。当端点被`启用`和`公开`时，它被认为是`可用`的，内置端点仅在可用时才会自动配置。

大多数应用程序选择通过 HTTP 公开端点，其中端点的 ID 和前缀 /actuator 被映射到一个 URL 地址。例如，默认情况下，health 端点映射到 /actuator/health。

默认情况下，除了 shutdown 之外的所有端点都是启用的，如果要配置一个端点的启用，需要使用 `management.endpoint.<id>.enabled` 配置属性。

由于端点可能包含敏感信息，我们应该仔细考虑何时公开它们。下表显示了内置端点的默认公开情况：

| ID                 | JMX  | Web  |
| ------------------ | ---- | ---- |
| `auditevents`      | Yes  | No   |
| `beans`            | Yes  | No   |
| `caches`           | Yes  | No   |
| `conditions`       | Yes  | No   |
| `configprops`      | Yes  | No   |
| `env`              | Yes  | No   |
| `flyway`           | Yes  | No   |
| `health`           | Yes  | Yes  |
| `heapdump`         | N/A  | No   |
| `httptrace`        | Yes  | No   |
| `info`             | Yes  | No   |
| `integrationgraph` | Yes  | No   |
| `jolokia`          | N/A  | No   |
| `logfile`          | N/A  | No   |
| `loggers`          | Yes  | No   |
| `liquibase`        | Yes  | No   |
| `metrics`          | Yes  | No   |
| `mappings`         | Yes  | No   |
| `prometheus`       | N/A  | No   |
| `quartz`           | Yes  | No   |
| `scheduledtasks`   | Yes  | No   |
| `sessions`         | Yes  | No   |
| `shutdown`         | Yes  | No   |
| `startup`          | Yes  | No   |
| `threaddump`       | Yes  | No   |

如果想要更改公开的端点，可以使用以下特定技术的 `include`和`exclude`配置属性：

| Property                                    | Default  |
| ------------------------------------------- | -------- |
| `management.endpoints.jmx.exposure.exclude` |          |
| `management.endpoints.jmx.exposure.include` | `*`      |
| `management.endpoints.web.exposure.exclude` |          |
| `management.endpoints.web.exposure.include` | `health` |

include 属性列出需要公开的端点 ID。exclude 属性列出不应公开的端点 ID，exclude 优先于 include。我们还可以使用端点 ID 列表来配置 include 和 exclude 属性。

`应用程序信息`（Application Information）公开了 ApplicationContext 中定义的所有 InfoContributor bean 收集的各种信息。 Spring Boot 包含许多自动配置的 InfoContributor bean，我们也可以编写自己的 InfoContributor bean。

在适当的时候，Spring Boot 会自动配置以下的 InfoContributor bean：

| ID      | Bean                                                         | 描述                             | 先决条件                                      |
| ------- | ------------------------------------------------------------ | -------------------------------- | --------------------------------------------- |
| `build` | [`BuildInfoContributor`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/info/BuildInfoContributor.java) | 公开构建信息                     | 资源文件`META-INF/build-info.properties` 存在 |
| `env`   | [`EnvironmentInfoContributor`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/info/EnvironmentInfoContributor.java) | 公开所有以 `info.`开头的环境属性 | 无                                            |
| `git`   | [`GitInfoContributor`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/info/GitInfoContributor.java) | 公开 git 信息                    | 资源文件`git.properties` 存在                 |
| `java`  | [`JavaInfoContributor`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/info/JavaInfoContributor.java) | 公开 Java 运行时信息             | 无                                            |
| `os`    | [`OsInfoContributor`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/info/OsInfoContributor.java) | 公开操作系统信息                 | 无                                            |

`management.info.<id>.enabled` 属性控制单个 InfoContributor bean 是否启用，不同的 InfoContributor bean 对此属性有不同的默认值，这取决于它们的先决条件和它们公开信息的性质。默认情况下 env、java 和 os 被禁用，我们可以通过将其 `management.info.<id>.enabled` 属性设置为 true 来开启。build 和 git 默认是开启的，我们可以通过将其 `management.info.<id>.enabled` 属性设置为 false 来禁用。

`健康信息`（Health Information）可以用来检查正在运行的应用程序状态。当生产系统出现故障时，监控软件经常使用它来提醒某人。

健康信息是从 HealthContributorRegistry 的内容中收集的（默认情况下，所有在 ApplicationContext 中定义的 HealthContributor 实例）。 Spring Boot 包含许多自动配置的 HealthContributor，我们也可以编写自己的。

在适当的时候，Spring Boot 会自动配置以下的 HealthIndicator bean：

| Key             | Bean                                                         | 描述                                |
| --------------- | ------------------------------------------------------------ | ----------------------------------- |
| `cassandra`     | [`CassandraDriverHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/cassandra/CassandraDriverHealthIndicator.java) | 检查 Cassandra 数据库是否已启动。   |
| `couchbase`     | [`CouchbaseHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/couchbase/CouchbaseHealthIndicator.java) | 检查 Couchbase 集群是否已启动。     |
| `db`            | [`DataSourceHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/jdbc/DataSourceHealthIndicator.java) | 检查是否可以获得`DataSource`连接。  |
| `diskspace`     | [`DiskSpaceHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/system/DiskSpaceHealthIndicator.java) | 检查磁盘空间是否不足。              |
| `elasticsearch` | [`ElasticsearchRestHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/elasticsearch/ElasticsearchRestHealthIndicator.java) | 检查 Elasticsearch 集群是否已启动。 |
| `hazelcast`     | [`HazelcastHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/hazelcast/HazelcastHealthIndicator.java) | 检查 Hazelcast 服务是否已启动。     |
| `influxdb`      | [`InfluxDbHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/influx/InfluxDbHealthIndicator.java) | 检查 InfluxDB 服务是否已启动。      |
| `jms`           | [`JmsHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/jms/JmsHealthIndicator.java) | 检查 JMS 代理是否已启动。           |
| `ldap`          | [`LdapHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/ldap/LdapHealthIndicator.java) | 检查 LDAP 服务是否已启动。          |
| `mail`          | [`MailHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/mail/MailHealthIndicator.java) | 检查邮件服务是否已启动。            |
| `mongo`         | [`MongoHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/mongo/MongoHealthIndicator.java) | 检查 Mongo 数据库是否已启动。       |
| `neo4j`         | [`Neo4jHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/neo4j/Neo4jHealthIndicator.java) | 检查 Neo4j 数据库是否已启动。       |
| `ping`          | [`PingHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/health/PingHealthIndicator.java) | 始终以 `UP`响应。                   |
| `rabbit`        | [`RabbitHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/amqp/RabbitHealthIndicator.java) | 检查 Rabbit 服务是否已启动。        |
| `redis`         | [`RedisHealthIndicator`](https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/redis/RedisHealthIndicator.java) | 检查 Redis 服务是否已启动。         |

我们可以通过 `management.health.<key>.enabled` 配置来启用或禁用选定的健康检查。

#### Spring Boot Admin 介绍

Spring Boot Admin 是一个用于管理和监控我们 Spring Boot 应用程序的开源项目，由服务端（Spring Boot Admin Server）和客户端（Spring Boot Admin Client）两部分构成。

应用程序使用 Spring Boot Admin Client（通过 HTTP）或使用 Spring Cloud 自动发现（例如 Eureka、Consul、Nacos 等）向 Spring Boot Admin Server 注册。

Spring Boot Admin Server UI 是构建在 Spring Boot Actuator 端点之上的 Vue.js 应用程序，Spring Boot Admin Server 的监控信息均来自 Spring Boot Actuator 端点，并且通过端点来管理我们的应用程序。

#### 构建 Spring Boot Admin Server

1.  使用 [Spring Initializr](https://start.spring.io/) 初始化一个 Spring Boot 项目，并加入以下依赖：

```xml
<dependency>
    <groupId>de.codecentric</groupId>
    <artifactId>spring-boot-admin-starter-server</artifactId>
    <version>3.0.4</version>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
</dependency>
```

2.  在 application.properties 配置文件中添加 Spring Security 用户名、密码的配置属性，用于登录 Spring Boot Admin Server：

```properties
spring.security.user.name=novel
spring.security.user.password=novel
```

3.  在启动类上添加 @EnableAdminServer 注解：

```java
@SpringBootApplication
@EnableAdminServer
public class MonitorApplication {

public static void main(String[] args) {
SpringApplication.run(MonitorApplication.class, args);
}

}
```

4.  添加 Spring Security 配置类：

```java
/**
 * Spring Security 配置
 *
 * @author xiongxiaoyang
 * @date 2022/6/8
 */
@Configuration(proxyBeanMethods = false)
public class SecuritySecureConfig extends WebSecurityConfigurerAdapter {

    private final AdminServerProperties adminServer;

    private final SecurityProperties security;

    public SecuritySecureConfig(AdminServerProperties adminServer, SecurityProperties security) {
        this.adminServer = adminServer;
        this.security = security;
    }

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler();
        successHandler.setTargetUrlParameter("redirectTo");
        successHandler.setDefaultTargetUrl(this.adminServer.path("/"));

        http.authorizeRequests(
                        authorizeRequests -> authorizeRequests
                                .antMatchers(this.adminServer.path("/assets/**")).permitAll()
                                .antMatchers(this.adminServer.path("/actuator/info")).permitAll()
                                .antMatchers(this.adminServer.path("/actuator/health")).permitAll()
                                .antMatchers(this.adminServer.path("/login")).permitAll()
                                .anyRequest().authenticated()
                ).formLogin(
                        formLogin -> formLogin
                                .loginPage(this.adminServer.path("/login"))
                                .successHandler(successHandler).and()
                ).logout(
                        logout -> logout.logoutUrl(this.adminServer.path("/logout"))
                ).httpBasic(Customizer.withDefaults())
                .csrf(csrf -> csrf.csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse())
                        .ignoringRequestMatchers(
                                new AntPathRequestMatcher(this.adminServer.path("/instances"),
                                        HttpMethod.POST.toString()),
                                new AntPathRequestMatcher(this.adminServer.path("/instances/*"),
                                        HttpMethod.DELETE.toString()),
                                new AntPathRequestMatcher(this.adminServer.path("/actuator/**"))
                        ))
                .rememberMe(rememberMe -> rememberMe
                        .key(UUID.randomUUID().toString())
                        .tokenValiditySeconds(1209600));
    }

    /**
     * Required to provide UserDetailsService for "remember functionality"
     * */
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.inMemoryAuthentication().withUser(security.getUser().getName())
                .password("{noop}" + security.getUser().getPassword()).roles("USER");
    }

}
```

此时，运行应用程序，浏览器中访问 8080 端口，输入上面配置的用户名和密码即可进入 Spring Boot Admin Server 控制台管理和监控我们的应用程序。

#### 通过 Spring Boot Admin Client 注册 novel 服务

1.  在我们 novel 项目中加入以下依赖：

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>de.codecentric</groupId>
    <artifactId>spring-boot-admin-starter-client</artifactId>
    <version>3.0.4</version>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
</dependency>
```

2.  在 novel 项目的 application.yml 配置文件中加入以下配置：

```yaml
spring:
  # Spring Boot 应用管理和监控
  boot:
    admin:
      client:
        # 是否开启 Spring Boot Admin 客户端
        enabled: true
        # Spring Boot Admin 服务端注册地址
        url: http://localhost:8080
        # Spring Boot Admin 服务端认证用户名
        username: novel
        # Spring Boot Admin 服务端认证密码
        password: novel
        instance:
          metadata:
            # SBA Client
            user.name: ${spring.security.user.name}
            user.password: ${spring.security.user.password}
  security:
    user:
      # Actuator 端点保护配置
      name: ENDPOINT_ADMIN
      password: ENDPOINT_ADMIN
      roles: ENDPOINT_ADMIN

# Actuator 端点管理
management:
  # 端点公开配置
  endpoints:
    # 通过 HTTP 公开的 Web 端点
    web:
      exposure:
        # 公开所有的 Web 端点
        include: "*"

  # 端点启用配置
  endpoint:
    logfile:
      # 启用返回日志文件内容的端点
      enabled: true
      # 外部日志文件路径
      external-file: logs/novel.log

  info:
    env:
      # 公开所有以 info. 开头的环境属性
      enabled: true
  health:
    rabbit:
      # 关闭 rabbitmq 的健康检查
      enabled: false
    elasticsearch:
      # 关闭 elasticsearch 的健康检查
      enabled: false

```

3.  novel 项目启动类中添加 Spring Boot Actuator 端点保护的 Spring Security 配置：

```java
@Bean
public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
    http.csrf().disable()
            .requestMatcher(EndpointRequest.toAnyEndpoint())
            .authorizeRequests(requests -> requests.anyRequest().hasRole("ENDPOINT_ADMIN"));
    http.httpBasic();
    return http.build();
}
```

此时，启动 novel 项目，登录 Spring Boot Admin Server 控制台可以看到如下监控信息：

![Spring Boot Admin](pic/springbootadmin1.png) ![Spring Boot Admin](pic/springbootadmin2.png) ![Spring Boot Admin](pic/springbootadmin3.png) ![Spring Boot Admin](pic/springbootadmin4.png) ![Spring Boot Admin](pic/springbootadmin5.png)

踩坑：在启动 Spring Boot Admin Server 之前有个 node 程序监听了 8080 端口没有释放，然后启动 Spring Boot Admin Server（默认也是 8080 端口），此时浏览器中可以正常访问到 Spring Boot Admin Server 的界面，但是 novel 服务无法注册到 Spring Boot Admin Server 上，提示404 错误。后来发现 novel 服务的注册被监听 8080 端口的 node 程序处理了，关闭该 node 程序即可正常注册。 该机制请参考 [Node.Js 的端口重用](https://segmentfault.com/a/1190000014701988)。

### 使用 Docker Compose 一键安装开发环境

1.  Docker Compose 安装。（除了第一步需要根据自己的平台去安装 Docker Compose 以外，其它步骤都一样）

在 Ubuntu 下执行如下的安装命令：

```sh
sudo apt-get update
sudo apt-get install docker-compose-plugin
```

查看 Docker Compose 和 Docker 的版本信息：

```sh
docker compose version

docker version
```

2.  创建 `.env` 文件，用来设置容器编排的环境变量。

```
# MYSQL 配置
MYSQL_VERSION=8.0
MYSQL_ROOT_PASSWORD=test123456

# Redis 配置
REDIS_VERSION=7.0
REDIS_PASSWORD=test123456

# RabbitMQ 配置
RABBITMQ_VERSION=3-management
RABBITMQ_DEFAULT_USER=xxyopen
RABBITMQ_DEFAULT_PASS=test123456
RABBITMQ_DEFAULT_VHOST=novel

# Elasticsearch 配置
ELASTIC_VERSION=8.6.2
# 'elastic' 账户的密码 (至少 6 个字符)
ELASTIC_PASSWORD=Fy2JWjJ1hcO2mi1USFL1
# 'kibana_system' 账号的密码 (至少 6 个字符)
KIBANA_PASSWORD=5JbbVsW9TkYcJu9Y9

# Kibana 配置
KIBANA_VERSION=8.6.2

# XXL-JOB 配置
XXLJOB_VERSION=2.3.1
XXLJOB_ACCESSTOKEN=123

```

3.  创建 Docker Compose 的容器编排文件 `docker-compose.yml`。

```yaml
version: '3.9'

services:
  novel-mysql:
    container_name: novel-mysql
    image: mysql:${MYSQL_VERSION}
    restart: always
    hostname: novel-mysql
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
    volumes:
      - "/data/docker/mysql/data:/var/lib/mysql"
      - "/data/docker/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql"
    command: mysqld --max_allowed_packet=100M
    ports:
      - "3306:3306"
    networks:
      - novelnet

  novel-redis:
    container_name: novel-redis
    image: redis:${REDIS_VERSION}
    restart: always
    hostname: novel-redis
    command: redis-server --save 60 1 --loglevel warning --requirepass "${REDIS_PASSWORD}"
    ports:
      - "6379:6379"
    networks:
      - novelnet

  novel-rabbitmq:
    container_name: novel-rabbitmq
    image: rabbitmq:${RABBITMQ_VERSION}
    restart: always
    hostname: novel-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_DEFAULT_VHOST}
    ports:
      - "15672:15672"
      - "5672:5672"
    networks:
      - novelnet

  novel-elasticsearch-setup:
    container_name: novel-elasticsearch-setup
    image: elasticsearch:${ELASTIC_VERSION}
    hostname: novel-elasticsearch-setup
    user: "0"
    command: >
      bash -c '
        echo "Waiting for Elasticsearch availability";
        until curl -s http://novel-elasticsearch:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "Setting kibana_system password";
        until curl -s -X POST -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" http://novel-elasticsearch:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "All done!";
      '
    networks:
      - novelnet

  novel-elasticsearch:
    container_name: novel-elasticsearch
    image: elasticsearch:${ELASTIC_VERSION}
    restart: always
    hostname: novel-elasticsearch
    environment:
      - "ES_JAVA_OPTS=-Xms125m -Xmx512m"
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - KIBANA_PASSWORD=${KIBANA_PASSWORD}
      - xpack.security.http.ssl.enabled=false
    ports:
      - "9200:9200"
    depends_on:
      - novel-elasticsearch-setup
    networks:
      - novelnet

  novel-kibana:
    container_name: novel-kibana
    image: kibana:${KIBANA_VERSION}
    restart: always
    hostname: novel-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://novel-elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
    ports:
      - "5601:5601"
    depends_on:
      - novel-elasticsearch
    networks:
      - novelnet

  novel-xxl-job-admin:
    container_name: novel-xxl-job-admin
    image: xuxueli/xxl-job-admin:${XXLJOB_VERSION}
    restart: always
    hostname: novel-xxl-job-admin
    environment:
      - PARAMS=--spring.datasource.url=jdbc:mysql://novel-mysql:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=${MYSQL_ROOT_PASSWORD} --xxl.job.accessToken=${XXLJOB_ACCESSTOKEN}
      - JAVA_OPTS=-Xmx512m
    volumes:
      - /data/docker/xxl-job-admin/data/applogs:/data/applogs
    ports:
      - "8080:8080"
    depends_on:
      - novel-mysql
    networks:
      - novelnet

networks:
  novelnet:
    driver: bridge
```

> 注意：Elasticsearch 容器挂载本地目录或文件时，需要修改目录或文件的读写权限，否则启动不成功。官方原文如下：
>
> If you are bind-mounting a local directory or file, it must be readable by the elasticsearch user. In addition, this user must have write access to the data and log dirs. A good strategy is to grant group access to gid 1000 or 0 for the local directory.
>
> For example, to prepare a local directory for storing data through a bind-mount:
>
> ```sh
> mkdir esdatadir
> chmod g+rwx esdatadir
> chgrp 1000 esdatadir
> ```

4.  在后台运行所有编排文件中的容器。

```sh
sudo docker-compose up -d
```

5.  使用 `.env` 环境文件中配置的 `elastic` 账号密码来登录 kibana 控制台。

```
elastic
Fy2JWjJ1hcO2mi1USFL1
```

> **注意：需要先将 xxl-job 的数据库文件导入 MySQL 后，xxl-job-admin 才能正常访问。**



常用命令

```
sudo docker-compose stop
sudo docker-compose start
sudo docker-compose up -d
sudo docker-compose down
```



## 项目部署

### 服务器购买和配置

我们可以前往[华为云](https://activity.huaweicloud.com/828_promotion/index.html?fromacct=bf5b45d9-d4a3-4f9e-9d3e-8280935375c6&utm_source=aHdpZF9vZjJkcXBfYWMyNHg3YmI==&utm_medium=cps&utm_campaign=201905)、[腾讯云](https://cloud.tencent.com/act/cps/redirect?redirect=1079&cps_key=736e609d66e0ac4e57813316cec6fd0b&from=console)、阿里云和百度云等云平台购买服务器。这里以购买华为云服务器为例，操作步骤如下：

1.  [点击此处](https://activity.huaweicloud.com/828_promotion/index.html?fromacct=bf5b45d9-d4a3-4f9e-9d3e-8280935375c6&utm_source=aHdpZF9vZjJkcXBfYWMyNHg3YmI==&utm_medium=cps&utm_campaign=201905)前往华为云产品折扣页面购买活动产品，如果没有华为云账号需要先进行注册和实名认证。

![](pic/huaweicloud13.png)

**注：预算有限的同学可以选择[腾讯云](https://cloud.tencent.com/act/cps/redirect?redirect=1079&cps_key=736e609d66e0ac4e57813316cec6fd0b&from=console)，具体操作差不多，算是目前优惠力度最大的云平台。**

2.  选好想要购买的云服务器后，点击立即购买，更换系统镜像为 CentOS，其它规格配置默认即可，如下所示：

![](pic/huaweicloud2.png)

3.  进入[华为云控制台](https://console.huaweicloud.com/ecm)，点击我的资源中的弹性云服务器，进入云服务器列表，如下所示：

![](pic/huaweicloud3.png) ![](pic/huaweicloud4.png)

4.  安全组规则配置，放行 80 端口，如下所示：

![](pic/huaweicloud8.png) ![](pic/huaweicloud9.png) ![](pic/huaweicloud10.png)

5.  重置远程登录密码，如下所示：

![](pic/huaweicloud5.png)

6.  重置远程登录密码后，开始远程登录，如下所示：

![](pic/huaweicloud6.png)

7.  登录成功后的界面如下所示：

![](pic/huaweicloud7.png)

### 域名购买和配置

为了学习更多的云平台，这次选择在[腾讯云](https://curl.qcloud.com/vET2Mrgq)进行域名购买和配置，其它云平台的操作也都差不多，具体步骤如下：

1.  进入[腾讯云](https://curl.qcloud.com/vET2Mrgq)，搜索域名注册，购买你想要注册的域名：

![](pic/tencentcloud1.png) ![](pic/tencentcloud2.png) ![](pic/tencentcloud3.png) ![](pic/tencentcloud4.png)

2.  进入到腾讯云的[域名控制台](https://console.cloud.tencent.com/domain/all-domain)，划动到页面底部，点击解析按钮：

![](pic/tencentcloud5.png)

3.  点击左上角添加记录按钮，添加前台门户网站（book.xxyopen.com）和后端接口（api.book.xxyopen.com）的域名解析记录（服务器公网IP可在华为云控制台的服务器列表获取）：

![](pic/tencentcloud6.png)

![](pic/tencentcloud7.png)

![](pic/tencentcloud8.png)

### Docker 安装

1.  Docker 安装[Install Docker Engine on CentOS](https://docs.docker.com/engine/install/centos/)

2.  查看 Docker 版本

```sh
docker -v
```



### MySQL 安装和配置

1.  Docker 方式安装 MySQL8.0

```sh
docker run -itd --name mysql8.0 --restart=always -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0
```

2.  上传 SQL 脚本文件`novel_data.sql`和`novel_struc.sql`到服务器

![](pic/huaweicloud11.png)

3.  导入 SQL 脚本文件到 MySQL 容器

```sh
docker cp novel_data.sql mysql8.0:/tmp/
```

```sh
docker cp novel_struc.sql mysql8.0:/tmp/
```

4.  登入到 MySQL 容器内的 MySQL 服务

```sh
docker exec -it mysql8.0 mysql -uroot -p123456
```

5.  创建数据库

```sh
create database novel_test default character set utf8mb4;
use novel;
```

6.  执行 SQL 文件

```sh
source /tmp/novel_struc.sql
```

```sh
source /tmp/novel_data.sql
```

7.  根据需要创建其它远程访问账号或修改 root 账号的远程访问权限

8.  退出 MySQL 容器

```sh
exit;
```



### Redis 安装和配置

1.  Docker 方式安装最新版 Redis

```
docker run -d --name redis8.0 --restart=always -p 6379:6379 redis --requirepass "123456" 
```

2.  根据需要开启 Redis 的远程访问权限



### JDK 安装和配置

yum 安装 JDK 17

```
sudo yum -y update
wget https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.rpm
sudo yum -y install ./jdk-17_linux-x64_bin.rpm

$ ls -1 /usr/lib/jvm/jre-openjdk/
bin
conf
include
legal
lib
release
tapset

# OR
$ ls -1 /usr/lib/jvm/jdk-17-oracle-x64/
bin
conf
include
jmods
legal
lib
LICENSE
man
README
release

java -version
```



### 后端服务部署

1.  下载后端项目源码
2.  修改 `application.yml` 和 `redisson.yml` 文件中的 MySQL 配置和 Redis 配置
3.  修改 `application.yml` 文件中的跨域配置
4.  项目根目录下运行`mvn clean package -Dmaven.test.skip`命令打包
5.  上传打包后的 jar 文件到服务器
6.  `nohup java -jar novel-<版本号>.jar &` 命令启动后端服务
7.  注意启动sentinel需要JVM参数

> ### nohup
>
> `nohup Command`用于不挂断地运行命令，即使终端关闭了也会一直运行，我们可以通过运行 `nohup Command &` 来达到守护进程的部分效果。
>
> 例如，我们经常通过`nohup java -jar <jarName>.jar &` 命令来[运行 Spring Boot 项目](#后端服务部署)。
>
> 默认情况下，所有输出都被重定向到当前目录一个名为 nohup.out 的文件中，nohup.out 相当于日志，如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中，如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。



### Nginx 安装和配置

1.  启动一个最新版 Nginx 的 Docker 临时容器

```sh
docker run -d --name nginx nginx
```

其中，Nginx 运行在 Docker 容器中对应的目录如下：

-   配置文件目录：/etc/nginx
-   日志目录：/var/log/nginx
-   项目根目录：/usr/share/nginx/html

2.  复制 Nginx 的配置文件到宿主机中

```sh
mkdir nginx
cd nginx
mkdir conf
cd conf
docker cp nginx:/etc/nginx ./
cd ..
mkdir html
mkdir log
```

3.  配置后端服务的反向代理

```sh
vim conf/nginx/conf.d/novel.conf
```

```
# server {
#    listen       80;
#    server_name  book.xxyopen.com;
    
#    location / {
#       root /www/novel;
#       index index.html index.htm;
#   }
# }

server {
    listen       80;
    server_name  api.book.xxyopen.com;
    
    location / {
        proxy_set_header   Host             $host;
#       proxy_set_header   X-Real-IP        $remote_addr;
        proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
        proxy_pass   http://192.168.0.58:8888; # 不能使用 127.0.0.1，要使用宿主机 IP
    }
}
```

4.  停止之前启动的临时容器，并删除

```sh
docker stop nginx
docker rm nginx
```

5.  启动新的 Nginx 容器

```sh
docker run -d -p 80:80 -p 443:443 --name nginx --restart=always -e TZ="Asia/Shanghai" -v /root/nginx/html:/usr/share/nginx/html:ro -v /root/nginx/conf/nginx:/etc/nginx/:ro -v /root/nginx/log:/var/log/nginx nginx
```

其中，

-   :ro：表示容器内部的 nginx 文件是只读的，想要修改配置内容，只能修改宿主机的 conf 文件夹。这样带来的好处是安全性更高
-   \-e TZ="Asia/Shanghai"：表示把时区设置为中国的时区

6.  如果出现问题，查看错误日志

```
tail -f log/error.log
```



### 前端网站部署

1.  下载前端项目源码
    
2.  修改 `.env.production` 中的生产环境配置
    
3.  项目根目录下运行 `yarn build` 命令构建
    
4.  上传`dist`文件夹中的内容到到服务器`/root/nginx/html`目录中



## 更多

### Git 提交规约

#### 格式

```
<type>[scope]: <subject>
// 空一行
[body]
// 空一行
[footer]
```

**注：\[\]代表可选，<>代表必选。**

#### type

必填，用于指定 commit 的类型。

```
feat：增加新功能
fix：修复 bug
docs：只改动了文档相关的内容
style：格式修改，没有修改代码逻辑，比如格式化、换行等
refactor：重构代码，既没有新增功能，也没有修复 bug，比如提取某段代码为一个方法、重构某个功能等
perf：性能、体验优化等
test：新增 test 用例或修改现有测试用例
build：构造工具的或者外部依赖的改动，比如 maven
ci：与 CI（持续集成服务）有关的改动
chore：不修改 src 或者 test 的其余修改，例如构建过程或辅助工具的变动
revert：执行 git revert 打印的 message
```

**当同时有feat、fix和其他类型时，类型取feat、fix。**

#### scope

非必填，用于描述改动的范围，格式一般为项目名/模块名，如果一次 commit 修改多个模块，建议拆分成多次 commit，以便更好追踪和维护。

#### subject

必填，此次提交的简短描述，动词开头，第一人称现在时，比如add，而不用 added、adds，第一个字母小写，句尾不加句号（.）

#### body

非必填，此次提交的详细描述，主要描述改动之前的情况及修改动机，对于小的修改不作要求，但是重大需求、更新等必须添加body来作说明。

#### footer

footer只用于以下两种情况

-   break changes

break changes 指明是否产生了破坏性修改，涉及 break changes 的改动必须指明该项，类似版本升级、接口参数减少、接口删除、迁移等，以`BREAKING CHANGE：`开头，后面是变动的描述、变动的理由以及迁移的方法。

-   关闭 issue

当前提交修改了某个 issue

#### 示例

```
fix(ngStyle): correctly remove old style when new style value is invalid

Since d6098ee, old styles were not removed if `newStyles` specified an
invalid value for the style (e.g. `false`). The assumption was that the
new style would overwrite the old style value, but using an invalid
value made browsers ignore the new value and thus keep the old style.
This would typically happen when guarding a style with a boolean flag;
e.g.: `ng-style="{backgroundColor: isError && 'red'}"`

This commit essentially revers commit d6098ee, whose main purpose was
to work around jquery/jquery#4185. The jQuery issue has been fixed in
3.4.0, so that should not be a problem any more.

Fixes #16860

Closes #16868
```

### Java 代码格式

Java 代码格式在遵循 [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html) 的基础上，采用 Alibaba`4`个空格缩进的规约（谷歌默认采用的是`2`个空格的缩进）。

IntelliJ IDEA 中导入（`Preferences` -> `Editor` -> `Code Style` -> `Java` -> `Schema` -> `Import Schema`）以下格式文件：

```
<?xml version="1.0" encoding="UTF-8"?>
<code_scheme name="GoogleStyle">

    <codeStyleSettings language="JAVA">
        <option name="KEEP_CONTROL_STATEMENT_IN_ONE_LINE" value="false"/>
        <option name="KEEP_BLANK_LINES_IN_CODE" value="1"/>
        <option name="BLANK_LINES_AFTER_CLASS_HEADER" value="1"/>
        <option name="ALIGN_MULTILINE_PARAMETERS" value="false"/>
        <option name="ALIGN_MULTILINE_RESOURCES" value="false"/>
        <option name="ALIGN_MULTILINE_FOR" value="false"/>
        <option name="CALL_PARAMETERS_WRAP" value="1"/>
        <option name="METHOD_PARAMETERS_WRAP" value="1"/>
        <option name="EXTENDS_LIST_WRAP" value="1"/>
        <option name="THROWS_KEYWORD_WRAP" value="1"/>
        <option name="METHOD_CALL_CHAIN_WRAP" value="1"/>
        <option name="BINARY_OPERATION_WRAP" value="1"/>
        <option name="BINARY_OPERATION_SIGN_ON_NEXT_LINE" value="true"/>
        <option name="TERNARY_OPERATION_WRAP" value="1"/>
        <option name="TERNARY_OPERATION_SIGNS_ON_NEXT_LINE" value="true"/>
        <option name="FOR_STATEMENT_WRAP" value="1"/>
        <option name="ARRAY_INITIALIZER_WRAP" value="1"/>
        <option name="WRAP_COMMENTS" value="true"/>
        <option name="IF_BRACE_FORCE" value="3"/>
        <option name="DOWHILE_BRACE_FORCE" value="3"/>
        <option name="WHILE_BRACE_FORCE" value="3"/>
        <option name="FOR_BRACE_FORCE" value="3"/>
        <option name="PARENT_SETTINGS_INSTALLED" value="true"/>
        <indentOptions>
            <option name="INDENT_SIZE" value="4"/>
            <option name="CONTINUATION_INDENT_SIZE" value="4"/>
            <option name="TAB_SIZE" value="4"/>
        </indentOptions>
    </codeStyleSettings>

</code_scheme>
```

### 接口调试利器 EasyYapi 插件

IntelliJ IDEA 的 EasyYapi 插件是一个基于 javadoc & KDoc & ScalaDoc 解析 API 文档的插件，可以在保持代码零侵入的情况下得到相当完整的 api 文档（特殊的需求还是需要部分特殊的注释/注解配合），支持导出文件中的 API 到`yapi`/`postman`/`markdown`，以及`在 IDEA 中直接发起文件中的 API 请求进行接口调试`。

如果是 Spring 项目，我们可以选中一个或多个 `@Controller` 的 `.java` 文件来批量生成需要调试的接口，效果如下：

![](pic/api10.png)

首先，我们需要在 IntelliJ IDEA 的插件市场中搜索并安装 EasyYapi 插件，安装成功后需要重启 IDEA：

![](pic/api0.png)

然后，选中需要调试的 API 文件，鼠标右键选择`Call Api`即可打开接口调试窗口对选中文件中的 API 发起请求进行接口调试。打开调试窗口后，我们选中用户登录接口，如下所示：

![](pic/api1.png)

![](pic/api2.png)

从上图可以看出，接口请求路径和请求数据格式都已经自动生成好了，我们只需要修改调试数据，然后点击运行按钮来发起 API 请求：

![](pic/api4.png)

如果我们要导出文件中的 API 到 `Yapi`/`Postman`/`Markdown`，需要选中一个或多个 `@Controller` 的 `.java` 文件然后鼠标右键选择`Export Api`（也可以直接选择`Export Yapi`/`Export Postman`/`Export Markdown`），如下所示:

![](pic/api5.png)

![](pic/api6.png)

生成的`Markdown`API 文档效果如下：

![](pic/api7.png)

### MySQL 官方多线程逻辑备份工具

#### 介绍

[MySQL Shel](https://dev.mysql.com/doc/mysql-shell/8.0/en)是 MySQL 的高级命令行客户端和代码编辑器。除了 SQL，MySQL Shell 还为 JavaScript 和 Python 提供脚本功能。当 MySQL Shell 通过 X 协议连接到 MySQL 服务器时，X DevAPI 可用于处理关系数据和文档数据。

MySQL Shell 8.0.21 包括一些新的易用、高性能和集成的工具（MySQL Shell Dump & Dump Loading Utility）用来创建逻辑转储和执行逻辑还原。该序列工具以 MySQL Shell 8.0.17 中引入的多线程 CSV 导入工具 util.importTable() 为基础构建以便轻松转储和加载整个数据库实例或一组 schema。该序列工具包括：

-   util.dumpInstance()：转储整个数据库实例，包括用户
    
-   util.dumpSchemas()：转储一组数据库 schema
    
-   util.loadDump()：将转储加载到目标数据库中
    

主要特色功能包括：

-   多线程转储，将较大的表分成较小的块，速度高达 3GB / s
    
-   并行加载块，结合 MySQL Server 8.0.21 中的禁用 InnoDB Redo Log 的功能，加载性能可以超过 200MB / s
    
-   在转储的同时进行加载
    
-   中断后继续加载数据（断点续传）
    
-   内置压缩（zstd 和 gzip）
    
-   加载数据后推迟二级索引的创建
    
-   直接从 OCI 对象存储中转储和加载
    
-   兼容 OCI 的 MySQL 数据库服务模式，使得向云的迁移变得容易
    

#### MySQL Shell 安装

MySQL Shell 提供了 Windows、Linux 和 Mac 的安装支持，具体请查看如下的官方安装文档：

[https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-install.htm](https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-install.html)

#### Dump & Dump Loading Utility

MySQL Shell Dump & Dump Loading Utility 的使用以及与其它各种主流逻辑转储和加载工具 mysqldump,、mysqlpump 和 mydumper 的比较结果如下：

-   数据以大约 256 MB 的块形式转储

```
mysqlsh-js> util.dumpSchemas(["<db>"], 
                             "<directory>",
                             {threads: 88, 
                             bytesPerChunk: "256M"})
```

![转存](pic/dump.png)

-   加载

```
mysqlsh-js> util.loadDump("<directory>", 
                          {threads: 88})
```

![加载](pic/load.png)

Redo Log 禁用的情况下，MySQL Shell 能够快速转储数据，高达近 `3GB/s`，并以 `200MB/s` 以上的速度加载数据。

#### 参考

\[1\] [https://dev.mysql.com/blog-archive/mysql-shell-dump-load-part-1-dem](https://dev.mysql.com/blog-archive/mysql-shell-dump-load-part-1-demo)

\[2\] [https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-utilities-dump-instance-schema.htm](https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-utilities-dump-instance-schema.html)

\[3\] [https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-utilities-load-dump.htm](https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-utilities-load-dump.html)

### Shell 基础操作

> 在计算机科学中，Shell 俗称壳（用来区别于核），是指“为使用者提供操作界面”的软件（command interpreter，命令解析器），它接收用户命令，然后调用相应的应用程序。

> Shell 同时也是一种程序设计语言。作为命令语言，它交互式解释和执行用户输入的命令或者自动地解释和执行预先设定好的一连串的命令；作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。

在 Linux/Unix 平台上，Shell 一般默认为 Bash Shell，也有其他 Shell，比如 C Shell 等；Mac 平台，从 Catalina 版本开始，默认 Shell 从 Bash 改为 Zsh；Windows 平台上，Shell = CMD（Command Shell 的简写，也叫做命令提示符）。

Mac 平台通过 terminal.app、Windows 平台通过 cmd.exe 来运行 shell。

在 Linux/Mac 上，通过如下命令查看当前系统所有的 shell：

```
cat /etc/shells
```

结果如下：

```
# List of acceptable shells for chpass(1).
# Ftpd will not allow users to connect who are not using
# one of these shells.

/bin/bash
/bin/csh
/bin/dash
/bin/ksh
/bin/sh
/bin/tcsh
/bin/zsh
```

查看当前使用的 shell：

```
echo $0
```

结果如下：

```
-zsh
```

修改系统默认 shell 为 bash:

```
chsh -s /bin/bash
```

查看结果（需要重启终端）：

```
xiongxiangdeAir:~ xiongxiaoyang$ echo $0
-bash
```

#### 切换目录

无论是 Linux 平台、Mac 平台还是 Windows 平台，都是通过 `cd`+目录名进入目录， `cd ..`返回上级目录。我们还可以通过`pushd`+目录名进入新目录同时记住之前的目录名，之后可以使用 `popd` 返回之前的目录。

```
xiongxiaoyang@xiongxiangdeAir ~ % pushd java/novel
~/java/novel ~
xiongxiaoyang@xiongxiangdeAir novel % popd
~
xiongxiaoyang@xiongxiangdeAir ~ % 
```

#### 目录列表

Linux/Mac 平台通过`ls`命令查看当前目录下的所有文件和子目录，Windows 平台通过`dir`命令查看。可以使用通配符`*`对显示的内容进行过滤。

```
xiongxiaoyang@xiongxiangdeAir manager % ls *Cache*.java
AuthorInfoCacheManager.java	BookRankCacheManager.java
BookCategoryCacheManager.java	FriendLinkCacheManager.java
BookChapterCacheManager.java	HomeBookCacheManager.java
BookContentCacheManager.java	NewsCacheManager.java
BookInfoCacheManager.java	UserInfoCacheManager.java
```

#### 新建目录

Linux/Mac 平台通过`mkdir`命令新建目录，Windows 平台通过`md`命令新建目录。

#### 删除文件

Linux/Mac 平台通过`rm`+文件名删除文件，Windows 平台通过`del`+文件名删除文件。

#### 删除目录

Linux/Mac 平台通过`rm -r`命令删除目录及其包含的所有文件，Windows 平台通过`deltree`命令实现。

#### 重复命令

所有平台都可以通过`⬆️`键来显示上一条命令，Linux/Mac 平台可以通过`!!`来执行上一条命令，`!n`来执行第 n 条命令。

#### 命令历史

Linux/Mac 平台通过 `history`命令来查看所有使用过的命令，Windows 平台通过`F7`键来实现。Linux/Mac 平台还会显示历史序号，这样就可以通过上面的`!n`命令来方便重复执行。

```
xiongxiaoyang@xiongxiangdeAir bin % history
  992  ls
  993  cd front
  994  ls
  995  cd ../../manager
  996  ls
  997  ls *Cache*.java
  998  chsh -s /bin/bash
  999  echo $0
 1000  echo $0
 1001  cd java/novel-plus/novel-front/target/build/bin
 1002  start.sh
 1003  ls
 1004  ll
 1005  chsh -s /bin/bash
 1006  ls
 1007  ll

```

```
xiongxiaoyang@xiongxiangdeAir bin % !1006
ls
readme.txt		stop.sh
start.sh		windows-start.bat
```

#### 解压文件

Linux/Mac 平台通过`unzip`命令来解压`.zip`后缀的压缩包文件，Windows 平台需要通过互联网安装`unzip`命令。

...

更多 shell 命令请搜索 `Windows Shell` 或 `Bash Shell`。

### Integer.valueOf() 的享元模式应用

在 Java 中，如果我们想要创建一个 Integer 对象，一般有以下三种方式：

1.  通过标准对象创建语法 new Interger(int) 来创建
    
2.  通过静态工厂 Integer.valueOf(int) 来创建
    
3.  通过自动装箱将基本类型 int 自动转换为包装类型 Integer，这其实是通过对 Integer.valueOf() 的自动调用来完成的
    

方式 1 和方式 3 本质上没有什么区别，只不过方式 1 看起来更简洁，那么方式 1 和方式 2 有什么区别呢？先来看一个经典的面试题：

```java
public static void main(String[] args) { 
    Integer m = Integer.valueOf(111);  
    Integer n = Integer.valueOf(111);  
    System.out.println(m == n);

    m = new Integer(111);  
    n = new Integer(111);  
    System.out.println(m == n);   
  
    Integer i = Integer.valueOf(222);    
    Integer j = Integer.valueOf(222);   
    System.out.println(i == j);
   
    i = new Integer(222);  
    j = new Integer(222);   
    System.out.println(i == j);
}
```

大家可以不急着看答案，先独立思考一下以上的打印结果。我想刷过面试题的同学答对这道题应该问题不大，并且能够知道一些原因。但是真正深入了解源码，以及背后设计思想的同学应该也不是很多。我们先来看看构造函数 Interger(int) 的源码（JDK 17），如下所示：

```java
private final int value;
@Deprecated(since="9", forRemoval = true)
public Integer(int value) {
    this.value = value;
}
```

使用 new 关键字创建对象会自动调用该对象的相应构造函数，从以上源码中可以看出，Interger(int) 构造函数只做一件事，那就是初始化成员常量 value 的值，该常量代表了 Integer 对象的值。

使用 new 关键字每次都会在堆内存上开辟一块新的空间用于存放创建出来的对象，只要使用了 new 关键字那么创建出来的对象就是新的对象，而 `==` 关系操作符比较的是两个对象之间的引用是否相等（即是否引用了同一个对象），所以使用 new 创建的每一个 Integer 对象使用`==` 关系操作符得到的结果都是`false`。

我们再来看看静态工厂 Integer.valueOf(int) 的源码（JDK 17），如下所示：

```java
private static class IntegerCache {
    static final int low = -128;
    static final int high;
    static final Integer[] cache;
    static Integer[] archivedCache;

    static {
        // high value may be configured by property
        int h = 127;
        String integerCacheHighPropValue =
            VM.getSavedProperty("java.lang.Integer.IntegerCache.high");
        if (integerCacheHighPropValue != null) {
            try {
                h = Math.max(parseInt(integerCacheHighPropValue), 127);
                // Maximum array size is Integer.MAX_VALUE
                h = Math.min(h, Integer.MAX_VALUE - (-low) -1);
            } catch( NumberFormatException nfe) {
                // If the property cannot be parsed into an int, ignore it.
            }
        }
        high = h;

        // Load IntegerCache.archivedCache from archive, if possible
        CDS.initializeFromArchive(IntegerCache.class);
        int size = (high - low) + 1;

        // Use the archived cache if it exists and is large enough
        if (archivedCache == null || size > archivedCache.length) {
            Integer[] c = new Integer[size];
            int j = low;
            for(int i = 0; i < c.length; i++) {
                c[i] = new Integer(j++);
            }
            archivedCache = c;
        }
        cache = archivedCache;
        // range [-128, 127] must be interned (JLS7 5.1.7)
        assert IntegerCache.high >= 127;
    }

    private IntegerCache() {}
}
@IntrinsicCandidate
public static Integer valueOf(int i) {
    if (i >= IntegerCache.low && i <= IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
}
```

从以上源码可以看出，Integer 类中包含一个私有的静态类 IntegerCache，该类是一个 Integer 对象数组（默认 -128 ～ 127）的缓存，缓存在第一次使用时被初始化，缓存的大小（Integer 缓存对象的最大值）可以由 JVM 参数`-XX:AutoBoxCacheMax=<size>` 或系统属性`-Djava.lang.Integer.IntegerCache.high=<size>`来设置。

如果我们通过静态工厂 Integer.valueOf(int) 来创建 Integer 对象，首先会判断创建的对象值是否在 IntegerCache 中有缓存，有的话直接取缓存中的值，否则通过标准对象创建语法 new Interger(int) 创建并返回。

所以默认情况下，如果使用 Integer.valueOf(int) 创建的 Integer 对象值在 -128 ～ 127 之间，那么无论创建多少次，创建的每一个对象使用`==` 关系操作符得到的结果都是`true`，否则都是`false`。

**注：如果修改过`java.lang.Integer.IntegerCache.high`属性值，那么结果就另当别论了。**

静态工厂 Integer.valueOf(int) 的设计正是对享元模式的应用。享元模式定义如下：

> 享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。

> 享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。

Integer.valueOf(int) 通过享元模式缓存频繁请求的值来显着提高空间和时间性能，效率远远高于通过 new Integer() 创建对象的方式。所以 Java 9 中直接弃用了new Integer()，我们以后在创建 Integer 的包装类型时，也尽量不要再使用 new Integer() 的方式了。

**注：其它包装类型（Long、Short 等）也类似。**



## 链接



[参考链接](https://docs.xxyopen.com/)



[API文档](http://localhost:8888/swagger-ui/index.html)



[前台页面](http://localhost:1024)



[springboot-admin](http://localhost:8082)



[Sentinel控制台](http://localhost:8081)



[xxl-job-admin](http://localhost:8080/xxl-job-admin/)



[RabbitMQ控制台](http://localhost:15672/)



[kibana控制台](http://localhost:5601/)



## 补充

什么是CSRF？
专业解释：跨站请求伪造（Cross-site request forgery），也被称为 one-click attack 或者
session riding，通常缩写为 CSRF 或者 XSRF，是一种挟制用户在当前已登录的Web应用程序上执行非本意的操作的攻击方法。

通俗易懂的例子： 就是我在一个安全的官方网站点了别人的一个恶意链接，由于我在安全网站的登录还没过期，或者是还没登出，我点这个恶意链接的时候是会携带浏览器中的cookie一起发给恶意链接的后端服务器的，恶意链接的后端就根据我发过去的cookie，拿到存在cookie中的sessin_Id，然后他这个恶意的后端伪造一个url请求，url里面带了一个刚刚拿到的session_id和一些业务参数，去正规网站里面用我的身份去进行一些操作，比如转账等，这就是一次跨域攻击。


为什么jwt可以防止csrf攻击？

因为JWT是由正规安全官网的后端生成的，我登录正规网站，正规网站的后端有一个用于生成JWT签名的密钥，先生成一个head，里面放type=jwt，alg(加密算法)=HS256，再将要传递的数据放到payload里面，第三步使用head中定义的加密算法和后端已经设置好的加密密钥，将head+payload这两部分加密生成一个signature签名，前面三步得到的数据加起来生成一个JWT令牌。也就是说，JWT令牌是由正规网站的后端生成的，用户在第一次登陆这个网站并登陆成功以后，后端就会返回一个JWT给用户，这个JWT存在用户浏览器的**localStorage本地缓存**里面，下次这个用户发送请求给正规网站的后台时，就会把这个JWT发给正规网站的后台，根本就用不到cookie，但，还是回到上面那个例子，我在正规网站上点了一个恶意链接，并且传递了cookie给恶意链接的后台，此时恶意链接的后台伪造了一个请求发给了正规网站的后台，由于恶意链接的后台**本地存储**里面没有我与正规网站约定的那个JWT令牌，因此，恶意链接后台生成的发送到正规网站后台的请求就**不会带上JWT**，就会被正规网站的后台判断为是非法请求，然后抛弃。

